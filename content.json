{"meta":{"title":"金子爸爸の家","subtitle":"热爱生活，喜欢软件","description":"欢迎来到金子爸爸博客の家","author":"金子爸爸","url":"https://zhangxin66666.github.io","root":"/"},"pages":[{"title":"标签","date":"2021-12-27T12:21:35.011Z","updated":"2021-12-27T12:21:35.011Z","comments":true,"path":"tags/index.html","permalink":"https://zhangxin66666.github.io/tags/index.html","excerpt":"","text":""},{"title":"留言板","date":"2021-12-27T12:21:35.011Z","updated":"2021-12-27T12:21:35.011Z","comments":true,"path":"message/index.html","permalink":"https://zhangxin66666.github.io/message/index.html","excerpt":"","text":"本页面还在开发中……"},{"title":"分类","date":"2021-12-27T12:21:34.977Z","updated":"2021-12-27T12:21:34.977Z","comments":true,"path":"categories/index.html","permalink":"https://zhangxin66666.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2021-12-27T12:21:34.977Z","updated":"2021-12-27T12:21:34.977Z","comments":true,"path":"css/custom.css","permalink":"https://zhangxin66666.github.io/css/custom.css","excerpt":"","text":"/* 文章页H1-H6图标样式效果 */ h1::before, h2::before, h3::before, h4::before, h5::before, h6::before { -webkit-animation: ccc 1.6s linear infinite ; animation: ccc 1.6s linear infinite ; } @-webkit-keyframes ccc { 0% { -webkit-transform: rotate(0deg); transform: rotate(0deg) } to { -webkit-transform: rotate(-1turn); transform: rotate(-1turn) } } @keyframes ccc { 0% { -webkit-transform: rotate(0deg); transform: rotate(0deg) } to { -webkit-transform: rotate(-1turn); transform: rotate(-1turn) } } #content-inner.layout h1::before { color: #ef50a8 ; margin-left: -1.55rem; font-size: 1.3rem; margin-top: -0.23rem; } #content-inner.layout h2::before { color: #fb7061 ; margin-left: -1.35rem; font-size: 1.1rem; margin-top: -0.12rem; } #content-inner.layout h3::before { color: #ffbf00 ; margin-left: -1.22rem; font-size: 0.95rem; margin-top: -0.09rem; } #content-inner.layout h4::before { color: #a9e000 ; margin-left: -1.05rem; font-size: 0.8rem; margin-top: -0.09rem; } #content-inner.layout h5::before { color: #57c850 ; margin-left: -0.9rem; font-size: 0.7rem; margin-top: 0.0rem; } #content-inner.layout h6::before { color: #5ec1e0 ; margin-left: -0.9rem; font-size: 0.66rem; margin-top: 0.0rem; } #content-inner.layout h1:hover, #content-inner.layout h2:hover, #content-inner.layout h3:hover, #content-inner.layout h4:hover, #content-inner.layout h5:hover, #content-inner.layout h6:hover { color: #49b1f5 ; } #content-inner.layout h1:hover::before, #content-inner.layout h2:hover::before, #content-inner.layout h3:hover::before, #content-inner.layout h4:hover::before, #content-inner.layout h5:hover::before, #content-inner.layout h6:hover::before { color: #49b1f5 ; -webkit-animation: ccc 3.2s linear infinite ; animation: ccc 3.2s linear infinite ; } /* 页面设置icon转动速度调整 */ #rightside_config i.fas.fa-cog.fa-spin { animation: fa-spin 5s linear infinite ; } /*--------更换字体------------*/ @font-face { font-family: 'tzy'; /* 字体名自定义即可 */ src: url('https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/font/ZhuZiAWan.woff2'); /* 字体文件路径 */ font-display: swap; } body, .gitcalendar { font-family: tzy !important; } .categoryBar-list { max-height: 400px; } .clock-row { overflow: hidden; text-overflow: ellipsis; } /*3s为加载动画的时间，1为加载动画的次数，ease-in-out为动画效果*/ #page-header, #web_bg { -webkit-animation: imgblur 2s 1 ease-in-out; animation: imgblur 2s 1 ease-in-out; } @keyframes imgblur { 0% { filter: blur(5px); } 100% { filter: blur(0px); } } /*适配使用-webkit内核的浏览器 */ @-webkit-keyframes imgblur { 0% { -webkit-filter: blur(5px); } 100% { -webkit-filter: blur(0px); } } .table-wrap img { margin: .6rem auto .1rem !important; } /* 标签外挂 网站卡片 start */ .site-card-group img { margin: 0 auto .1rem !important; } .site-card-group .info a img { margin-right: 10px !important; } [data-theme='dark'] .site-card-group .site-card .info .title { color: #f0f0f0 !important; } [data-theme='dark'] .site-card-group .site-card .info .desc { color: rgba(255, 255, 255, .7) !important; } .site-card-group .info .desc { margin-top: 4px !important; } /* 代码块颜色 */ figure.highlight pre .addition { color: #00bf03 !important; }"},{"title":"技术笔记","date":"2021-12-27T12:21:35.011Z","updated":"2021-12-27T12:21:35.011Z","comments":true,"path":"技术笔记/index.html","permalink":"https://zhangxin66666.github.io/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/index.html","excerpt":"","text":"我是技术笔记"},{"title":"关于我","date":"2021-12-28T01:47:38.563Z","updated":"2021-12-28T01:47:38.563Z","comments":true,"path":"关于我/index.html","permalink":"https://zhangxin66666.github.io/%E5%85%B3%E4%BA%8E%E6%88%91/index.html","excerpt":"","text":"关于我十年生死两茫茫,写程序，到天亮。千行代码，Bug何处藏。纵使上线又怎样，朝令改，夕断肠。领导每天新想法，天天改，日日忙。 相顾无言，惟有泪千行。每晚灯火阑珊处，程序员，又加班，工作狂~ 来一张楼主无美颜生活照，见笑了！🤣🤣🤣 基本信息 类别 信息 出生年月 1990年2月 现居地 北京市朝阳区 籍贯 辽宁省锦州市 邮箱 &#56;&#x33;&#52;&#54;&#49;&#x33;&#50;&#x40;&#113;&#113;&#46;&#x63;&#x6f;&#x6d; 教育经历 时间 学校 专业 备注 2009.09~2013.07 沈阳化工大学 电子科学与技术 统招本科 2006.09~2009.07 辽宁省北镇市高级中学 高级基础教育 市重点 工作经历 时间 公司 职位 2021.04~至今 龙湖集团 Java 开发工程师 2017.05~2021.04 包头市包银消费金融股份有限公司 Java 开发工程师 2016.09~2017.04 大连灵动科技发展有限公司 Java 开发工程师 2013.07~2016.08 大连安吉尼尔科技有限公司 Java 开发工程师 专业技能 Java 基础扎实、掌握 JVM 原理、多线程、网络原理、设计模式、常用的数据结构和算法 熟悉 Windows、Mac、Linux 操作系统，熟练使用 linux 常用操作指令 熟练使用 IntelliJ IDEA 开发工具(及各种插件)、熟练使用 Git 版本同步工具 阅读过 Spring、SpringMVC、等开源框架源码，理解其设计原理及底层架构，具备框架定制开发能力 理解 Redis 线程模型，Netty 线程模型，掌握基于响应式的异步非阻塞模型的基本原理，了解 Webflux 熟练掌握分布式缓存 Redis、Elaticsearch，对分布式锁，幂等等常见问题有深入研究及多年实战经验 熟悉常见消息中间件的使用，有多年 RabbitMQ 的实战开发经验，对高级消息队列有深入理解 熟练掌握 Mysql 事务，索引，锁，SQL 优化相关知识，可根据业务场景给出详细及高性能设计方案 熟练使用数据库操作框架 Mybatis、Mybatsi-plus 进行高效业务功能开发 掌握 springCloud 相关框架，对 SpringBoot、SpringCloud 原理有一定了解，有成熟项目经验 熟悉定时任务及延迟任务等业务相关设计，如 xxl-job，延迟消息等相关技术有多年开发经验 熟悉微服务思想，MVC 分层，DDD 理论，服务拆分，治理，监控，服务熔断，降级等相关能力 熟悉 jvm 原理，熟悉垃圾回收以 jvm 性能调优技术，有过线上服务器性能监测及调优经验 熟悉多线程及线程池使用，有多年多线程业务处理经验，封装过多线程批处理工具类等公用组建 了解 Mysql 分库分表相关原理，如 Sardingsphere、Mycat 等框架有相关使用经验 了解操作系统底层原理以及 C、C++程序开发，对计算机底层原理有初步了解 了解前端开发，了解 html，css，js，vue 等前端技术，对前端开发有一定的了解 研究过单片机等硬件开发，喜欢科技产品，喜欢软件，喜欢折腾各种电子产品以及软件 项目经验​ 项目经验只写了在北京之后参与过的相关项目，在大连做的项目偏向于传统，项目也都是单点部署，主要用的框架都是spring、mybatis、Hibernate、springMVC等相互结合使用，即：SSM，SSH，相比于springBoot来说不值一提，现在应该没有几个公司还没用springBoot了吧(#^.^#)，值得一提的是，刚毕业那会，做了半年的C语言嵌入式开发，外包到大连东软做对日的佳能相机系统，虽然目前我已经做了多年的java开发，但是那毕竟是我第一次参加开发项目，人都是有初恋情节的嘛，对自己的第一次念念不忘(我指得是工作🤭)，那半年让我对硬件底层有了一些理解，也算是最大的收获了吧。 —— 包银消费金融(现名：蒙商消费) ——​ 包头市包银消费金融股份有限公司是经中国银监会批准成立的持牌消费金融公司，由包商银行发起设立，包银消费金融为个人消费者提供消费信贷服务。其主要合作渠道有：证大财富，京东金条，微粒贷，去哪儿，京东借贷平台，分期乐，小米等多家放款渠道。目前，已累计完成 1200 多万客户注册和 320 多亿放款规模。 acs：核心交易系统主要包含信贷核算业务和虚拟账户业务，信贷核算主要负责借还款、核销减免交易、利息、罚息计提、各种费用等业务的计算和落地，日终生成交易流水文件供会计核算系统生成会计分录；虚拟账户部分主要为清结算人员提供交易产生的不同资金账户金额的变化及资金流向，为清结算人员对账提供数据支持；系统可以处理每分钟峰值 640 多笔授信申请，每小时峰值 2 万笔授信申请，贷后支持每小时 17 万客户数据。核心日终处理量达 152 万笔(借据数量)。 gls：财务核算系统对核心交易系统日终生成的交易流水解析之后按照分录借贷规则生成财务分录文件交给金蝶系统，17 年财务核算系统是买来的系统，19 年由我重新开发出属于公司自己的财务核算系统，并增加了财务对账功能(核心交易系统和财务分录对账)，不但及时发现线上交易的错误数据，及时解决问题，更提升了月终对账，年结的效率，实现了财务对账自动化，解决了年结人工对账的痛点。 ecif：渠道系统要负责对接第三方引流渠道，客户通过第三方渠道授信、借款，渠道引流到包银，由于不同渠道的授信、放款业务逻辑不同，针对不同渠道提供不同的功能开发。其中部分渠道积累一天客户授信请求指定时间统一发送授信申请到包银，系统可处理每分钟 800 笔授信请求。 css：清结算系统此系统是公司内部清结算人员使用的内部业务系统，主要功能有个人溢缴款账户管理、对公付款、对私付款、退款以及清结算同事转账业务的发起和审核功能 联合贷款系统主要功能有联合贷款协议，路由配置，路由规则，借据还款计划拆分，资方授信，借据、交易流水文件，联合贷款授信影音资料推送 监管报送系统按照监管报送需求，对借据(每月报送全量数据)，还款计划，还款流水，客户，产品，核销，借款申请，资产证券化，五级分类等信息进行加工之后推送给监管报送系统 自我评价业精于勤，荒于嬉 、行成于思，毁于随。 性格乐观开朗，话痨，热爱生活，喜欢拍视频记录生活，喜欢分享知识，分享技术，分享生活中的点点滴滴，脾气好，怕老婆 个人爱好 电子科技产品 软件 —— 喜欢win、Mac、Android 好用无广告软件研究及分享 足球 —— 喜欢但是没机会玩，怀念高中时代呀…. 三国杀 —— 基本已经被凉企逼到退游了….而且生活中也很难找到一起玩这个游戏的朋友了🤣 逛B站 —— 生活区和科技区一个不知名阿婆主😂，佛系更新视频 👉 点击打开我的B站个人空间 记得三连 👍👍👍 看电影 —— 喜欢科幻、漫威粉、追斗罗大陆….."},{"title":"","date":"2021-12-27T12:21:35.011Z","updated":"2021-12-27T12:21:35.011Z","comments":true,"path":"js/chocolate.js","permalink":"https://zhangxin66666.github.io/js/chocolate.js","excerpt":"","text":"/* * @Author: tzy1997 * @Date: 2020-12-15 20:55:25 * @LastEditors: tzy1997 * @LastEditTime: 2021-01-12 19:02:25 */ // 友情链接页面 头像找不到时 替换图片 if (location.href.indexOf(\"link\") !== -1) { var imgObj = document.getElementsByTagName(\"img\"); for (i = 0; i < imgObj.length; i++) { imgObj[i].onerror = function() { this.src = \"https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/theme_f/friend_404.gif\" } } } $(function() { // 气泡 function bubble() { $('#page-header').circleMagic({ radius: 10, density: .2, color: 'rgba(255,255,255,.4)', clearOffset: 0.99 }); }! function(p) { p.fn.circleMagic = function(t) { var o, a, n, r, e = !0, i = [], d = p.extend({ color: \"rgba(255,0,0,.5)\", radius: 10, density: .3, clearOffset: .2 }, t), l = this[0]; function c() { e = !(document.body.scrollTop > a) } function s() { o = l.clientWidth, a = l.clientHeight, l.height = a + \"px\", n.width = o, n.height = a } function h() { if (e) for (var t in r.clearRect(0, 0, o, a), i) i[t].draw(); requestAnimationFrame(h) } function f() { var t = this; function e() { t.pos.x = Math.random() * o, t.pos.y = a + 100 * Math.random(), t.alpha = .1 + Math.random() * d.clearOffset, t.scale = .1 + .3 * Math.random(), t.speed = Math.random(), \"random\" === d.color ? t.color = \"rgba(\" + Math.floor(255 * Math.random()) + \", \" + Math.floor(0 * Math.random()) + \", \" + Math.floor(0 * Math.random()) + \", \" + Math.random().toPrecision(2) + \")\" : t.color = d.color } t.pos = {}, e(), this.draw = function() { t.alpha"}],"posts":[{"title":"Spring技术笔记","slug":"学习笔记/Spring","date":"2021-12-27T12:21:34.975Z","updated":"2021-12-28T03:04:56.317Z","comments":true,"path":"2021/12/27/学习笔记/Spring/","link":"","permalink":"https://zhangxin66666.github.io/2021/12/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Spring/","excerpt":"","text":"Spring底层核心原理解析下载Spring源码git clone的地址为：https://gitee.com/archguide/spring-framework-5.3.10.git Bean的创建过程那么Spring到底是如何来创建一个Bean的呢，这个就是Bean创建的生命周期，大致过程如下： 利用该类的构造方法来实例化得到一个对象（但是如何一个类中有多个构造方法，Spring则会进行选择，这个叫做推断构造方法） 得到一个对象后，Spring会判断该对象中是否存在被@Autowired注解了的属性，把这些属性找出来并由Spring进行赋值（依赖注入） 依赖注入后，Spring会判断该对象是否实现了BeanNameAware接口、BeanClassLoaderAware接口、BeanFactoryAware接口，如果实现了，就表示当前对象必须实现该接口中所定义的setBeanName()、setBeanClassLoader()、setBeanFactory()方法，那Spring就会调用这些方法并传入相应的参数（Aware回调） Aware回调后，Spring会判断该对象中是否存在某个方法被@PostConstruct注解了，如果存在，Spring会调用当前对象的此方法（初始化前） 紧接着，Spring会判断该对象是否实现了InitializingBean接口，如果实现了，就表示当前对象必须实现该接口中的afterPropertiesSet()方法，那Spring就会调用当前对象中的afterPropertiesSet()方法（初始化） 最后，Spring会判断当前对象需不需要进行AOP，如果不需要那么Bean就创建完了，如果需要进行AOP，则会进行动态代理并生成一个代理对象做为Bean（初始化后） 通过最后一步，我们可以发现，当Spring根据UserService类来创建一个Bean时： 如果不用进行AOP，那么Bean就是UserService类的构造方法所得到的对象。 如果需要进行AOP，那么Bean就是UserService的代理类所实例化得到的对象，而不是UserService本身所得到的对象。 Bean对象创建出来后： 如果当前Bean是单例Bean，那么会把该Bean对象存入一个Map&lt;String,Object&gt;，Map的key为beanName，value为Bean对象。这样下次getBean时就可以直接从Map中拿到对应的Bean对象了。（实际上，在Spring源码中，这个Map就是单例池） 如果当前Bean是原型Bean，那么后续没有其他动作，不会存入一个Map，下次getBean时会再次执行上述创建过程，得到一个新的Bean对象。 推断构造方法Spring在基于某个类生成Bean的过程中，需要利用该类的构造方法来实例化得到一个对象，但是如果一个类存在多个构造方法，Spring会使用哪个呢？ Spring的判断逻辑如下： 如果一个类只存在一个构造方法，不管该构造方法是无参构造方法，还是有参构造方法，Spring都会用这个构造方法 如果一个类存在多个构造方法a. 这些构造方法中，存在一个无参的构造方法，那么Spring就会用这个无参的构造方法b. 这些构造方法中，不存在一个无参的构造方法，那么Spring就会报错 Spring的设计思想是这样的： 如果一个类只有一个构造方法，那么没得选择，只能用这个构造方法 如果一个类存在多个构造方法，Spring不知道如何选择，就会看是否有无参的构造方法，因为无参构造方法本身表示了一种默认的意义 不过如果某个构造方法上加了@Autowired注解，那就表示程序员告诉Spring就用这个加了注解的方法，那Spring就会用这个加了@Autowired注解构造方法了 需要重视的是，如果Spring选择了一个有参的构造方法，Spring在调用这个有参构造方法时，需要传入参数，那这个参数是怎么来的呢？ Spring会根据入参的类型和入参的名字去Spring中找Bean对象（以单例Bean为例，Spring会从单例池那个Map中去找）： 先根据入参类型找，如果只找到一个，那就直接用来作为入参 如果根据类型找到多个，则再根据入参名字来确定唯一一个 最终如果没有找到，则会报错，无法创建当前Bean对象 确定用哪个构造方法，确定入参的Bean对象，这个过程就叫做推断构造方法。 AOP大致流程AOP就是进行动态代理，在创建一个Bean的过程中，Spring在最后一步会去判断当前正在创建的这个Bean是不是需要进行AOP，如果需要则会进行动态代理。 如何判断当前Bean对象需不需要进行AOP: 找出所有的切面Bean 遍历切面中的每个方法，看是否写了@Before、@After等注解 如果写了，则判断所对应的Pointcut是否和当前Bean对象的类是否匹配 如果匹配则表示当前Bean对象有匹配的的Pointcut，表示需要进行AOP 利用cglib进行AOP的大致流程： 生成代理类UserServiceProxy，代理类继承UserService 代理类中重写了父类的方法，比如UserService中的test()方法 代理类中还会有一个target属性，该属性的值为被代理对象（也就是通过UserService类推断构造方法实例化出来的对象，进行了依赖注入、初始化等步骤的对象） 代理类中的test()方法被执行时的逻辑如下：a. 执行切面逻辑（@Before）b. 调用target.test() 当我们从Spring容器得到UserService的Bean对象时，拿到的就是UserServiceProxy所生成的对象，也就是代理对象。UserService代理对象.test()—&gt;执行切面逻辑—&gt;target.test()，注意target对象不是代理对象，而是被代理对象。 Spring事务当我们在某个方法上加了@Transactional注解后，就表示该方法在调用时会开启Spring事务，而这个方法所在的类所对应的Bean对象会是该类的代理对象。 Spring事务的代理对象执行某个方法时的步骤： 判断当前执行的方法是否存在@Transactional注解 如果存在，则利用事务管理器（TransactionMananger）新建一个数据库连接 修改数据库连接的autocommit为false 执行target.test()，执行程序员所写的业务逻辑代码，也就是执行sql 执行完了之后如果没有出现异常，则提交，否则回滚 Spring事务是否会失效的判断标准：某个加了@Transactional注解的方法被调用时，要判断到底是不是直接被代理对象调用的，如果是则事务会生效，如果不是则失效。","categories":[{"name":"分类1","slug":"分类1","permalink":"https://zhangxin66666.github.io/categories/%E5%88%86%E7%B1%BB1/"}],"tags":[]},{"title":"RabbitMQ消息中间件技术笔记","slug":"学习笔记/RabbitMQ","date":"2021-12-27T12:21:34.975Z","updated":"2021-12-28T03:03:16.540Z","comments":true,"path":"2021/12/27/学习笔记/RabbitMQ/","link":"","permalink":"https://zhangxin66666.github.io/2021/12/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/RabbitMQ/","excerpt":"","text":"MQ相关概念什么是MQMQ(message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常见的上下游“逻辑解耦+物理解耦”的消息通信服务。使用了 MQ之后，消息发送上游只需要依赖 MQ，不用依赖其他服务。 为什么要用MQ 流量消峰 举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。 应用解耦 以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。 异步提速 有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完，以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题，A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样 B 服务也不用做这些操作。A 服务还能及时的得到异步处理成功的消息。 MQ的分类 ActiveMQ优点：单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，消息可靠性较低的概率丢失数据。 缺点：官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。 Kafka大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafka，这款为大数据而生的消息中间件，以其百万级 TPS 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。目前已经被 LinkedIn，Uber, Twitter, Netflix 等大公司所采纳。 优点：性能卓越，单机写入 TPS 约在百万条/秒，最大的优点，就是吞吐量高。时效性 ms 级可用性非常高，kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用,消费者采用 Pull 方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;有优秀的第三方Kafka Web 管理界面 Kafka-Manager；在日志领域比较成熟，被多家公司和多个开源项目使用；功能支持：功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用。 缺点：Kafka 单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；支持消息顺序，但是一台代理宕机后，就会产生消息乱序，社区更新较慢。 RocketMQRocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发等场景。 优点：单机吞吐量十万级,可用性非常高，分布式架构,消息可以做到 0 丢失,MQ 功能较为完善，还是分布式的，扩展性好,支持 10 亿级别的消息堆积，不会因为堆积导致性能下降,源码是 java 我们可以自己阅读源码，定制自己公司的 MQ。 缺点：支持的客户端语言不多，目前是 java 及 c++，其中 c++不成熟；社区活跃度一般,没有在 MQ核心中去实现 JMS 等接口,有些系统要迁移需要修改大量代码。 RabbitMQ2007 年发布，是一个在 AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。 优点：由于 erlang 语言的高并发特性，性能较好；吞吐量到万级，MQ 功能比较完备,健壮、稳定、易用、跨平台、支持多种语言 如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持 AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用,社区活跃度高；更新频率相当高。 缺点：商业版需要收费,学习成本较高。 MQ的选择KafkaKafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。 RocketMQ天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。 RabbitMQ结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。 RabbitMQ简介2007年，Rabbit 技术公司基于 AMQP 标准开发的 RabbitMQ 1.0 发布。RabbitMQ 采用 Erlang 语言开发。Erlang 语言由 Ericson 设计，专门为开发高并发和分布式系统的一种语言，在电信领域使用广泛。 RabbitMQ四大核心概念 生产者产生数据发送消息的程序是生产者 交换机交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定。 队列 队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列的方式。 消费者 消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。 RabbitMQ的工作模式 简单模式 HelloWorld： 一个生产者、一个消费者，不需要设置交换机（使用默认的交换机）。 工作队列模式 Work Queue： 一个生产者、多个消费者（竞争关系），不需要设置交换机（使用默认的交换机）。 发布订阅模式 Publish/subscribe：需要设置类型为 fanout 的交换机，并且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列。 路由模式 Routing： 需要设置类型为 direct 的交换机，交换机和队列进行绑定，并且指定 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 通配符模式 Topic：需要设置类型为 topic 的交换机，交换机和队列进行绑定，并且指定通配符方式的 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 RabbitMQ工作原理 Broker：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等 Connection：publisher／consumer 和 broker 之间的 TCP 连接 Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCPConnection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。 l Channel 作为轻量级的Connection 极大减少了操作系统建立 TCP connection 的开销 Exchange ： message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout(multicast) Queue ： 消息最终被送到这里等待 consumer 取走 Binding ： exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据 RabbitMQ安装略….推荐使用Docker安装学习，参考文章：Docker操作笔记-从小白到入门 RabbitMQ在安装好后，可以访问http://ip地址:15672 ;其自带了guest/guest的 用户名和密码。 角色说明 超级管理员(administrator)：可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操 作。 监控者(monitoring)：可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用 情况，磁盘使用情况等)。 策略制定者(policymaker)：可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上 图红框标识的部分)。 普通管理者(management)：仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他：无法登陆管理控制台，通常就是普通的生产者和消费者。 消息应答及持久化消息应答机制概念消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成了部分突然它挂掉了，会发生什么情况。RabbitMQ 一旦向消费者传递了一条消息，便立即将该消息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息。以及后续发送给该消费这的消息，因为它无法接收到。为了保证消息在发送过程中不丢失，rabbitmq 引入消息应答机制，消息应答就是: 消费者在接收到消息并且处理该消息之后，告诉rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。 自动应答消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权衡,因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失了,当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制，当然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，最终使得内存耗尽，最终这些消费者线程被操作系统杀死， 所以这种模式仅适用在消费者可以高效并以某种速率能够处理这些消息的情况下使用。 总结：尽量少用自动应答，自动应答是在接收到消息的一刹那就进行了应答，如果后续对消息进行了处理出现错误，不能重新从队列中获取消息处理。 手动应答消息应答的方法 Channel.basicAck(用于肯定确认)：RabbitMQ 已知道该消息并且成功的处理消息，可以将其丢弃了 Channel.basicNack(用于否定确认) Channel.basicReject(用于否定确认)：与 Channel.basicNack 相比少一个参数(是否批量处理)，不处理该消息了直接拒绝，可以将其丢弃了 手动应答的好处是可以批量应答并且减少网络拥堵 multiple 的 true 和 false 代表不同意思 true 代表批量应答 channel 上未应答的消息，比如说 channel 上有传送 tag 的消息 5,6,7,8 当前 tag 是 8 那么此时5-8 的这些还未应答的消息都会被确认收到消息应答 false 同上面相比只会应答 tag=8 的消息 5,6,7 这三个消息依然不会被确认收到消息应答 消息自动重新入队如果消费者由于某些原因失去连接(其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确保不会丢失任何消息。 消息手动应答代码编写默认消息采用的是自动应答，所以我们要想实现消息消费过程中不丢失，需要把自动应答改为手动应答，消费者在上面代码的基础上增加下面画红色部分代码。 消息生产者123456789101112131415161718public class Producer &#123; // 队列名称 public static final String TASK_QUEUE_NAME = &quot;ack_queue&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 声明队列：队列名称，是否持久化，是否共享，自动删除，参数 channel.queueDeclare(TASK_QUEUE_NAME, false, false, false, null); Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) &#123; String message = scanner.next(); channel.basicPublish(&quot;&quot;, TASK_QUEUE_NAME, null, message.getBytes(StandardCharsets.UTF_8)); log.info(&quot;生产者发送消息：&#123;&#125;&quot;, message); &#125; &#125;&#125; RabbitMQ 连接工具类 123456789101112131415public class RabbitMqUtils &#123; // 得到一个连接的 channel public static Channel getChannel() throws Exception &#123; // 创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;127.0.0.1&quot;); factory.setPort(5672); factory.setUsername(&quot;guest&quot;); factory.setPassword(&quot;guest&quot;); factory.setVirtualHost(&quot;demo&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); return channel; &#125;&#125; 消费者1234567891011121314151617181920212223242526public class Work01 &#123; private static final String ACK_QUEUE_NAME = &quot;ack_queue&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); System.out.println(&quot;Work01 等待接收消息处理时间较短&quot;); // 消息消费的时候如何处理消息 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody()); // 业务处理耗时1秒 SleepUtils.sleep(1); System.out.println(&quot; 接收到消息:&quot; + message); /** * 采用手动应答 * 1. 消息标记 tag * 2. 是否批量应答未应答消息：不批量信道中的消息 */ channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;; // ***采用手动应答 boolean autoAck = false; channel.basicConsume(ACK_QUEUE_NAME, autoAck, deliverCallback, (consumerTag) -&gt; &#123; System.out.println(consumerTag + &quot; 消费者取消消费接口回调逻辑&quot;); &#125;); &#125;&#125; 睡眠工具 123456789public class SleepUtils &#123; public static void sleep(int second) &#123; try &#123; Thread.sleep(1000L * second); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; RabbitMQ 持久化持久化概念刚刚我们已经看到了如何处理任务不丢失的情况，但是如何保障当 RabbitMQ 服务停掉以后消息生产者发送过来的消息不丢失。默认情况下 RabbitMQ 退出或由于某种原因崩溃时，它忽视队列和消息，除非告知它不要这样做。确保消息不会丢失需要做两件事：我们需要将队列和消息都标记为持久化。 队列实现持久化之前我们创建的队列都是非持久化的，rabbitmq 如果重启的化，该队列就会被删除掉，如果 要队列实现持久化 需要在声明队列的时候把 durable 参数设置为持久化 但是需要注意的就是如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新创建一个持久化的队列，不然就会出现错误。 以下为控制台中持久化与非持久化队列的 UI 显示区： 这个时候即使重启 rabbitmq 队列也依然存在。 消息实现持久化要想让消息实现持久化需要在消息生产者修改代码，MessageProperties.PERSISTENT_TEXT_PLAIN 添加这个属性，如下图 将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是 这里依然存在当消息刚准备存储在磁盘的时候 但是还没有存储完，消息还在缓存的一个间隔点。此时并没 有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。如果需要 更强有力的持久化策略，参考后边课件发布确认章节。 不公平分发在最开始的时候我们学习到 RabbitMQ 分发消息采用的轮训分发，但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2 处理速度却很慢，这个时候我们还是采用轮训分发的化就会到这处理速度快的这个消费者很大一部分时间处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实就不太好，但是RabbitMQ 并不知道这种情况它依然很公平的进行分发。 注：为了避免这种情况，我们可以设置参数 channel.basicQos(1)，不公平分发由消费方设置，生产环境应该设置为不公平分发。 意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个任务，然后 rabbitmq 就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加新的 worker 或者改变其他存储任务的策略。 发布确认发布确认原理生产者将信道设置成 confirm 模式，一旦信道进入confirm 模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker 就会发送一个确认给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker回传 给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。confirm 模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消 息，生产者应用程序同样可以在回调方法中处理该nack消息。 发布确认的策略开启发布确认的方法发布确认默认是没有开启的，如果要开启需要调用方法 confirmSelect，每当你要想使用发布确认，都需要在 channel 上调用该方法。 12Channel channel = connection.createchannel();channel.confirmselect(); 第一种：单个确认发布这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它 被确认发布，后续的消息才能继续发布,waitForConfirmsOrDie(long)这个方法只有在消息被确认 的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。这种确认方式有一个最大的缺点就是:发布速度特别的慢，因为如果没有确认发布的消息就会 阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某 些应用程序来说这可能已经足够了。 123456789101112131415161718192021// 发布单条消息1000条耗时测试： 722mspublic static void publishMessageOne() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = i + &quot;&quot;; channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); // 发送之后马上进行发布确认，服务端返回 false 或超时时间内未返回，生产者可以消息重发 boolean flag = channel.waitForConfirms(); if (flag) &#123; System.out.println(&quot; 消息发送成功&quot;); &#125; &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个单独确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 第二种：批量确认发布上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地 提高吞吐量，当然这种方式的缺点就是:当发生故障导致发布出现问题时，不知道是哪个消息出现 问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种 方案仍然是同步的，也一样阻塞消息的发布。 123456789101112131415161718192021222324252627282930// 批量发布确认 发布1000个消息，耗时141mspublic static void publishMessageBatch() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); // 批量确认消息大小 int batchSize = 100; // 未确认消息个数 int outstandingMessageCount = 0; long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = i + &quot;&quot;; channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); outstandingMessageCount++; // 100条确认一次 if (outstandingMessageCount == batchSize) &#123; channel.waitForConfirms(); outstandingMessageCount = 0; &#125; &#125; // 为了确保还有剩余没有确认消息 再次确认 if (outstandingMessageCount &gt; 0) &#123; channel.waitForConfirms(); &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个批量确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 第三种：异步确认发布异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说， 他是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功， 下面就让我们来详细讲解异步确认是怎么实现的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 异步发布确认 发布1000个消息，耗时62mspublic static void publishMessageAsync() throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); // 开启发布确认 channel.confirmSelect(); /** * 线程安全有序的一个哈希表，适用于高并发的情况 * 1. 轻松的将序号与消息进行关联 * 2. 轻松批量删除条目 只要给到序列号 * 3. 支持并发访问 */ ConcurrentSkipListMap&lt;Long, String&gt; outstandingConfirms = new ConcurrentSkipListMap&lt;&gt;(); /** * 确认收到消息的一个回调 * 1. 消息序列号 * 2.true 可以确认小于等于当前序列号的消息 * false 确认当前序列号消息 */ ConfirmCallback ackCallback = (sequenceNumber, multiple) -&gt; &#123; if (multiple) &#123; // 返回的是小于等于当前序列号的未确认消息 是一个 map ConcurrentNavigableMap&lt;Long, String&gt; confirmed = outstandingConfirms.headMap(sequenceNumber, true); // 清除该部分未确认消息 confirmed.clear(); &#125;else&#123; // 只清除当前序列号的消息 outstandingConfirms.remove(sequenceNumber); &#125; &#125;; ConfirmCallback nackCallback = (sequenceNumber, multiple) -&gt; &#123; String message = outstandingConfirms.get(sequenceNumber); System.out.println(&quot; 发布的消息&quot;+message+&quot; 未被确认，序列号&quot;+sequenceNumber); &#125;; /** * 添加一个异步确认的监听器 * 1. 确认收到消息的回调 * 2. 未收到消息的回调 */ channel.addConfirmListener(ackCallback, null); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123; String message = &quot; 消息&quot; + i; /** * channel.getNextPublishSeqNo() 获取下一个消息的序列号 * 通过序列号与消息体进行一个关联 * 全部都是未确认的消息体 */ outstandingConfirms.put(channel.getNextPublishSeqNo(), message); channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); &#125; long end = System.currentTimeMillis(); System.out.println(&quot; 发布&quot; + MESSAGE_COUNT + &quot; 个异步确认消息, 耗时&quot; + (end - begin) + &quot;ms&quot;); &#125;&#125; 如何处理异步未确认消息好的解决的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列， 比如说用 ConcurrentLinkedQueue 这个队列在 confirm callbacks 与发布线程之间进行消息的传 递。 3种发布确认速度对比 单独发布消息：同步等待确认，简单，但吞吐量非常有限。 批量发布消息：批量同步等待确认，简单，合理的吞吐量，一旦出现问题但很难推断出是那条消息出现了问题。 异步处理：最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些。 交换机在上一节中，我们创建了一个工作队列。我们假设的是工作队列背后，每个任务都恰好交付给一个消 费者(工作进程)。在这一部分中，我们将做一些完全不同的事情-我们将消息传达给多个消费者。这种模式 称为 ”发布/订阅”，为了说明这种模式，我们将构建一个简单的日志系统。它将由两个程序组成:第一个程序将发出日志消 息，第二个程序是消费者。其中我们会启动两个消费者，其中一个消费者接收到消息后把日志存储在磁盘，另外一个消费者接收到消息后把消息打印在屏幕上，事实上第一个程序发出的日志消息将广播给所有消费者。 Exchanges概念RabbitMQ 消息传递模型的核心思想是: 生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中。相反，**生产者只能将消息发送到交换机(exchange)**，交换机工作的内容非常简单，一方面它接收来 自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息。是应该把这些消 息放到特定队列还是说把他们到许多队列中还是说应该丢弃它们。这就的由交换机的类型来决定。 Exchanges 的类型 直接(direct) — 路由类型 主题(topic) — 通配符匹配模式 标题(headers) — 已经不用了 扇出(fanout) — 发布订阅类型 无名 exchange第一个参数是交换机的名称。空字符串表示默认或无名称交换机：消息能路由发送到队列中其实是由 routingKey(bindingkey)绑定 key 指定的。 临时队列每当我们连接到 Rabbit 时，我们都需要一个全新的空队列，为此我们可以创建一个具有随机名称的队列，或者能让服务器为我们选择一个随机队列名称那就更好了。其次一旦我们断开了消费者的连接，队列将被自动删除。创建临时队列的方式如下:String queueName = channel.queueDeclare().getQueue(); 绑定(bindings)什么是 bingding 呢，binding 其实是 exchange 和 queue 之间的桥梁，它告诉我们 exchange 和那个队 列进行了绑定关系。比如说下面这张图告诉我们的就是 X 与 Q1 和 Q2 进行了绑定 Fanout(发布订阅交换机)Fanout 这种类型非常简单。正如从名称中猜到的那样，它是将接收到的所有消息广播到它知道的 所有队列中。系统中默认有些 exchange 类型 Fanout 实战 Logs 和临时队列的绑定关系如下图 发布订阅发布者1234567891011121314151617181920public class EmitLog &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; /** * 声明一个 exchange * 1.exchange 的名称 * 2.exchange 的类型 */ channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); Scanner sc = new Scanner(System.in); System.out.println(&quot; 请输入信息&quot;); while (sc.hasNext()) &#123; String message = sc.nextLine(); channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot; 生产者发出消息&quot; + message); &#125; &#125; &#125;&#125; 发布订阅接收者112345678910111213141516171819202122public class ReceiveLogs01 &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); /** * 生成一个临时的队列 队列的名称是随机的 * 当消费者断开和该队列的连接时 队列自动删除 */ String queueName = channel.queueDeclare().getQueue(); // 把该临时队列绑定我们的 exchange 其中 routingkey( 也称之为 binding key) 为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); System.out.println(&quot;01等待接收消息, 把接收到的消息打印在屏幕.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(&quot;01控制台打印接收到的消息&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 发布订阅接收者212345678910111213141516171819202122public class ReceiveLogs02 &#123; private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); /** * 生成一个临时的队列 队列的名称是随机的 * 当消费者断开和该队列的连接时 队列自动删除 */ String queueName = channel.queueDeclare().getQueue(); // 把该临时队列绑定我们的 exchange 其中 routingkey( 也称之为 binding key) 为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); System.out.println(&quot;02等待接收消息, 把接收到的消息打印在屏幕.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(&quot;02控制台打印接收到的消息&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; Direct exchange(直接交换机)上一节中，我们构建了一个简单的日志记录系统。我们能够向许多接收者广播日志消息。在本节我们将向其中添加一些特别的功能-比方说我们只让某个消费者订阅发布的部分消息。例如我们只把严重错误消息定向存储到日志文件(以节省磁盘空间)，同时仍然能够在控制台上打印所有日志消息。我们再次来回顾一下什么是 bindings，绑定是交换机和队列之间的桥梁关系。也可以这么理解：队列只对它绑定的交换机的消息感兴趣。绑定用参数：routingKey 来表示也可称该参数为 binding key，创建绑定我们用代码:channel.queueBind(queueName, EXCHANGE_NAME, &quot;routingKey&quot;);绑定之后的意义由其交换类型决定。 直接交换机发布者12345678910111213141516171819202122public class EmitLogDirect &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); // 创建多个 bindingKey Map&lt;String, String&gt; bindingKeyMap = new HashMap&lt;&gt;(); bindingKeyMap.put(&quot;info&quot;, &quot; 普通 info 信息&quot;); bindingKeyMap.put(&quot;warning&quot;, &quot; 警告 warning 信息&quot;); bindingKeyMap.put(&quot;error&quot;, &quot; 错误 error 信息&quot;); //debug 没有消费这接收这个消息 所有就丢失了 bindingKeyMap.put(&quot;debug&quot;, &quot; 调试 debug 信息&quot;); for (Map.Entry&lt;String, String&gt; bindingKeyEntry : bindingKeyMap.entrySet()) &#123; String bindingKey = bindingKeyEntry.getKey(); String message = bindingKeyEntry.getValue(); channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes(StandardCharsets.UTF_8)); System.out.println(&quot; 生产者发出消息:&quot; + message); &#125; &#125; &#125;&#125; 直接交换机消费者11234567891011121314151617181920public class ReceiveLogsDirect01 &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = &quot;disk&quot;; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, &quot;error&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); message = &quot; 接收绑定键:&quot; + delivery.getEnvelope().getRoutingKey() + &quot;, 消息:&quot; + message; // 写磁盘忽略 System.out.println(&quot; 错误日志已经接收&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 直接交换机消费者212345678910111213141516171819public class ReceiveLogsDirect02 &#123; private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = &quot;console&quot;; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, &quot;info&quot;); channel.queueBind(queueName, EXCHANGE_NAME, &quot;warning&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot; 接 收 绑 定 键 :&quot; + delivery.getEnvelope().getRoutingKey() + &quot;, 消息:&quot; + message); &#125;; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; Topics(主题交换机)在上一个小节中，我们改进了日志记录系统。我们没有使用只能进行随意广播的 fanout 交换机，而是使用了 direct 交换机，从而有能实现有选择性地接收日志。尽管使用 direct 交换机改进了我们的系统，但是它仍然存在局限性-比方说我们想接收的日志类型有info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候 direct 就办不到了。这个时候就只能使用 topic 类型。 Topic 要求发送到类型是 topic 交换机的消息的 routing_key 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开。这些单词可以是任意单词，比如说：”stock.usd.nyse”, “nyse.vmw”,”quick.orange.rabbit”.这种类型的。当然这个单词列表最多不能超过 255 个字节。在这个规则列表中，其中有两个替换符是大家需要注意的 *(星号)可以代替一个单词 #(井号)可以替代零个或多个单词 Topic 匹配案例下图绑定关系如下： Q1–&gt;绑定的是：中间带 orange 带 3 个单词的字符串(.orange.) Q2–&gt;绑定的是：最后一个单词是 rabbit 的 3 个单词(..rabbit) 第一个单词是 lazy 的多个单词(lazy.#) 上图是一个队列绑定关系图，我们来看看他们之间数据接收情况是怎么样的quick.orange.rabbit ———— 被队列 Q1Q2 接收到lazy.orange.elephant ———— 被队列 Q1Q2 接收到quick.orange.fox ———— 被队列 Q1 接收到lazy.brown.fox ———— 被队列 Q2 接收到lazy.pink.rabbit ———— 虽然满足两个绑定但只被队列 Q2 接收一次quick.brown.fox ———— 不匹配任何绑定不会被任何队列接收到会被丢弃quick.orange.male.rabbit ———— 是四个单词不匹配任何绑定会被丢弃lazy.orange.male.rabbit ———— 是四个单词但匹配 Q2 当队列绑定关系是下列这种情况时需要引起注意 当一个队列绑定键是#,那么这个队列将接收所有数据，就有点像 fanout 了，如果队列绑定键当中没有#和*出现，那么该队列绑定类型就是 direct 了。 死信队列死信的概念先从概念解释上搞清楚这个定义，死信，顾名思义就是无法被消费的消息，字面意思可以这样理 解，一般来说，producer 将消息投递到 broker 或者直接到 queue 里了，consumer 从 queue 取出消息 进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有 后续的处理，就变成了死信，有死信自然就有了死信队列。 应用场景:为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息 消费发生异常时，将消息投入死信队列中.还有比如说: 用户在商城下单成功并点击去支付后在指定时 间未支付时自动失效 死信的来源 消息 TTL 过期 队列达到最大长度(队列满了，无法再添加数据到 mq 中) 消息被拒绝(basic.reject 或 basic.nack)并且 requeue=false. 代码架构图 消息TTL过期代码死信生产者123456789101112131415161718public class Producer &#123; private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); // 设置消息的 TTL 时间 AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(&quot;10000&quot;).build(); // 该信息是用作演示队列个数限制 for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; channel.basicPublish(NORMAL_EXCHANGE, &quot;zhangsan&quot;, properties, message.getBytes()); System.out.println(&quot; 生产者发送消息:&quot; + message); &#125; &#125; &#125;&#125; 死信消费者C1消费者 C1 ( 启动之后关闭该消费者 模拟其接收不到消息) 12345678910111213141516171819202122232425262728293031323334public class Consumer01 &#123; // 普通交换机名称 private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; // 死信交换机名称 private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 声明死信和普通交换机 类型为 direct channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); // 声明死信队列 String deadQueue = &quot;dead-queue&quot;; channel.queueDeclare(deadQueue, false, false, false, null); // 死信队列绑定死信交换机与 routingkey channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;); // 正常队列绑定死信队列信息 Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); // 正常队列设置死信交换机 参数 key 是固定值 params.put(&quot;x-dead-letter-exchange&quot;, DEAD_EXCHANGE); // 正常队列设置死信 routing-key 参数 key 是固定值 params.put(&quot;x-dead-letter-routing-key&quot;, &quot;lisi&quot;); String normalQueue = &quot;normal-queue&quot;; channel.queueDeclare(normalQueue, false, false, false, params); channel.queueBind(normalQueue, NORMAL_EXCHANGE, &quot;zhangsan&quot;); System.out.println(&quot; 等待接收消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot;Consumer01 接收到消息&quot; + message); &#125;; channel.basicConsume(normalQueue, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 死信队列消费者消费者 C2 ( 以上步骤完成后 启动 C2 消费者它消费死信队列里面的消息) 123456789101112131415161718public class Consumer02 &#123; private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;; public static void main(String[] argv) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); String deadQueue = &quot;dead-queue&quot;; channel.queueDeclare(deadQueue, false, false, false, null); channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;); System.out.println(&quot; 等待接收死信队列消息.....&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot;Consumer02 接收死信队列的消息&quot; + message); &#125;; channel.basicConsume(deadQueue, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 队列达到最大长度生产者消息生产者代码去掉 TTL 属性 123456789101112131415public class TooLongProducer &#123; private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; public static void main(String[] argv) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); // 该信息是用作演示队列个数限制 for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; channel.basicPublish(NORMAL_EXCHANGE, &quot;zhangsan&quot;, null, message.getBytes()); System.out.println(&quot; 生产者发送消息:&quot; + message); &#125; &#125; &#125;&#125; 消费者C1 消费者修改以下代码 ( 启动之后关闭该消费者 模拟其接收不到消息) 注意此时需要把原先队列删除 因为参数改变了 ,C2 消费者代码不变( 启动 C2 消费者) 消息被拒进入死信代码略 延迟队列延时队列,队列内部是有序的，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。 延迟队列使用场景 订单在十分钟之内未支付则自动取消 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。 用户注册成功后，如果三天内没有登陆则进行短信提醒。 用户发起退款，如果三天内没有得到处理则通知相关运营人员。 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议 RabbitMQ 中的 TTLTTL 是什么呢？TTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了 TTL 属性或者进入了设置 TTL 属性的队列，那么这条消息如果在 TTL 设置的时间内没有被消费，则会成为”死信”。如果同时配置了队列的 TTL 和消息的TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。 消息设置 TTL另一种方式便是针对每条消息设置 TTL 队列设置 TTL第一种是在创建队列的时候设置队列的“x-message-ttl”属性 两者的区别如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃(如果配置了死信队列被丢到死信队列中)，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间；另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。 前一小节我们介绍了死信队列，刚刚又介绍了 TTL，至此利用 RabbitMQ 实现延时队列的两大要素已经集齐，接下来只需要将它们进行融合，再加入一点点调味料，延时队列就可以新鲜出炉了。想想看，延时队列，不就是想要消息延迟多久被处理吗，TTL 则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就完事了，因为里面的消息都是希望被立即处理的消息。 整合SpringBoot添加依赖123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;!--RabbitMQ 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--RabbitMQ 测试依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 修改配置文件1234spring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=123 死信队列实现延迟MQ创建两个队列 QA 和 QB，两者队列 TTL 分别设置为 10S 和 40S，然后在创建一个交换机 X 和死信交换机 Y，它们的类型都是 direct，创建一个死信队列 QD，它们的绑定关系如下： 配置文件类代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class TtlQueueConfig &#123; public static final String X_EXCHANGE = &quot;X&quot;; public static final String QUEUE_A = &quot;QA&quot;; public static final String QUEUE_B = &quot;QB&quot;; public static final String Y_DEAD_LETTER_EXCHANGE = &quot;Y&quot;; public static final String DEAD_LETTER_QUEUE = &quot;QD&quot;; // 声明 xExchange @Bean(&quot;xExchange&quot;) public DirectExchange xExchange() &#123; return new DirectExchange(X_EXCHANGE); &#125; // 声明 xExchange @Bean(&quot;yExchange&quot;) public DirectExchange yExchange() &#123; return new DirectExchange(Y_DEAD_LETTER_EXCHANGE); &#125; // 声明队列 A ttl 为 10s 并绑定到对应的死信交换机 @Bean(&quot;queueA&quot;) public Queue queueA() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); // 声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE); // 声明当前队列的死信路由 key args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;); // 声明队列的 TTL args.put(&quot;x-message-ttl&quot;, 10000); return QueueBuilder.durable(QUEUE_A).withArguments(args).build(); &#125; // 声明队列 A 绑定 X 交换机 @Bean public Binding queueaBindingX(@Qualifier(&quot;queueA&quot;) Queue queueA, @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123; return BindingBuilder.bind(queueA).to(xExchange).with(&quot;XA&quot;); &#125; // 声明队列 B ttl 为 40s 并绑定到对应的死信交换机 @Bean(&quot;queueB&quot;) public Queue queueB() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); // 声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE); // 声明当前队列的死信路由 key args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;); // 声明队列的 TTL args.put(&quot;x-message-ttl&quot;, 40000); return QueueBuilder.durable(QUEUE_B).withArguments(args).build(); &#125; // 声明队列 B 绑定 X 交换机 @Bean public Binding queuebBindingX(@Qualifier(&quot;queueB&quot;) Queue queue1B, @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123; return BindingBuilder.bind(queue1B).to(xExchange).with(&quot;XB&quot;); &#125; // 声明死信队列 QD @Bean(&quot;queueD&quot;) public Queue queueD() &#123; return new Queue(DEAD_LETTER_QUEUE); &#125; // 声明死信队列 QD 绑定关系 @Bean public Binding deadLetterBindingQAD(@Qualifier(&quot;queueD&quot;) Queue queueD, @Qualifier(&quot;yExchange&quot;) DirectExchange yExchange) &#123; return BindingBuilder.bind(queueD).to(yExchange).with(&quot;YD&quot;); &#125;&#125; 生产者代码1234567891011121314@Slf4j@RequestMapping(&quot;ttl&quot;)@RestControllerpublic class SendMsgController &#123; @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(&quot;sendMsg/&#123;message&#125;&quot;) public void sendMsg(@PathVariable String message) &#123; log.info(&quot; 当前时间：&#123;&#125;, 发送一条信息给两个 TTL 队列:&#123;&#125;&quot;, new Date(), message); rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XA&quot;, &quot; 消息来自 ttl 为 为 10S 的队列: &quot; + message); rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XB&quot;, &quot; 消息来自 ttl 为 为 40S 的队列: &quot; + message); &#125;&#125; 消费者代码123456789@Slf4j@Componentpublic class DeadLetterQueueConsumer &#123; @RabbitListener(queues = &quot;QD&quot;) public void receiveD(Message message, Channel channel) throws IOException &#123; String msg = new String(message.getBody()); log.info(&quot; 当前时间：&#123;&#125;, 收到死信队列信息&#123;&#125;&quot;, new Date().toString(), msg); &#125;&#125; 第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息，然后被消费掉，这样一个延时队列就打造完成了。不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S两个时间选项，如果需要一个小时后处理，那么就需要增加 TTL 为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？ 延时队列优化在这里新增了一个队列 QC,绑定关系如下,该队列不设置 TTL 时间 看起来似乎没什么问题，但是在最开始的时候，就介绍过如果使用在消息属性上设置 TTL 的方式，消息可能并不会按时“死亡“，因为 RabbitMQ 只会检查第一个消息是否过期，如果过期则丢到死信队列，如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行。 Rabbitmq插件实现延迟队列参考文章 SpringBoot+RabbitMQ用死信队列和插件形式实现延迟队列 Docker安装Rabbitmq及其延时队列插件 安装延时队列插件在官网 ，下载rabbitmq_delayed_message_exchange插件，然后解压放置到 RabbitMQ 的插件目录。进入 RabbitMQ 的安装目录下的 plgins 目录，执行下面命令让该插件生效，然后重启 RabbitMQ /usr/lib/rabbitmq/lib/rabbitmq_server-3.8.8/plugins rabbitmq-plugins enable rabbitmq_delayed_message_exchange 发布确认高级姿势在生产环境中由于一些不明原因，导致 rabbitmq 重启，在 RabbitMQ 重启期间生产者消息投递失败，导致消息丢失，需要手动处理和恢复。于是，我们开始思考，如何才能进行 RabbitMQ 的消息可靠投递呢？特别是在这样比较极端的情况，RabbitMQ 集群不可用的时候，无法投递的消息该如何处理呢: 发布确认 springboot 版本确认机制方案 代码架构图 配置文件12# 在配置文件当中需要添加spring.rabbitmq.publisher-confirm-type=correlated NONE：禁用发布确认模式，是默认值 CORRELATED：发布消息成功到交换器后会触发回调方法 SIMPLE：经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker，注：此配置同步确认消息，生产不建议使用 交换机发布确认代码1234567891011121314151617181920212223242526272829public class MessageConfirmCallBack&lt;T&gt; implements RabbitTemplate.ConfirmCallback &#123; @Resource private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; rabbitTemplate.setConfirmCallback(this); &#125; /** * 交换机确认回调方法 (发布者发送消息是否到交换机触发回调) * 1. 发消息 交换机接收到消息，回调 * 1.1 correlationData 保存毁掉消息的id及相关信息 * 1.2 交换机接收到消息 true * 1.3 失败原因-null * 2. 发消息 交换机接收失败 回调 * 2.1 correlationData 保存毁掉消息的id及相关信息 * 2.2 false * 2.3 失败原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if (ack) &#123; log.info(&quot;发布确认:交换机收到消息id：&#123;&#125;&quot;, correlationData.getId()); &#125; else &#123; log.info(&quot;发布确认:交换机未收到消息，id为：&#123;&#125;,原因：&#123;&#125;&quot;, correlationData.getId(), cause); // TODO 保存数据库重新发送等逻辑保证消息重新发送给交换机 &#125; &#125;&#125; 回退消息在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的。那么如何让无法被路由的消息帮我想办法处理一下？最起码通知我一声，我好自己处理啊。通过设置 mandatory 参数可以在当消息传递过程中不可达目的地时将消息返回给生产者。 添加配置12# 消息回退配置，如果消息无法路由，则回退给生产者spring.rabbitmq.publisher-returns=true 回退代码演示1234567891011121314151617181920212223public class MessageReturnCallBack&lt;T&gt; implements RabbitTemplate.ReturnCallback &#123; @Resource private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; rabbitTemplate.setReturnCallback(this); &#125; /** * 可以将消息传递过程中不可达到目的地(队列)的消息返回给生产者 * 只有不可达 才会回退消息 * 请注意!!!如果你使用了延迟队列插件，那么一定会调用该callback方法，因为数据并没有提交上去， * 而是提交在交换器中，过期时间到了才提交上去，并非是bug！你可以用if进行判断交换机名称来捕捉该报错 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; if(exchange.equals(delayedQueueProperties.getDelayedExchangeName()))&#123; return; &#125; log.info(&quot;消息&#123;&#125;，被交换机&#123;&#125;退回，退回原因：&#123;&#125;，路由Key：&#123;&#125;&quot;, new String(message.getBody()), exchange, replyText, routingKey); &#125;&#125; 备份交换机有了 mandatory 参数和回退消息，我们获得了对无法投递消息的感知能力，有机会在生产者的消息无法被投递时发现并处理。但有时候，我们并不知道该如何处理这些无法路由的消息，最多打个日志，然后触发报警，再来手动处理。而通过日志来处理这些无法路由的消息是很不优雅的做法，特别是当生产者所在的服务有多台机器的时候，手动复制日志会更加麻烦而且容易出错。而且设置 mandatory 参数会增加生产者的复杂性，需要添加处理这些被退回的消息的逻辑。如果既不想丢失消息，又不想增加生产者的复杂性，该怎么做呢？前面在设置死信队列的文章中，我们提到，可以为队列设置死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息。在 RabbitMQ 中，有一种备份交换机的机制存在，可以很好的应对这个问题。什么是备份交换机呢？备份交换机可以理解为 RabbitMQ 中交换机的“备胎”，当我们为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理，通常备份交换机的类型为 Fanout ，这样就能把所有消息都投递到与其绑定的队列中，然后我们在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都进入这个队列了。当然，我们还可以建立一个报警队列，用独立的消费者来进行监测和报警。 备份交换机代码声明在原来的代码上面多声明一个交换机和两个队列，还有一个报警消费者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// @Configurationpublic class ConfirmConfig &#123; public static final String CONFIRM_EXCHANGE_NAME = &quot;confirm.exchange&quot;; public static final String CONFIRM_QUEUE_NAME = &quot;confirm.queue&quot;; public static final String BACKUP_EXCHANGE_NAME = &quot;backup.exchange&quot;; public static final String BACKUP_QUEUE_NAME = &quot;backup.queue&quot;; public static final String WARNING_QUEUE_NAME = &quot;warning.queue&quot;; // 声明确认队列 @Bean(&quot;confirmQueue&quot;) public Queue confirmQueue() &#123; return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build(); &#125; // 声明确认队列绑定关系 @Bean public Binding queueBinding(@Qualifier(&quot;confirmQueue&quot;) Queue queue, @Qualifier(&quot;confirmExchange&quot;) DirectExchange exchange) &#123; return BindingBuilder.bind(queue).to(exchange).with(&quot;key1&quot;); &#125; // 声明备份 Exchange @Bean(&quot;backupExchange&quot;) public FanoutExchange backupExchange() &#123; return new FanoutExchange(BACKUP_EXCHANGE_NAME); &#125; // 声明确认 Exchange 交换机的备份交换机 @Bean(&quot;confirmExchange&quot;) public DirectExchange confirmExchange() &#123; ExchangeBuilder exchangeBuilder = ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME) .durable(true) // 设置该交换机的备份交换机 .withArgument(&quot;alternate-exchange&quot;, BACKUP_EXCHANGE_NAME); return (DirectExchange) exchangeBuilder.build(); &#125; // 声明警告队列 @Bean(&quot;warningQueue&quot;) public Queue warningQueue() &#123; return QueueBuilder.durable(WARNING_QUEUE_NAME).build(); &#125; // 声明报警队列绑定关系 @Bean public Binding warningBinding(@Qualifier(&quot;warningQueue&quot;) Queue queue, @Qualifier(&quot;backupExchange&quot;) FanoutExchange backupExchange) &#123; return BindingBuilder.bind(queue).to(backupExchange); &#125; // 声明备份队列 @Bean(&quot;backQueue&quot;) public Queue backQueue() &#123; return QueueBuilder.durable(BACKUP_QUEUE_NAME).build(); &#125; // 声明备份队列绑定关系 @Bean public Binding backupBinding(@Qualifier(&quot;backQueue&quot;) Queue queue, @Qualifier(&quot;backupExchange&quot;) FanoutExchange backupExchange) &#123; return BindingBuilder.bind(queue).to(backupExchange); &#125;&#125; 报警消费者1234567891011@Component@Slf4jpublic class WarningConsumer &#123; public static final String WARNING_QUEUE_NAME = &quot;warning.queue&quot;; @RabbitListener(queues = WARNING_QUEUE_NAME) public void receiveWarningMsg(Message message) &#123; String msg = new String(message.getBody()); log.error(&quot; 报警发现不可路由消息：&#123;&#125;&quot;, msg); &#125;&#125; 测试注意事项 重新启动项目的时候需要把原来的 confirm.exchange 删除因为我们修改了其绑定属性，不然报错。 备份交换机和回退优先级mandatory 参数与备份交换机可以一起使用的时候，如果两者同时开启，消息究竟何去何从？谁优先级高，经过上面结果显示答案是备份交换机优先级高。 RabbitMQ其他知识点幂等性用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等 消息重复消费消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断，故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。 解决思路MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识比如时间戳 或者 UUID 或者订单消费者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。 消费端的幂等性保障在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性，这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。业界主流的幂等性有两种操作:a.唯一 ID+指纹码机制,利用数据库主键去重, b.利用 redis 的原子性去实现 唯一ID+ 指纹码机制指纹码:我们的一些规则或者时间戳加别的服务给到的唯一信息码,它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中,优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。 Redis原子性利用 redis 执行 setnx 命令，天然具有幂等性。从而实现不重复消费，此方式为目前用的最多的方案。 优先级队列使用场景在我们系统中有一个订单催付的场景，我们的客户在天猫下的订单,淘宝会及时将订单推送给我们，如果在用户设定的时间内未付款那么就会给用户推送一条短信提醒，很简单的一个功能对吧，但是，tmall商家对我们来说，肯定是要分大客户和小客户的对吧，比如像苹果，小米这样大商家一年起码能给我们创造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis 来存放的定时轮询，大家都知道 redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ 进行改造和优化,如果发现是大客户的订单给一个相对比较高的优先级，否则就是默认优先级。 如何添加a.控制台页面添加 b.队列中代码添加优先级 123Map&lt;String, Object&gt; params = new HashMap();params.put(&quot;x-max-priority&quot;, 10);channel.queueDeclare(&quot;hello&quot;, true, false, false, params); c.消息中代码添加优先级 1AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); d.注意事项 要让队列实现优先级需要做的事情有如下事情:队列需要设置为优先级队列，消息需要设置消息的优先级，消费者需要等待消息已经发送到队列中才去消费因为，这样才有机会对消息进行排序 实战生产者1234567891011121314151617181920public class Producer &#123; private static final String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws Exception &#123; try (Channel channel = RabbitMqUtils.getChannel();) &#123; // 给消息赋予一个 priority 属性 AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); for (int i = 1; i &lt; 11; i++) &#123; String message = &quot;info&quot; + i; if (i == 5) &#123; channel.basicPublish(&quot;&quot;, QUEUE_NAME, properties, message.getBytes()); &#125; else &#123; channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes()); &#125; System.out.println(&quot; 发送消息完成:&quot; + message); &#125; &#125; &#125;&#125; 消费者12345678910111213141516171819public class Consumer &#123; private static final String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws Exception &#123; Channel channel = RabbitMqUtils.getChannel(); // 设置队列的最大优先级 最大可以设置到 255 官网推荐 1-10 如果设置太高比较吃内存和 CPU Map&lt;String, Object&gt; params = new HashMap(); params.put(&quot;x-max-priority&quot;, 10); channel.queueDeclare(QUEUE_NAME, true, false, false, params); System.out.println(&quot; 消费者启动等待消费......&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String receivedMessage = new String(delivery.getBody()); System.out.println(&quot; 接收到消息:&quot; + receivedMessage); &#125;; channel.basicConsume(QUEUE_NAME, true, deliverCallback, (consumerTag) -&gt; &#123; System.out.println(&quot; 消费者无法消费 消息时调用，如队列被删除&quot;); &#125;); &#125;&#125; 惰性队列RabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当消费者由于各种各样的原因(比如消费者下线、宕机亦或者是由于维护而关闭等)而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存之中，这样可以更加快速的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。虽然 RabbitMQ 的开发者们一直在升级相关的算法，但是效果始终不太理想，尤其是在消息量特别大的时候。 两种模式队列具备两种模式：default 和 lazy。默认的为 default 模式，在 3.6.0 之前的版本无需做任何变更。lazy模式即为惰性队列的模式，可以通过调用 channel.queueDeclare 方法的时候在参数中设置，也可以通过Policy 的方式设置，如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级。如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。在队列声明的时候可以通过“x-queue-mode”参数来设置队列的模式，取值为“default”和“lazy”。下面示例中演示了一个惰性队列的声明细节： 123Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;();args.put(&quot;x-queue-mode&quot;, &quot;lazy&quot;);channel.queueDeclare(&quot;myqueue&quot;, false, false, false, args); 内存开销对比 在发送 1 百万条消息，每条消息大概占 1KB 的情况下，普通队列占用内存是 1.2GB，而惰性队列仅仅占用 1.5MB RabbitMQ 集群clustering集群模式使用集群的原因最开始我们介绍了如何安装及运行 RabbitMQ 服务，不过这些是单机版的，无法满足目前真实应用的要求。如果 RabbitMQ 服务器遇到内存崩溃、机器掉电或者主板故障等情况，该怎么办？单台 RabbitMQ服务器可以满足每秒 1000 条消息的吞吐量，那么如果应用需要 RabbitMQ 服务满足每秒 10 万条消息的吞吐量呢？购买昂贵的服务器来增强单机 RabbitMQ 务的性能显得捉襟见肘，搭建一个 RabbitMQ 集群才是解决实际问题的关键。 搭建步骤1.修改 3 台机器的主机名称 vim /etc/hostname 2.配置各个节点的 hosts 文件，让各个节点都能互相识别对方 vim /etc/hosts10.211.55.74 node110.211.55.75 node210.211.55.76 node3 3.以确保各个节点的 cookie 文件使用的是同一个值 在 node1 上执行远程操作命令scp /var/lib/rabbitmq/.erlang.cookie root@node2:/var/lib/rabbitmq/.erlang.cookiescp /var/lib/rabbitmq/.erlang.cookie root@node3:/var/lib/rabbitmq/.erlang.cookie 4.启动 RabbitMQ 服务,顺带启动 Erlang 虚拟机和 RbbitMQ 应用服务(在三台节点上分别执行以下命令) rabbitmq-server -detached 5.在节点 2 执行 1234rabbitmqctl stop_app (rabbitmqctl stop 会将 Erlang 虚拟机关闭，rabbitmqctl stop_app 只关闭 RabbitMQ 服务)rabbitmqctl resetrabbitmqctl join_cluster rabbit@node1rabbitmqctl start_app(只启动应用服务) 6.在节点 3 执行 1234rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster rabbit@node2rabbitmqctl start_app 7.集群状态 rabbitmqctl cluster_status 8.需要重新设置用户 创建账号rabbitmqctl add_user admin 123设置用户角色rabbitmqctl set_user_tags admin administrator设置用户权限rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 9.解除集群节点(node2 和 node3 机器分别执行) 12345rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_apprabbitmqctl cluster_statusrabbitmqctl forget_cluster_node rabbit@node2(node1 机器上执行) 镜像队列使用镜像的原因如果 RabbitMQ 集群中只有一个 Broker 节点，那么该节点的失效将导致整体服务的临时性不可用，并且也可能会导致消息的丢失。可以将所有消息都设置为持久化，并且对应队列的durable属性也设置为true，但是这样仍然无法避免由于缓存导致的问题：因为消息在发送之后和被写入磁盘井执行刷盘动作之间存在一个短暂却会产生问题的时间窗。通过 publisherconfirm 机制能够确保客户端知道哪些消息己经存入磁盘，尽管如此，一般不希望遇到因单点故障导致的服务不可用。引入镜像队列(Mirror Queue)的机制，可以将队列镜像到集群中的其他 Broker 节点之上，如果集群中的一个节点失效了，队列能自动地切换到镜像中的另一个节点上以保证服务的可用性。 搭建步骤1.启动三台集群节点 2.随便找一个节点添加 policy 3.在 node1 上创建一个队列发送一条消息，队列存在镜像队列 4.停掉 node1 之后发现 node2 成为镜像队列 5.就算整个集群只剩下一台机器了 依然能消费队列里面的消息 说明队列里面的消息被镜像队列传递到相应机器里面了 实现高可用负载均衡整体架构图 Haproxy 实现负载均衡HAProxy 提供高可用性、负载均衡及基于 TCPHTTP 应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案，包括 Twitter,Reddit,StackOverflow,GitHub 在内的多家知名互联网公司在使用。HAProxy 实现了一种事件驱动、单一进程模型，此模型支持非常大的井发连接数。 扩展 nginx,lvs,haproxy 之间的区别: http://www.ha97.com/5646.html Keepalived实现双机试想如果前面配置的 HAProxy 主机突然宕机或者网卡失效，那么虽然 RbbitMQ 集群没有任何故障但是对于外界的客户端来说所有的连接都会被断开结果将是灾难性的为了确保负载均衡服务的可靠性同样显得十分重要，这里就要引入 Keepalived 它能够通过自身健康检查、资源接管功能做高可用(双机热备)，实现故障转移。 Federation Exchange​ (broker 北京)，(broker 深圳)彼此之间相距甚远，网络延迟是一个不得不面对的问题。有一个在北京的业务(Client 北京) 需要连接(broker 北京)，向其中的交换器 exchangeA 发送消息，此时的网络延迟很小，(Client 北京)可以迅速将消息发送至 exchangeA 中，就算在开启了 publisherconfirm 机制或者事务机制的情况下，也可以迅速收到确认信息。此时又有个在深圳的业务(Client 深圳)需要向 exchangeA 发送消息，那么(Client 深圳) (broker 北京)之间有很大的网络延迟，(Client 深圳) 将发送消息至 exchangeA 会经历一定的延迟，尤其是在开启了 publisherconfirm 机制或者事务机制的情况下，(Client 深圳) 会等待很长的延迟时间来接收(broker 北京)的确认信息，进而必然造成这条发送线程的性能降低，甚至造成一定程度上的阻塞。​ 将业务(Client 深圳)部署到北京的机房可以解决这个问题，但是如果(Client 深圳)调用的另些服务都部署在深圳，那么又会引发新的时延问题，总不见得将所有业务全部部署在一个机房，那么容灾又何以实现？这里使用 Federation 插件就可以很好地解决这个问题. 搭建步骤1.需要保证每台节点单独运行 2.在每台机器上开启 federation 相关插件 12rabbitmq-plugins enable rabbitmq_federationrabbitmq-plugins enable rabbitmq_federation_management 3.原理图(先运行 consumer 在 node2 创建 fed_exchange) 4.在 downstream(node2)配置 upstream(node1) 5.添加 policy 6.成功的前提 Federation Queue联邦队列可以在多个 Broker 节点(或者集群)之间为单个队列提供均衡负载的功能。一个联邦队列可以连接一个或者多个上游队列(upstream queue)，并从这些上游队列中获取消息以满足本地消费者消费消息的需求。 搭建步骤1.原理图 2.添加 upstream(同上) 3.添加 policy ShovelFederation 具备的数据转发功能类似，Shovel 够可靠、持续地从一个 Broker 中的队列(作为源端，即source)拉取数据并转发至另一个 Broker 中的交换器(作为目的端，即 destination)。作为源端的队列和作为目的端的交换器可以同时位于同一个 Broker，也可以位于不同的 Broker 上。Shovel 可以翻译为”铲子”，是一种比较形象的比喻，这个”铲子”可以将消息从一方”铲子”另一方。Shovel 行为就像优秀的客户端应用程序能够负责连接源和目的地、负责消息的读写及负责连接失败问题的处理。 搭建步骤1.开启插件(需要的机器都开启) 12rabbitmq-plugins enable rabbitmq_shovelrabbitmq-plugins enable rabbitmq_shovel_management 2.原理图在源头发送的消息直接回进入到目的地队列 3.添加 shovel 源和目的地 RabbitMQ工具类在企业开发过程中，直接使用SpringBoot提供的RabbitTemplate还是略显复杂，通常我们一个系统发送消息基本上也是只依赖于一个交换机和一个队列（延迟消息需单独依赖于延迟交换机），基于此，我们可以把交换机、队列以及路由key等声明直接放在配置文件中，然后封装发送普通消息的工具类，和发送延迟消息的工具类，发送的消息体内容我们可以增加交易码这个概念，消费者通过不同交易码，处理不同的业务。消息体通过泛型，在发消息时声明消息体类型，通过json序列化传输。 工具类使用延迟消息发送项目启动时，直接声明好延迟交换机，延迟队列以及路由key，发送延迟消息只需要一句代码 12345public void sendDelayMsg(@PathVariable String message, @PathVariable Integer delayTime) &#123; log.info(&quot;当前时间：&#123;&#125;,发送一条时长&#123;&#125;毫秒TTL信息给队列QC:&#123;&#125;&quot;, new Date(), delayTime, message); MsgData&lt;String&gt; msgData = new MsgData&lt;&gt;(&quot;0001&quot;, message, &quot;这是我的测试延迟消息！&quot;); EventDispatcherUtil.eventDispatch(msgData, delayTime);&#125; 普通消息发送普通消息通过发布订阅模式实现，其他系统若要接收次消息，只需要声明一个队列然后添加监听，绑定到此交换机上即可，发送普通消息也只需要一句代码实现 12345public void sendFanoutMsg(@PathVariable String message) &#123; log.info(&quot;当前时间：&#123;&#125;,发送一条信息给队列QC:&#123;&#125;&quot;, new Date(), message); MsgData&lt;String&gt; msgData = new MsgData&lt;&gt;(&quot;0001&quot;, message, &quot;这是我的测订阅消息！&quot;); EventDispatcherUtil.eventDispatch(msgData);&#125; RabbitMQ相关面试题如何保证消息不丢失？ 队列和消息持久化：保证MQ宕机了消息不丢失，必须保证在磁盘上才能（3.4.2、3.4.3） 消息发布确认：开启消息发布确认，MQ将消息发送到交换机并且保存在磁盘上之后返回一个确认，此时可以保证生产者发送的消息绝对不丢失。见：9.1 消息回退处理：当消息到达交换机无法路由到队列时，交换机把消息回退给生产者，也可以通过备份交换机实现。见：9.2 消息应答机制：设置为手动应答，保证消费者正确处理完消息，如果处理失败，消息重新入队 集群环境下，添加镜像队列。见：11.2 消息的类型主要是交换机的类型，包括： 直接(direct)：路由类型 主题(topic) 标题(headers) ：已经不用了 扇出(fanout)：发布订阅类型","categories":[{"name":"分类2","slug":"分类2","permalink":"https://zhangxin66666.github.io/categories/%E5%88%86%E7%B1%BB2/"}],"tags":[]}],"categories":[{"name":"分类1","slug":"分类1","permalink":"https://zhangxin66666.github.io/categories/%E5%88%86%E7%B1%BB1/"},{"name":"分类2","slug":"分类2","permalink":"https://zhangxin66666.github.io/categories/%E5%88%86%E7%B1%BB2/"}],"tags":[]}