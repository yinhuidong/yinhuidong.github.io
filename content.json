{"meta":{"title":"二十","subtitle":"卷就完了","description":"欢迎来卷","author":"二十","url":"https://yinhuidong.github.io","root":"/"},"pages":[{"title":"分类","date":"2022-01-10T12:46:21.418Z","updated":"2021-12-27T12:21:34.000Z","comments":true,"path":"categories/index.html","permalink":"https://yinhuidong.github.io/categories/index.html","excerpt":"","text":""},{"title":"留言板","date":"2022-01-10T12:46:21.418Z","updated":"2021-12-27T12:21:35.000Z","comments":true,"path":"message/index.html","permalink":"https://yinhuidong.github.io/message/index.html","excerpt":"","text":"本页面还在开发中……"},{"title":"标签","date":"2022-01-10T12:46:21.418Z","updated":"2021-12-27T12:21:35.000Z","comments":true,"path":"tags/index.html","permalink":"https://yinhuidong.github.io/tags/index.html","excerpt":"","text":""},{"title":"关于我","date":"2022-01-11T02:40:01.624Z","updated":"2022-01-11T02:40:01.624Z","comments":true,"path":"关于我/index.html","permalink":"https://yinhuidong.github.io/%E5%85%B3%E4%BA%8E%E6%88%91/index.html","excerpt":"","text":"关于我十年生死两茫茫,写程序，到天亮。千行代码，Bug何处藏。纵使上线又怎样，朝令改，夕断肠。领导每天新想法，天天改，日日忙。 相顾无言，惟有泪千行。每晚灯火阑珊处，程序员，又加班，工作狂~ 🤣🤣🤣 基本信息 类别 信息 出生年月 1998年11月 现居地 北京市 籍贯 大庆市 邮箱 &#49;&#x39;&#x37;&#x32;&#x30;&#51;&#57;&#x37;&#x37;&#51;&#64;&#113;&#x71;&#46;&#99;&#x6f;&#109; 教育经历 时间 学校 专业 备注 2017.09~2021.07 齐齐哈尔大学 计算机科学与技术 统招本科 工作经历 时间 公司 职位 2021.06~至今 mi Java 开发工程师 专业技能 Java 基础扎实、掌握 JVM 原理、多线程、网络原理、设计模式、常用的数据结构和算法 熟悉 Windows、Mac、Linux 操作系统，熟练使用 linux 常用操作指令 熟练使用 IntelliJ IDEA 开发工具(及各种插件)、熟练使用 Git 版本同步工具 阅读过 Spring、SpringMVC、等开源框架源码，理解其设计原理及底层架构，具备框架定制开发能力 理解 Redis 线程模型，Netty 线程模型，掌握基于响应式的异步非阻塞模型的基本原理，了解 Webflux 熟练掌握分布式缓存 Redis、Elaticsearch，对分布式锁，幂等等常见问题有深入研究及多年实战经验 熟悉常见消息中间件的使用，有多年 RabbitMQ 的实战开发经验，对高级消息队列有深入理解 熟练掌握 Mysql 事务，索引，锁，SQL 优化相关知识，可根据业务场景给出详细及高性能设计方案 熟练使用数据库操作框架 Mybatis、Mybatsi-plus 进行高效业务功能开发 掌握 springCloud 相关框架，对 SpringBoot、SpringCloud 原理有一定了解，有成熟项目经验 熟悉定时任务及延迟任务等业务相关设计，如 xxl-job，延迟消息等相关技术有多年开发经验 熟悉微服务思想，MVC 分层，DDD 理论，服务拆分，治理，监控，服务熔断，降级等相关能力 熟悉 jvm 原理，熟悉垃圾回收以 jvm 性能调优技术，有过线上服务器性能监测及调优经验 熟悉多线程及线程池使用，有多年多线程业务处理经验，封装过多线程批处理工具类等公用组建 了解 Mysql 分库分表相关原理，如 Sardingsphere、Mycat 等框架有相关使用经验 了解操作系统底层原理以及 C、C++程序开发，对计算机底层原理有初步了解 了解前端开发，了解 html，css，js，vue 等前端技术，对前端开发有一定的了解 研究过单片机等硬件开发，喜欢科技产品，喜欢软件，喜欢折腾各种电子产品以及软件 项目经验​ 自我评价NB。"},{"title":"技术笔记","date":"2022-01-10T12:46:21.418Z","updated":"2021-12-27T12:21:35.000Z","comments":true,"path":"技术笔记/index.html","permalink":"https://yinhuidong.github.io/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/index.html","excerpt":"","text":"我是技术笔记"},{"title":"","date":"2022-01-10T12:46:21.418Z","updated":"2021-12-27T12:21:35.000Z","comments":true,"path":"js/chocolate.js","permalink":"https://yinhuidong.github.io/js/chocolate.js","excerpt":"","text":"/* * @Author: tzy1997 * @Date: 2020-12-15 20:55:25 * @LastEditors: tzy1997 * @LastEditTime: 2021-01-12 19:02:25 */ // 友情链接页面 头像找不到时 替换图片 if (location.href.indexOf(\"link\") !== -1) { var imgObj = document.getElementsByTagName(\"img\"); for (i = 0; i < imgObj.length; i++) { imgObj[i].onerror = function() { this.src = \"https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/theme_f/friend_404.gif\" } } } $(function() { // 气泡 function bubble() { $('#page-header').circleMagic({ radius: 10, density: .2, color: 'rgba(255,255,255,.4)', clearOffset: 0.99 }); }! function(p) { p.fn.circleMagic = function(t) { var o, a, n, r, e = !0, i = [], d = p.extend({ color: \"rgba(255,0,0,.5)\", radius: 10, density: .3, clearOffset: .2 }, t), l = this[0]; function c() { e = !(document.body.scrollTop > a) } function s() { o = l.clientWidth, a = l.clientHeight, l.height = a + \"px\", n.width = o, n.height = a } function h() { if (e) for (var t in r.clearRect(0, 0, o, a), i) i[t].draw(); requestAnimationFrame(h) } function f() { var t = this; function e() { t.pos.x = Math.random() * o, t.pos.y = a + 100 * Math.random(), t.alpha = .1 + Math.random() * d.clearOffset, t.scale = .1 + .3 * Math.random(), t.speed = Math.random(), \"random\" === d.color ? t.color = \"rgba(\" + Math.floor(255 * Math.random()) + \", \" + Math.floor(0 * Math.random()) + \", \" + Math.floor(0 * Math.random()) + \", \" + Math.random().toPrecision(2) + \")\" : t.color = d.color } t.pos = {}, e(), this.draw = function() { t.alpha"},{"title":"","date":"2022-01-10T12:46:21.415Z","updated":"2021-12-27T12:21:34.000Z","comments":true,"path":"css/custom.css","permalink":"https://yinhuidong.github.io/css/custom.css","excerpt":"","text":"/* 文章页H1-H6图标样式效果 */ h1::before, h2::before, h3::before, h4::before, h5::before, h6::before { -webkit-animation: ccc 1.6s linear infinite ; animation: ccc 1.6s linear infinite ; } @-webkit-keyframes ccc { 0% { -webkit-transform: rotate(0deg); transform: rotate(0deg) } to { -webkit-transform: rotate(-1turn); transform: rotate(-1turn) } } @keyframes ccc { 0% { -webkit-transform: rotate(0deg); transform: rotate(0deg) } to { -webkit-transform: rotate(-1turn); transform: rotate(-1turn) } } #content-inner.layout h1::before { color: #ef50a8 ; margin-left: -1.55rem; font-size: 1.3rem; margin-top: -0.23rem; } #content-inner.layout h2::before { color: #fb7061 ; margin-left: -1.35rem; font-size: 1.1rem; margin-top: -0.12rem; } #content-inner.layout h3::before { color: #ffbf00 ; margin-left: -1.22rem; font-size: 0.95rem; margin-top: -0.09rem; } #content-inner.layout h4::before { color: #a9e000 ; margin-left: -1.05rem; font-size: 0.8rem; margin-top: -0.09rem; } #content-inner.layout h5::before { color: #57c850 ; margin-left: -0.9rem; font-size: 0.7rem; margin-top: 0.0rem; } #content-inner.layout h6::before { color: #5ec1e0 ; margin-left: -0.9rem; font-size: 0.66rem; margin-top: 0.0rem; } #content-inner.layout h1:hover, #content-inner.layout h2:hover, #content-inner.layout h3:hover, #content-inner.layout h4:hover, #content-inner.layout h5:hover, #content-inner.layout h6:hover { color: #49b1f5 ; } #content-inner.layout h1:hover::before, #content-inner.layout h2:hover::before, #content-inner.layout h3:hover::before, #content-inner.layout h4:hover::before, #content-inner.layout h5:hover::before, #content-inner.layout h6:hover::before { color: #49b1f5 ; -webkit-animation: ccc 3.2s linear infinite ; animation: ccc 3.2s linear infinite ; } /* 页面设置icon转动速度调整 */ #rightside_config i.fas.fa-cog.fa-spin { animation: fa-spin 5s linear infinite ; } /*--------更换字体------------*/ @font-face { font-family: 'tzy'; /* 字体名自定义即可 */ src: url('https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/font/ZhuZiAWan.woff2'); /* 字体文件路径 */ font-display: swap; } body, .gitcalendar { font-family: tzy !important; } .categoryBar-list { max-height: 400px; } .clock-row { overflow: hidden; text-overflow: ellipsis; } /*3s为加载动画的时间，1为加载动画的次数，ease-in-out为动画效果*/ #page-header, #web_bg { -webkit-animation: imgblur 2s 1 ease-in-out; animation: imgblur 2s 1 ease-in-out; } @keyframes imgblur { 0% { filter: blur(5px); } 100% { filter: blur(0px); } } /*适配使用-webkit内核的浏览器 */ @-webkit-keyframes imgblur { 0% { -webkit-filter: blur(5px); } 100% { -webkit-filter: blur(0px); } } .table-wrap img { margin: .6rem auto .1rem !important; } /* 标签外挂 网站卡片 start */ .site-card-group img { margin: 0 auto .1rem !important; } .site-card-group .info a img { margin-right: 10px !important; } [data-theme='dark'] .site-card-group .site-card .info .title { color: #f0f0f0 !important; } [data-theme='dark'] .site-card-group .site-card .info .desc { color: rgba(255, 255, 255, .7) !important; } .site-card-group .info .desc { margin-top: 4px !important; } /* 代码块颜色 */ figure.highlight pre .addition { color: #00bf03 !important; }"}],"posts":[{"title":"MySQL[十四]redo日志","slug":"MySQL/MySQL[十四]redo日志","date":"2022-01-11T03:17:34.284Z","updated":"2022-01-11T03:25:35.265Z","comments":true,"path":"2022/01/11/MySQL/MySQL[十四]redo日志/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E5%8D%81%E5%9B%9B]redo%E6%97%A5%E5%BF%97/","excerpt":"","text":"一，什么是redo日志InnoDB存储引擎是以页为单位来管理存储空间的，我们的CRUD操作其实都是在访问页面。在真正访问页面之前，需要把磁盘中的页加载到内存的BufferPool，之后才能访问，但是因为事务要保持持久性，如果我们仅仅在内存的缓冲池修改了页面，假设事务提交后突然发生故障，导致内存的数据都消失了，那么这个已经提交的事务在数据库做的更改就丢失了。 如何保证持久性呢？可以在事务提交完成之前，把事务修改的所有页面都刷新到磁盘。不过这样做存在一些问题： 刷新一个完整的数据页过于浪费 随机IO效率比较低 事实上仅仅是为了保证事务的持久性，没有必要每次提交事务的时候就把该事务在内存修改过的全部页面刷新到磁盘，只需要把修改的内容记录一下就好，这样在事务提交的时候，就会把这个记录刷新到磁盘。即使系统因为崩溃而重启只需要按照记录的内容重新更新数据页即可恢复数据，上述记录修改的内容就叫做重做日志（redo log）。 相比于在事务提交的时候将所有修改过的内存中的页面刷新到磁盘，重做日志有以下好处： redo日志占用空间小：在存储表空间ID，页号，偏移量以及需要更新的值时，需要的存储空间很小。 redo日志是顺序写入磁盘的：在执行事务过程中，每执行一条语句，就可能产生若干条redo日志，这些日志是按照产生的顺序写入磁盘的，也就是使用顺序IO。 二，redo日志格式重做日志本质上仅仅是记录了一下事务对数据库进行了哪些修改。针对事务对数据库的不同修改场景MySQL定义了很多种重做日志，但是大部分类型的重做日志都有以下的通用结构。 type 重做日志的类型 space ID 表空间ID page number 页号 Data 日志的具体内容 1. 简单的redo日志类型行格式里面有一个隐藏列叫做row_id。为row_id进行赋值的方式如下： 服务器会在内存中维护一个全局变量，每当像某个包含row_id隐藏列的表插入一条记录的时候，就会把这个全局变量的值当做新记录row_id的值，并且把这个全局变量自增1。 每当这个全局变量的值是256的整数倍的时候，就会把这个变量的值刷新到系统表空间页号为7的页面中一个叫做Max Row ID的属性中。 当系统启动的时候，会将Max Row ID属性加载到内存，并把这个值加上256之后赋值给前面提到的全局变量。 这个Max Row ID占用的存储空间是8字节。当某个事务向某个包含row_id的表插入一条记录并且该记录分配的row_id值为256的整数倍的时候，就会像系统表空间页号为7的页面的相应偏移量处写入8字节的值。但是这个写入操作实际上是在内存缓冲区完成的，我们需要把这次修改以redo日志的形式记录下来，这样在事务提交之后，即使系统崩溃，也可以将该页面恢复成崩溃前的状态。在这种对页面的修改特别简单的时候，重做日志仅仅需要记录一下在某个页面的某个偏移量处修改了几个字节的值，具体修改后的内容是什么就可以了。这也叫做物理日志。 offset表示页面中的偏移量。如果写入的是字节序列类型的重做日志，还需要有一个len属性记录实际写入的长度。 2.复杂的redo日志类型有时候执行一条语句会修改非常多的页面，包括系统数据页面和用户数据页面（用户数据指的就是聚簇索引和二级索引对应的B+树）。 这时我们如果使用简单的物理redo日志来记录这些修改时，可以有两种解决方案： 方案一：在每个修改的地方都记录一条redo日志。也就是有多少个修改的记录，就写多少条物理redo日志。这样子记录redo日志的缺点是显而易见的，因为被修改的地方是在太多了，可能记录的redo日志占用的空间都比整个页面占用的空间都多。 方案二：将整个页面的第一个被修改的字节到最后一个修改的字节之间所有的数据当成是一条物理redo日志中的具体数据。第一个被修改的字节到最后一个修改的字节之间仍然有许多没有修改过的数据，我们把这些没有修改的数据也加入到redo日志中太浪费了。 正因为上述两种使用物理redo日志的方式来记录某个页面中做了哪些修改比较浪费，InnoDB提出了一些新的redo日志类型。 这些类型的redo日志既包含物理层面的意思，也包含逻辑层面的意思，具体指： 物理层面看，这些日志都指明了对哪个表空间的哪个页进行了修改。 逻辑层面看，在系统崩溃重启时，并不能直接根据这些日志里的记载，将页面内的某个偏移量处恢复成某个数据，而是需要调用一些事先准备好的函数，执行完这些函数后才可以将页面恢复成系统崩溃前的样子。 这个类型为MLOG_COMP_REC_INSERT的redo日志并没有记录PAGE_N_DIR_SLOTS的值修改为了什么，PAGE_HEAP_TOP的值修改为了什么，PAGE_N_HEAP的值修改为了什么等等这些信息，而只是把在本页面中插入一条记录所有必备的要素记了下来，之后系统崩溃重启时，服务器会调用相关向某个页面插入一条记录的那个函数，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数，在调用完该函数后，页面中的PAGE_N_DIR_SLOTS、PAGE_HEAP_TOP、PAGE_N_HEAP等等的值也就都被恢复到系统崩溃前的样子了。这就是所谓的逻辑日志的意思。 日志格式说了一堆核心其实就是：重做日志会把事务执行过程中对数据库所做的所有修改都记录下来，在之后系统因为崩溃而重启后可以把事务所做的任何修改都恢复过来。 为了节省重做日志占用的空间大小，InnoDB还对重做日志中的某些数据进行了压缩处理，比如表空间ID&amp;page number 一般占用4字节来存储，但是经过压缩之后占用的空间就更小了。 三，Mini-Transcation1.以组的形式写入redo日志语句在执行过程中可能修改若干个页面。比如我们前边说的一条INSERT语句可能修改系统表空间页号为7的页面的Max Row ID属性（当然也可能更新别的系统页面，只不过我们没有都列举出来而已），还会更新聚簇索引和二级索引对应B+树中的页面。由于对这些页面的更改都发生在Buffer Pool中，所以在修改完页面之后，需要记录一下相应的redo日志。在执行语句的过程中产生的redo日志被InnoDB人为的划分成了若干个不可分割的组，比如： 更新Max Row ID属性时产生的redo日志是不可分割的。 向聚簇索引对应B+树的页面中插入一条记录时产生的redo日志是不可分割的。 向某个二级索引对应B+树的页面中插入一条记录时产生的redo日志是不可分割的。 还有其他的一些对页面的访问操作时产生的redo日志是不可分割的。。。 怎么理解这个不可分割的意思呢？我们以向某个索引对应的B+树插入一条记录为例，在向B+树中插入这条记录之前，需要先定位到这条记录应该被插入到哪个叶子节点代表的数据页中，定位到具体的数据页之后，有两种可能的情况： 情况一：该数据页的剩余的空闲空间充足，足够容纳这一条待插入记录，那么事情很简单，直接把记录插入到这个数据页中，记录一条类型为MLOG_COMP_REC_INSERT的redo日志就好了，我们把这种情况称之为乐观插入。假如某个索引对应的B+树长这样：现在我们要插入一条键值为10的记录，很显然需要被插入到页b中，由于页b现在有足够的空间容纳一条记录，所以直接将该记录插入到页b中就好了，就像这样： 情况二：该数据页剩余的空闲空间不足，那么事情就悲剧了，我们前边说过，遇到这种情况要进行所谓的页分裂操作，也就是新建一个叶子节点，然后把原先数据页中的一部分记录复制到这个新的数据页中，然后再把记录插入进去，把这个叶子节点插入到叶子节点链表中，最后还要在内节点中添加一条目录项记录指向这个新创建的页面。很显然，这个过程要对多个页面进行修改，也就意味着会产生多条redo日志，我们把这种情况称之为悲观插入。假如某个索引对应的B+树长这样：现在我们要插入一条键值为10的记录，很显然需要被插入到页b中，但是从图中也可以看出来，此时页b已经塞满了记录，没有更多的空闲空间来容纳这条新记录了，所以我们需要进行页面的分裂操作，就像这样：如果作为内节点的页a的剩余空闲空间也不足以容纳增加一条目录项记录，那需要继续做内节点页a的分裂操作，也就意味着会修改更多的页面，从而产生更多的redo日志。另外，对于悲观插入来说，由于需要新申请数据页，还需要改动一些系统页面，比方说要修改各种段、区的统计信息信息，各种链表的统计信息（比如什么FREE链表、FSP_FREE_FRAG链表等，我们在介绍表空间那一篇中介绍过的各种东西），反正总共需要记录的redo日志有二、三十条。 其实不光是悲观插入一条记录会生成许多条redo日志，InnoDB为了其他的一些功能，在乐观插入时也可能产生多条redo日志。 InnoDB认为向某个索引对应的B+树中插入一条记录的这个过程必须是原子的，不能说插了一半之后就停止了。比方说在悲观插入过程中，新的页面已经分配好了，数据也复制过去了，新的记录也插入到页面中了，可是没有向内节点中插入一条目录项记录，这个插入过程就是不完整的，这样会形成一棵不正确的B+树。我们知道redo日志是为了在系统崩溃重启时恢复崩溃前的状态，如果在悲观插入的过程中只记录了一部分redo日志，那么在系统崩溃重启时会将索引对应的B+树恢复成一种不正确的状态，这是InnoDB所不能忍受的。所以他们规定在执行这些需要保证原子性的操作时必须以组的形式来记录的redo日志，在进行系统崩溃重启恢复时，针对某个组中的redo日志，要么把全部的日志都恢复掉，要么一条也不恢复。怎么做到的呢？这得分情况讨论： 有的需要保证原子性的操作会生成多条redo日志，比如向某个索引对应的B+树中进行一次悲观插入就需要生成许多条redo日志。如何把这些redo日志划分到一个组里边儿呢？InnoDB做了一个很简单的操作，就是在该组中的最后一条redo日志后边加上一条特殊类型的redo日志，该类型名称为MLOG_MULTI_REC_END，type字段对应的十进制数字为31，该类型的redo日志结构很简单，只有一个type字段：所以某个需要保证原子性的操作产生的一系列redo日志必须要以一个类型为MLOG_MULTI_REC_END结尾，就像这样：这样在系统崩溃重启进行恢复时，只有当解析到类型为MLOG_MULTI_REC_END的redo日志，才认为解析到了一组完整的redo日志，才会进行恢复。否则的话直接放弃前边解析到的redo日志。 有的需要保证原子性的操作只生成一条redo日志，比如更新Max Row ID属性的操作就只会生成一条redo日志。其实在一条日志后边跟一个类型为MLOG_MULTI_REC_END的redo日志也是可以的，InnoDB不想浪费一个比特位。虽然redo日志的类型比较多，但撑死了也就是几十种，是小于127这个数字的，也就是说我们用7个比特位就足以包括所有的redo日志类型，而type字段其实是占用1个字节的，也就是说我们可以省出来一个比特位用来表示该需要保证原子性的操作只产生单一的一条redo日志，示意图如下：如果type字段的第一个比特位为1，代表该需要保证原子性的操作只产生了单一的一条redo日志，否则表示该需要保证原子性的操作产生了一系列的redo日志。 2.Mini-TransactionMySQL把对底层页面中的一次原子访问的过程称之为一个Mini-Transaction，简称mtr，比如上边所说的修改一次Max Row ID的值算是一个Mini-Transaction，向某个索引对应的B+树中插入一条记录的过程也算是一个Mini-Transaction。一个所谓的mtr可以包含一组redo日志，在进行崩溃恢复时这一组redo日志作为一个不可分割的整体。 一个事务可以包含若干条语句，每一条语句其实是由若干个mtr组成，每一个mtr又可以包含若干条redo日志，画个图表示它们的关系就是这样： 四，redo日志的写入过程1.redo log blockInnoDB为了更好的进行系统崩溃恢复，他们把通过mtr生成的redo日志都放在了大小为512字节的页中。为了和表空间中的页做区别，我们这里把用来存储redo日志的页称为block。一个redo log block的示意图如下： 真正的redo日志都是存储到占用496字节大小的log block body中，图中的log block header和log block trailer存储的是一些管理信息。 其中log block header的几个属性的意思分别如下： LOG_BLOCK_HDR_NO：每一个block都有一个大于0的唯一标号，本属性就表示该标号值。 LOG_BLOCK_HDR_DATA_LEN：表示block中已经使用了多少字节，初始值为12（因为log block body从第12个字节处开始）。随着往block中写入的redo日志越来也多，本属性值也跟着增长。如果log block body已经被全部写满，那么本属性的值被设置为512。 LOG_BLOCK_FIRST_REC_GROUP：一条redo日志也可以称之为一条redo日志记录（redo log record），一个mtr会生产多条redo日志记录，这些redo日志记录被称之为一个redo日志记录组（redo log record group）。LOG_BLOCK_FIRST_REC_GROUP就代表该block中第一个mtr生成的redo日志记录组的偏移量（其实也就是这个block里第一个mtr生成的第一条redo日志的偏移量）。 LOG_BLOCK_CHECKPOINT_NO：表示所谓的checkpoint的序号，checkpoint是我们后续内容的重点，现在先不用清楚它的意思，稍安勿躁。 log block trailer中属性的意思如下： LOG_BLOCK_CHECKSUM：表示block的校验值，用于正确性校验，我们暂时不关心它。 2.redo 日志缓冲区InnoDB为了解决磁盘速度过慢的问题而引入了Buffer Pool。同理，写入redo日志时也不能直接直接写到磁盘上，实际上在服务器启动时就向操作系统申请了一大片称之为redo log buffer的连续内存空间，翻译成中文就是redo日志缓冲区，也可以简称为log buffer。这片内存空间被划分成若干个连续的redo log block，就像这样： 我们可以通过启动参数innodb_log_buffer_size来指定log buffer的大小，在MySQL 5.7.21这个版本中，该启动参数的默认值为16MB。 3.redo log 日志写入log buffer向log buffer中写入redo日志的过程是顺序的，也就是先往前边的block中写，当该block的空闲空间用完之后再往下一个block中写。当我们想往log buffer中写入redo日志时，第一个遇到的问题就是应该写在哪个block的哪个偏移量处，所以InnoDB特意提供了一个称之为buf_free的全局变量，该变量指明后续写入的redo日志应该写入到log buffer中的哪个位置，如图所示： 一个mtr执行过程中可能产生若干条redo日志，这些redo日志是一个不可分割的组，所以其实并不是每生成一条redo日志，就将其插入到log buffer中，而是每个mtr运行过程中产生的日志先暂时存到一个地方，当该mtr结束的时候，将过程中产生的一组redo日志再全部复制到log buffer中。我们现在假设有两个名为T1、T2的事务，每个事务都包含2个mtr，我们给这几个mtr命名一下： 事务T1的两个mtr分别称为mtr_T1_1和mtr_T1_2。 事务T2的两个mtr分别称为mtr_T2_1和mtr_T2_2。 每个mtr都会产生一组redo日志，不同的事务可能是并发执行的，所以T1、T2之间的mtr可能是交替执行的。每当一个mtr执行完成时，伴随该mtr生成的一组redo日志就需要被复制到log buffer中，也就是说不同事务的mtr可能是交替写入log buffer的，我们画个示意图（为了美观，我们把一个mtr中产生的所有的redo日志当作一个整体来画）： 从示意图中我们可以看出来，不同的mtr产生的一组redo日志占用的存储空间可能不一样，有的mtr产生的redo日志量很少，比如mtr_t1_1、mtr_t2_1就被放到同一个block中存储，有的mtr产生的redo日志量非常大，比如mtr_t1_2产生的redo日志甚至占用了3个block来存储。 五，redo 日志文件1.redo日志刷盘时机mtr运行过程中产生的一组redo日志在mtr结束时会被复制到log buffer中，在一些情况下它们会被刷新到磁盘里，比如： log buffer空间不足时log buffer的大小是有限的（通过系统变量innodb_log_buffer_size指定），如果不停的往这个有限大小的log buffer里塞入日志，很快它就会被填满。InnoDB认为如果当前写入log buffer的redo日志量已经占满了log buffer总容量的大约一半左右，就需要把这些日志刷新到磁盘上。 事务提交时之所以使用redo日志主要是因为它占用的空间少，还是顺序写，在事务提交时可以不把修改过的Buffer Pool页面刷新到磁盘，但是为了保证持久性，必须要把修改这些页面对应的redo日志刷新到磁盘。 将某个脏页刷新到磁盘前，会保证先将该脏页对应的 redo 日志刷新到磁盘中（再一次 强调，redo 日志是顺序刷新的，所以在将某个脏页对应的 redo 日志从 redo log buffer 刷新到磁盘时，也会保证将在其之前产生的 redo 日志也刷新到磁盘）。 后台线程不停的刷后台有一个线程，大约每秒都会刷新一次log buffer中的redo日志到磁盘。 正常关闭服务器时 做所谓的checkpoint时 其他的一些情况… 2.redo日志文件组MySQL的数据目录（使用SHOW VARIABLES LIKE &#39;datadir&#39;查看）下默认有两个名为ib_logfile0和ib_logfile1的文件，log buffer中的日志默认情况下就是刷新到这两个磁盘文件中。如果我们对默认的redo日志文件不满意，可以通过下边几个启动参数来调节： innodb_log_group_home_dir该参数指定了redo日志文件所在的目录，默认值就是当前的数据目录。 innodb_log_file_size该参数指定了每个redo日志文件的大小，在MySQL 5.7.21这个版本中的默认值为48MB， innodb_log_files_in_group该参数指定redo日志文件的个数，默认值为2，最大值为100。 磁盘上的redo日志文件不只一个，而是以一个日志文件组的形式出现的。这些文件以ib_logfile[数字]（数字可以是0、1、2…）的形式进行命名。在将redo日志写入日志文件组时，是从ib_logfile0开始写，如果ib_logfile0写满了，就接着ib_logfile1写，同理，ib_logfile1写满了就去写ib_logfile2，依此类推。如果写到最后一个文件该咋办？那就重新转到ib_logfile0继续写，所以整个过程如下图所示： 总共的redo日志文件大小其实就是：innodb_log_file_size × innodb_log_files_in_group。 如果采用循环使用的方式向redo日志文件组里写数据的话，那岂不是要追尾，也就是后写入的redo日志覆盖掉前边写的redo日志？当然可能了！所以InnoDB提出了checkpoint的概念。 3.redo日志文件格式log buffer本质上是一片连续的内存空间，被划分成了若干个512字节大小的block。将log buffer中的redo日志刷新到磁盘的本质就是把block的镜像写入日志文件中，所以redo日志文件其实也是由若干个512字节大小的block组成。 redo日志文件组中的每个文件大小都一样，格式也一样，都是由两部分组成： 前2048个字节，也就是前4个block是用来存储一些管理信息的。 从第2048字节往后是用来存储log buffer中的block镜像的。 所以我们前边所说的循环使用redo日志文件，其实是从每个日志文件的第2048个字节开始算，画个示意图就是这样： 普通block的格式我们在了解log buffer的时候都说过了，就是log block header、log block body、log block trialer这三个部分。这里需要介绍一下每个redo日志文件前2048个字节，也就是前4个特殊block的格式都是什么作用。 从图中可以看出来，这4个block分别是： log file header：描述该redo日志文件的一些整体属性各个属性的具体释义如下： 属性名 长度（单位：字节） 描述 LOG_HEADER_FORMAT 4 redo日志的版本，在MySQL 5.7.21中该值永远为1 LOG_HEADER_PAD1 4 做字节填充用的，没什么实际意义，忽略～ LOG_HEADER_START_LSN 8 标记本redo日志文件开始的LSN值，也就是文件偏移量为2048字节初对应的LSN值。 LOG_HEADER_CREATOR 32 一个字符串，标记本redo日志文件的创建者是谁。正常运行时该值为MySQL的版本号，比如：&quot;MySQL 5.7.21&quot;，使用mysqlbackup命令创建的redo日志文件的该值为&quot;ibbackup&quot;和创建时间。 LOG_BLOCK_CHECKSUM 4 本block的校验值，所有block都有，我们不关心 checkpoint1：记录关于checkpoint的一些属性，看一下它的结构：各个属性的具体释义如下： 属性名 长度（单位：字节） 描述 LOG_CHECKPOINT_NO 8 服务器做checkpoint的编号，每做一次checkpoint，该值就加1。 LOG_CHECKPOINT_LSN 8 服务器做checkpoint结束时对应的LSN值，系统崩溃恢复时将从该值开始。 LOG_CHECKPOINT_OFFSET 8 上个属性中的LSN值在redo日志文件组中的偏移量 LOG_CHECKPOINT_LOG_BUF_SIZE 8 服务器在做checkpoint操作时对应的log buffer的大小 LOG_BLOCK_CHECKSUM 4 本block的校验值，所有block都有，我们不关心 第三个block未使用，忽略 checkpoint2：结构和checkpoint1一样。 六，Log Sequence Number自系统开始运行，就不断的在修改页面，也就意味着会不断的生成redo日志。redo日志的量在不断的递增。InnoDB为记录已经写入的redo日志量，设计了一个称之为Log Sequence Number的全局变量，翻译过来就是：日志序列号，简称lsn。InnoDB规定初始的lsn值为8704（也就是一条redo日志也没写入时，lsn的值为8704）。 在向log buffer中写入redo日志时不是一条一条写入的，而是以一个mtr生成的一组redo日志为单位进行写入的。而且实际上是把日志内容写在了log block body处。但是在统计lsn的增长量时，是按照实际写入的日志量加上占用的log block header和log block trailer来计算的。我们来看一个例子： 系统第一次启动后初始化log buffer时，buf_free（就是标记下一条redo日志应该写入到log buffer的位置的变量）就会指向第一个block的偏移量为12字节（log block header的大小）的地方，那么lsn值也会跟着增加12： 如果某个mtr产生的一组redo日志占用的存储空间比较小，也就是待插入的block剩余空闲空间能容纳这个mtr提交的日志时，lsn增长的量就是该mtr生成的redo日志占用的字节数，就像这样：我们假设上图中mtr_1产生的redo日志量为200字节，那么lsn就要在8716的基础上增加200，变为8916。 如果某个mtr产生的一组redo日志占用的存储空间比较大，也就是待插入的block剩余空闲空间不足以容纳这个mtr提交的日志时，lsn增长的量就是该mtr生成的redo日志占用的字节数加上额外占用的log block header和log block trailer的字节数，就像这样：我们假设上图中mtr_2产生的redo日志量为1000字节，为了将mtr_2产生的redo日志写入log buffer，我们不得不额外多分配两个block，所以lsn的值需要在8916的基础上增加1000 + 12×2 + 4 × 2 = 1032。 从上边的描述中可以看出来，每一组由mtr生成的redo日志都有一个唯一的LSN值与其对应，LSN值越小，说明redo日志产生的越早。 1.flushed_to_disk_lsnredo日志是首先写到log buffer中，之后才会被刷新到磁盘上的redo日志文件。所以InnoDB提出了一个称之为buf_next_to_write的全局变量，标记当前log buffer中已经有哪些日志被刷新到磁盘中了。画个图表示就是这样： lsn是表示当前系统中写入的redo日志量，这包括了写到log buffer而没有刷新到磁盘的日志，相应的，InnoDB提出了一个表示刷新到磁盘中的redo日志量的全局变量，称之为flushed_to_disk_lsn。系统第一次启动时，该变量的值和初始的lsn值是相同的，都是8704。随着系统的运行，redo日志被不断写入log buffer，但是并不会立即刷新到磁盘，lsn的值就和flushed_to_disk_lsn的值拉开了差距。我们推理一下： 系统第一次启动后，向log buffer中写入了mtr_1、mtr_2、mtr_3这三个mtr产生的redo日志，假设这三个mtr开始和结束时对应的lsn值分别是： mtr_1：8716 ～ 8916 mtr_2：8916 ～ 9948 mtr_3：9948 ～ 10000 此时的lsn已经增长到了10000，但是由于没有刷新操作，所以此时flushed_to_disk_lsn的值仍为8704，如图： 随后进行将log buffer中的block刷新到redo日志文件的操作，假设将mtr_1和mtr_2的日志刷新到磁盘，那么flushed_to_disk_lsn就应该增长mtr_1和mtr_2写入的日志量，所以flushed_to_disk_lsn的值增长到了9948，如图： 综上所述，当有新的redo日志写入到log buffer时，首先lsn的值会增长，但flushed_to_disk_lsn不变，随后随着不断有log buffer中的日志被刷新到磁盘上，flushed_to_disk_lsn的值也跟着增长。如果两者的值相同时，说明log buffer中的所有redo日志都已经刷新到磁盘中了。 应用程序向磁盘写入文件时其实是先写到操作系统的缓冲区中去，如果某个写入操作要等到操作系统确认已经写到磁盘时才返回，那需要调用一下操作系统提供的fsync函数。其实只有当系统执行了fsync函数后，flushed_to_disk_lsn的值才会跟着增长，当仅仅把log buffer中的日志写入到操作系统缓冲区却没有显式的刷新到磁盘时，另外的一个称之为write_lsn的值跟着增长。 2.lsn值和redo日志文件偏移量的对应关系因为lsn的值是代表系统写入的redo日志量的一个总和，一个mtr中产生多少日志，lsn的值就增加多少（当然有时候要加上log block header和log block trailer的大小），这样mtr产生的日志写到磁盘中时，很容易计算某一个lsn值在redo日志文件组中的偏移量，如图： 初始时的LSN值是8704，对应文件偏移量2048，之后每个mtr向磁盘中写入多少字节日志，lsn的值就增长多少。 3.flush链表中的LSN一个mtr代表一次对底层页面的原子访问，在访问过程中可能会产生一组不可分割的redo日志，在mtr结束时，会把这一组redo日志写入到log buffer中。除此之外，在mtr结束时还有一件非常重要的事情要做，就是把在mtr执行过程中可能修改过的页面加入到Buffer Pool的flush链表。 当第一次修改某个缓存在Buffer Pool中的页面时，就会把这个页面对应的控制块插入到flush链表的头部，之后再修改该页面时由于它已经在flush链表中了，就不再次插入了。也就是说flush链表中的脏页是按照页面的第一次修改时间从大到小进行排序的。在这个过程中会在缓存页对应的控制块中记录两个关于页面何时修改的属性： oldest_modification：如果某个页面被加载到Buffer Pool后进行第一次修改，那么就将修改该页面的mtr开始时对应的lsn值写入这个属性。 newest_modification：每修改一次页面，都会将修改该页面的mtr结束时对应的lsn值写入这个属性。也就是说该属性表示页面最近一次修改后对应的系统lsn值。 接着上边flushed_to_disk_lsn的例子看一下： 假设mtr_1执行过程中修改了页a，那么在mtr_1执行结束时，就会将页a对应的控制块加入到flush链表的头部。并且将mtr_1开始时对应的lsn，也就是8716写入页a对应的控制块的oldest_modification属性中，把mtr_1结束时对应的lsn，也就是8916写入页a对应的控制块的newest_modification属性中。画个图表示一下（oldest_modification缩写成了o_m，newest_modification缩写成了n_m）： 接着假设mtr_2执行过程中又修改了页b和页c两个页面，那么在mtr_2执行结束时，就会将页b和页c对应的控制块都加入到flush链表的头部。并且将mtr_2开始时对应的lsn，也就是8916写入页b和页c对应的控制块的oldest_modification属性中，把mtr_2结束时对应的lsn，也就是9948写入页b和页c对应的控制块的newest_modification属性中。画个图表示一下：从图中可以看出来，每次新插入到flush链表中的节点都是被放在了头部，也就是说flush链表中前边的脏页修改的时间比较晚，后边的脏页修改时间比较早。 接着假设mtr_3执行过程中修改了页b和页d，不过页b之前已经被修改过了，所以它对应的控制块已经被插入到了flush链表，所以在mtr_3执行结束时，只需要将页d对应的控制块都加入到flush链表的头部即可。所以需要将mtr_3开始时对应的lsn，也就是9948写入页d对应的控制块的oldest_modification属性中，把mtr_3结束时对应的lsn，也就是10000写入页d对应的控制块的newest_modification属性中。另外，由于页b在mtr_3执行过程中又发生了一次修改，所以需要更新页b对应的控制块中newest_modification的值为10000。画个图表示一下： 总结一下上边说的，就是：flush链表中的脏页按照修改发生的时间顺序进行排序，也就是按照oldest_modification代表的LSN值进行排序，被多次更新的页面不会重复插入到flush链表中，但是会更新newest_modification属性的值。 七，checkpointredo日志文件组容量是有限的，我们不得不选择循环使用redo日志文件组中的文件，但是这会造成最后写的redo日志与最开始写的redo日志追尾，这时应该想到：redo日志只是为了系统崩溃后恢复脏页用的，如果对应的脏页已经刷新到了磁盘，也就是说即使现在系统崩溃，那么在重启后也用不着使用redo日志恢复该页面了，所以该redo日志也就没有存在的必要了，那么它占用的磁盘空间就可以被后续的redo日志所重用。也就是说：判断某些redo日志占用的磁盘空间是否可以覆盖的依据就是它对应的脏页是否已经刷新到磁盘里。我们看一下前边的那个例子： 如图，虽然mtr_1和mtr_2生成的redo日志都已经被写到了磁盘上，但是它们修改的脏页仍然留在Buffer Pool中，所以它们生成的redo日志在磁盘上的空间是不可以被覆盖的。之后随着系统的运行，如果页a被刷新到了磁盘，那么它对应的控制块就会从flush链表中移除，就像这样子： 这样mtr_1生成的redo日志就没有用了，它们占用的磁盘空间就可以被覆盖掉了。InnoDB提出了一个全局变量checkpoint_lsn来代表当前系统中可以被覆盖的redo日志总量是多少，这个变量初始值也是8704。 比方说现在页a被刷新到了磁盘，mtr_1生成的redo日志就可以被覆盖了，所以我们可以进行一个增加checkpoint_lsn的操作，我们把这个过程称之为做一次checkpoint。做一次checkpoint其实可以分为两个步骤： 步骤一：计算一下当前系统中可以被覆盖的redo日志对应的lsn值最大是多少。redo日志可以被覆盖，意味着它对应的脏页被刷到了磁盘，只要我们计算出当前系统中被最早修改的脏页对应的oldest_modification值，那凡是在系统lsn值小于该节点的oldest_modification值时产生的redo日志都是可以被覆盖掉的，我们就把该脏页的oldest_modification赋值给checkpoint_lsn。比方说当前系统中页a已经被刷新到磁盘，那么flush链表的尾节点就是页c，该节点就是当前系统中最早修改的脏页了，它的oldest_modification值为8916，我们就把8916赋值给checkpoint_lsn（也就是说在redo日志对应的lsn值小于8916时就可以被覆盖掉）。 步骤二：将checkpoint_lsn和对应的redo日志文件组偏移量以及此次checkpint的编号写到日志文件的管理信息（就是checkpoint1或者checkpoint2）中。InnoDB维护了一个目前系统做了多少次checkpoint的变量checkpoint_no，每做一次checkpoint，该变量的值就加1。我们前边说过计算一个lsn值对应的redo日志文件组偏移量是很容易的，所以可以计算得到该checkpoint_lsn在redo日志文件组中对应的偏移量checkpoint_offset，然后把这三个值都写到redo日志文件组的管理信息中。我们说过，每一个redo日志文件都有2048个字节的管理信息，但是上述关于checkpoint的信息只会被写到日志文件组的第一个日志文件的管理信息中。不过我们是存储到checkpoint1中还是checkpoint2中呢？InnoDB规定，当checkpoint_no的值是偶数时，就写到checkpoint1中，是奇数时，就写到checkpoint2中。 记录完checkpoint的信息之后，redo日志文件组中各个lsn值的关系就像这样： 1.批量从flush链表中刷出脏页一般情况下都是后台的线程在对LRU链表和flush链表进行刷脏操作，这主要因为刷脏操作比较慢，不想影响用户线程处理请求。但是如果当前系统修改页面的操作十分频繁，这样就导致写日志操作十分频繁，系统lsn值增长过快。如果后台的刷脏操作不能将脏页刷出，那么系统无法及时做checkpoint，可能就需要用户线程同步的从flush链表中把那些最早修改的脏页（oldest_modification最小的脏页）刷新到磁盘，这样这些脏页对应的redo日志就没用了，然后就可以去做checkpoint了。 2.查看系统中的各种LSN值我们可以使用SHOW ENGINE INNODB STATUS命令查看当前InnoDB存储引擎中的各种LSN值的情况，比如： 12345678910111213mysql&gt; SHOW ENGINE INNODB STATUS\\G(...省略前边的许多状态)LOG---Log sequence number 124476971Log flushed up to 124099769Pages flushed up to 124052503Last checkpoint at 1240524940 pending log flushes, 0 pending chkp writes24 log i/o&#x27;s done, 2.00 log i/o&#x27;s/second----------------------(...省略后边的许多状态) 其中： Log sequence number：代表系统中的lsn值，也就是当前系统已经写入的redo日志量，包括写入log buffer中的日志。 Log flushed up to：代表flushed_to_disk_lsn的值，也就是当前系统已经写入磁盘的redo日志量。 Pages flushed up to：代表flush链表中被最早修改的那个页面对应的oldest_modification属性值。 Last checkpoint at：当前系统的checkpoint_lsn值。 3.innodb_flush_log_at_trx_commit的用法为了保证事务的持久性，用户线程在事务提交时需要将该事务执行过程中产生的所有redo日志都刷新到磁盘上。这一条要求太狠了，会很明显的降低数据库性能。如果对事务的持久性要求不是那么强烈的话，可以选择修改一个称为innodb_flush_log_at_trx_commit的系统变量的值，该变量有3个可选的值： 0：当该系统变量值为0时，表示在事务提交时不立即向磁盘中同步redo日志，这个任务是交给后台线程做的。这样很明显会加快请求处理速度，但是如果事务提交后服务器挂了，后台线程没有及时将redo日志刷新到磁盘，那么该事务对页面的修改会丢失。 1：当该系统变量值为1时，表示在事务提交时需要将redo日志同步到磁盘，可以保证事务的持久性。1也是innodb_flush_log_at_trx_commit的默认值。 2：当该系统变量值为2时，表示在事务提交时需要将redo日志写到操作系统的缓冲区中，但并不需要保证将日志真正的刷新到磁盘。这种情况下如果数据库挂了，操作系统没挂的话，事务的持久性还是可以保证的，但是操作系统也挂了的话，那就不能保证持久性了。 八，崩溃恢复在服务器不挂的情况下，redo日志不仅没用，反而让性能变得更差。但是万一数据库挂了，我们就可以在重启时根据redo日志中的记录就可以将页面恢复到系统崩溃前的状态。我们接下来大致看一下恢复过程。 1.确定恢复的起点checkpoint_lsn之前的redo日志都可以被覆盖，也就是说这些redo日志对应的脏页都已经被刷新到磁盘中了，既然它们已经被刷盘，我们就没必要恢复它们了。对于checkpoint_lsn之后的redo日志，它们对应的脏页可能没被刷盘，也可能被刷盘了，我们不能确定，所以需要从checkpoint_lsn开始读取redo日志来恢复页面。 当然，redo日志文件组的第一个文件的管理信息中有两个block都存储了checkpoint_lsn的信息，我们当然是要选取最近发生的那次checkpoint的信息。衡量checkpoint发生时间早晚的信息就是所谓的checkpoint_no，只要把checkpoint1和checkpoint2这两个block中的checkpoint_no值读出来比一下大小，哪个的checkpoint_no值更大，说明哪个block存储的就是最近的一次checkpoint信息。这样我们就能拿到最近发生的checkpoint对应的checkpoint_lsn值以及它在redo日志文件组中的偏移量checkpoint_offset。 2.确定恢复的终点redo日志恢复的起点确定了，那终点是哪个呢？这个还得从block的结构说起。在写redo日志的时候都是顺序写的，写满了一个block之后会再往下一个block中写。 普通block的log block header部分有一个称之为LOG_BLOCK_HDR_DATA_LEN的属性，该属性值记录了当前block里使用了多少字节的空间。对于被填满的block来说，该值永远为512。如果该属性的值不为512，那么就是它了，它就是此次崩溃恢复中需要扫描的最后一个block。 3.怎么恢复确定了需要扫描哪些redo日志进行崩溃恢复之后，接下来就是怎么进行恢复了。假设现在的redo日志文件中有5条redo日志，如图： 由于redo 0在checkpoint_lsn后前边，恢复时可以不管它。现在可以按照redo日志的顺序依次扫描checkpoint_lsn之后的各条redo日志，按照日志中记载的内容将对应的页面恢复出来。这样没什么问题，不过InnoDB还是想了一些办法加快这个恢复的过程： 使用哈希表根据redo日志的space ID和page number属性计算出散列值，把space ID和page number相同的redo日志放到哈希表的同一个槽里，如果有多个space ID和page number都相同的redo日志，那么它们之间使用链表连接起来，按照生成的先后顺序链接起来的，如图所示：之后就可以遍历哈希表，因为对同一个页面进行修改的redo日志都放在了一个槽里，所以可以一次性将一个页面修复好（避免了很多读取页面的随机IO），这样可以加快恢复速度。另外需要注意一点的是，同一个页面的redo日志是按照生成时间顺序进行排序的，所以恢复的时候也是按照这个顺序进行恢复，如果不按照生成时间顺序进行排序的话，那么可能出现错误。比如原先的修改操作是先插入一条记录，再删除该条记录，如果恢复时不按照这个顺序来，就可能变成先删除一条记录，再插入一条记录，这显然是错误的。 跳过已经刷新到磁盘的页面checkpoint_lsn之前的redo日志对应的脏页确定都已经刷到磁盘了，但是checkpoint_lsn之后的redo日志我们不能确定是否已经刷到磁盘，主要是因为在最近做的一次checkpoint后，可能后台线程又不断的从LRU链表和flush链表中将一些脏页刷出Buffer Pool。这些在checkpoint_lsn之后的redo日志，如果它们对应的脏页在崩溃发生时已经刷新到磁盘，那在恢复时也就没有必要根据redo日志的内容修改该页面了。那在恢复时怎么知道某个redo日志对应的脏页是否在崩溃发生时已经刷新到磁盘了呢？这还得从页面的结构说起，每个页面都有一个称之为File Header的部分，在File Header里有一个称之为FIL_PAGE_LSN的属性，该属性记载了最近一次修改页面时对应的lsn值（其实就是页面控制块中的newest_modification值）。如果在做了某次checkpoint之后有脏页被刷新到磁盘中，那么该页对应的FIL_PAGE_LSN代表的lsn值肯定大于checkpoint_lsn的值，凡是符合这种情况的页面就不需要重复执行lsn值小于FIL_PAGE_LSN的redo日志了，所以更进一步提升了崩溃恢复的速度。 九，LOG_BLOCK_HDR_NO是如何计算的对于实际存储redo日志的普通的log block来说，在log block header处有一个称之为LOG_BLOCK_HDR_NO的属性，我们说这个属性代表一个唯一的标号。这个属性是初次使用该block时分配的，跟当时的系统lsn值有关。使用下边的公式计算该block的LOG_BLOCK_HDR_NO值： 1((lsn / 512) &amp; 0x3FFFFFFFUL) + 1 从图中可以看出，0x3FFFFFFFUL对应的二进制数的前2位为0，后30位的值都为1。一个二进制位与0做与运算（&amp;）的结果肯定是0，一个二进制位与1做与运算（&amp;）的结果就是原值。让一个数和0x3FFFFFFFUL做与运算的意思就是要将该值的前2个比特位的值置为0，这样该值就肯定小于或等于0x3FFFFFFFUL了。这也就说明了，不论lsn多大，((lsn / 512) &amp; 0x3FFFFFFFUL)的值肯定在0``~~0x3FFFFFFFUL~~之间，再加1的话肯定在~~1~~``0x40000000UL之间。而0x40000000UL这个值就代表着1GB。也就是说系统最多能产生不重复的LOG_BLOCK_HDR_NO值只有1GB个。InnoDB规定redo日志文件组中包含的所有文件大小总和不得超过512GB，一个block大小是512字节，也就是说redo日志文件组中包含的block块最多为1GB个，所以有1GB个不重复的编号值也就够用了。 另外，LOG_BLOCK_HDR_NO值的第一个比特位比较特殊，称之为flush bit，如果该值为1，代表着本block是在某次将log buffer中的block刷新到磁盘的操作中的第一个被刷入的block。 十，double write​ 1.脏页刷盘风险​ 关于IO的最小单位： 数据库IO的最小单位是16K（MySQL默认，oracle是8K） 文件系统IO的最小单位是4K（也有1K的） 磁盘IO的最小单位是512字节 因此，存在IO写入导致page损坏的风险：​ ​​ 2.doublewrite：两次写提高innodb的可靠性，用来解决部分写失败(partial page write页断裂)。​ 2.1 Double write解决了什么问题​ 一个数据页的大小是16K，假设在把内存中的脏页写到数据库的时候，写了2K突然掉电，也就是说前2K数据是新的，后14K是旧的，那么磁盘数据库这个数据页就是不完整的，是一个坏掉的数据页。redo只能加上旧、校检完整的数据页恢复一个脏块，不能修复坏掉的数据页，所以这个数据就丢失了，可能会造成数据不一致，所以需要double write。​ 2.2使用情景​ 当数据库正在从内存想磁盘写一个数据页是，数据库宕机，从而导致这个页只写了部分数据，这就是部分写失效，它会导致数据丢失。这时是无法通过重做日志恢复的，因为重做日志记录的是对页的物理修改，如果页本身已经损坏，重做日志也无能为力。​ 2.3 double write工作流程 doublewrite由两部分组成，一部分为内存中的doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间(ibdata x)中连续的128个页，即2个区(extent)，大小也是2M。 当一系列机制触发数据缓冲池中的脏页刷新时，并不直接写入磁盘数据文件中，而是先拷贝至内存中的doublewrite buffer中； 接着从两次写缓冲区分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB； 待第二步完成后，再将doublewrite buffer中的脏页数据写入实际的各个表空间文件(离散写)；(脏页数据固化后，即进行标记对应doublewrite数据可覆盖) 2.4 doublewrite的崩溃恢复​ 如果操作系统在将页写入磁盘的过程中发生崩溃，在恢复过程中，innodb存储引擎可以从共享表空间的doublewrite中找到该页的一个最近的副本，将其复制到表空间文件，再应用redo log，就完成了恢复过程。因为有副本所以也不担心表空间中数据页是否损坏。 Q：为什么_log write_不需要_doublewrite_的支持？A：因为_redolog_写入的单位就是512字节，也就是磁盘IO的最小单位，所以无所谓数据损坏。 ​ 3.doublewrite的副作用3.1 double write带来的写负载 double write是一个buffer, 但其实它是开在物理文件上的一个buffer, 其实也就是file, 所以它会导致系统有更多的fsync操作, 而硬盘的fsync性能是很慢的, 所以它会降低mysql的整体性能。 但是，doublewrite buffer写入磁盘共享表空间这个过程是连续存储，是顺序写，性能非常高，(约占写的10%)，牺牲一点写性能来保证数据页的完整还是很有必要的。3.2 监控double write工作负载 12345678mysql&gt; show global status like &#x27;%dblwr%&#x27;;+----------------------------+-------+| Variable_name | Value |+----------------------------+-------+| Innodb_dblwr_pages_written | 7 || Innodb_dblwr_writes | 3 |+----------------------------+-------+2 rows in set (0.00 sec) 关注点：Innodb_dblwr_pages_written / Innodb_dblwr_writes​ 开启doublewrite后，每次脏页刷新必须要先写doublewrite，而doublewrite存在于磁盘上的是两个连续的区，每个区由连续的页组成，一般情况下一个区最多有64个页，所以一次IO写入应该可以最多写64个页。​ 而根据以上系统Innodb_dblwr_pages_written与Innodb_dblwr_writes的比例来看，大概在3左右，远远还没到64(如果约等于64，那么说明系统的写压力非常大，有大量的脏页要往磁盘上写)，所以从这个角度也可以看出，系统写入压力并不高。​ 3.3 关闭double write适合的场景 海量DML 不惧怕数据损坏和丢失 系统写负载成为主要负载1234567mysql&gt; show variables like &#x27;%double%&#x27;;+--------------------+-------+| Variable_name | Value |+--------------------+-------+| innodb_doublewrite | ON |+--------------------+-------+1 row in set (0.04 sec) 作为InnoDB的一个关键特性，doublewrite功能默认是开启的，但是在上述特殊的一些场景也可以视情况关闭，来提高数据库写性能。静态参数，配置文件修改，重启数据库。3.4 为什么没有把double write里面的数据写到data page里面呢？ double write里面的数据是连续的，如果直接写到data page里面，而data page的页又是离散的，写入会很慢。 double write里面的数据没有办法被及时的覆盖掉，导致double write的压力很大；短时间内可能会出现double write溢出的情况。十一，总结 redo日志记录了事务执行过程中都修改了哪些内容。 事务提交时只将执行过程中产生的redo日志刷新到磁盘，而不是将所有修改过的页面都刷新到磁盘。这样做有两个好处： redo日志占用的空间非常小 redo日志是顺序写入磁盘的 一条redo日志由下面几部分组成。 type：这条redo日志的类型 space ID:表空间ID page number :页号 data：这条redo日志的具体内容 redo日志的类型有简单和复杂之分。简单类型的redo日志是纯粹的物理日志，复杂类型的redo日志兼有物理日志和逻辑日志的特性。 一个MTR可以包含一组redo日志。在进行崩溃恢复时，这一组redo日志作为一个不可分割的整体来处理。 redo日志存放在大小为512字节的block中。每一个block被分为3部分： log block header log block body log block trailer redo日志缓冲区是一片连续的内存空间，由若干个block组成；可以通过启动选项innodb_log_buffer_size 来调整他的大小。 redo日志文件组由若干个日志文件组成，这些redo日志文件是被循环使用的。redo日志文件组中每个文件的大小都一样，格式也一样，都是由两部分组成的： 前2048字节用来存储一些管理信息 从第2048字节往后的字节用来存储log buffer中的block镜像 lsn指已经写入的redo日志量，flushed_to_disk_lsn指刷新到磁盘中的redo日志量，flush链表中的脏页按照修改发生的时间顺序进行排序，也就是按照oldest_modification代表的lsn值进行排序。被多次更新的页面不会重复插入到flush链表，但是会更新newest_modification属性的值。checkpoint_lsn表示当前系统中可以被覆盖的redo日志总量是多少。 redo日志占用的磁盘空间在他对应的脏页已经被刷新到磁盘后即可被覆盖。执行一次checkpoint的意思就是增加checkpoint_lsn的值，然后把相关信息放到日志文件的管理信息中。 innodb_flush_log_at_trx_commit系统变量控制着在事务提交时是否将该事务运行过程中产生的redo刷新到磁盘。 在崩溃恢复过程中，从redo日志文件组第一个文件的管理信息中取出最近发生的那次checkpoint信息，然后从checkpoint_lsn在日志文件组中对应的偏移量开始，一直扫描日志文件中的block，直到某个block的LOG_BLOCK_HDR_DATA_LEN值不等于512为止。再恢复过程中，使用hash表可加快恢复过程，并且会跳过已经刷新到磁盘的页面。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[十三]事务","slug":"MySQL/MySQL[十三]事务","date":"2022-01-11T03:17:20.893Z","updated":"2022-01-11T03:25:11.029Z","comments":true,"path":"2022/01/11/MySQL/MySQL[十三]事务/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E5%8D%81%E4%B8%89]%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"一，事务的起源1.原子性（Atomicity）现实世界中转账操作是一个不可分割的操作，也就是说要么压根儿就没转，要么转账成功，不能存在中间的状态，也就是转了一半的这种情况。设计数据库的大叔们把这种要么全做，要么全不做的规则称之为原子性。但是在现实世界中的一个不可分割的操作却可能对应着数据库世界若干条不同的操作，数据库中的一条操作也可能被分解成若干个步骤（比如先修改缓存页，之后再刷新到磁盘等），最要命的是在任何一个可能的时间都可能发生意想不到的错误（可能是数据库本身的错误，或者是操作系统错误，甚至是直接断电之类的）而使操作执行不下去。为了保证在数据库世界中某些操作的原子性，MySQL需要保证如果在执行操作的过程中发生了错误，把已经做了的操作恢复成没执行之前的样子。 2.隔离性（Isolation）现实世界中的两次状态转换应该是互不影响的，所以对于现实世界中状态转换对应的某些数据库操作来说，不仅要保证这些操作以原子性的方式执行完成，而且要保证其它的状态转换不会影响到本次状态转换，这个规则被称之为隔离性。这时MySQL就需要采取一些措施来让访问相同数据的不同状态转换对应的数据库操作的执行顺序有一定规律。 3.一致性（Consistency）我们生活的这个世界存在着形形色色的约束，比如身份证号不能重复，性别只能是男或者女，高考的分数只能在0～750之间，人民币面值最大只能是100（现在是2019年），红绿灯只有3种颜色，房价不能为负的。 只有符合这些约束的数据才是有效的。数据库世界只是现实世界的一个映射，现实世界中存在的约束当然也要在数据库世界中有所体现。如果数据库中的数据全部符合现实世界中的约束（all defined rules），我们说这些数据就是一致的，或者说符合一致性的。 如何保证数据库中数据的一致性（就是符合所有现实世界的约束）呢？这其实靠两方面的努力： 数据库本身能为我们保证一部分一致性需求（就是数据库自身可以保证一部分现实世界的约束永远有效）。我们知道MySQL数据库可以为表建立主键、唯一索引、外键、声明某个列为NOT NULL来拒绝NULL值的插入。比如说当我们对某个列建立唯一索引时，如果插入某条记录时该列的值重复了，那么MySQL就会报错并且拒绝插入。除了这些我们已经非常熟悉的保证一致性的功能，MySQL还支持CHECK语法来自定义约束，比如这样：上述例子中的CHECK语句本意是想规定balance列不能存储小于0的数字，对应的现实世界的意思就是银行账户余额不能小于0。但是很遗憾，MySQL仅仅支持CHECK语法，但实际上并没有一点卵用，也就是说即使我们使用上述带有CHECK子句的建表语句来创建account表，那么在后续插入或更新记录时，MySQL并不会去检查CHECK子句中的约束是否成立。虽然CHECK子句对一致性检查没什么卵用，但是我们还是可以通过定义触发器的方式来自定义一些约束条件以保证数据库中数据的一致性。 1234567CREATE TABLE account ( id INT NOT NULL AUTO_INCREMENT COMMENT &#x27;自增id&#x27;, name VARCHAR(100) COMMENT &#x27;客户名称&#x27;, balance INT COMMENT &#x27;余额&#x27;, PRIMARY KEY (id), CHECK (balance &gt;= 0) ); 其它的一些数据库，比如SQL Server或者Oracle支持的CHECK语法是有实实在在的作用的，每次进行插入或更新记录之前都会检查一下数据是否符合CHECK子句中指定的约束条件是否成立，如果不成立的话就会拒绝插入或更新。 更多的一致性需求需要靠写业务代码的程序员自己保证。为建立现实世界和数据库世界的对应关系，理论上应该把现实世界中的所有约束都反应到数据库世界中，但是在更改数据库数据时进行一致性检查是一个耗费性能的工作，比方说我们为account表建立了一个触发器，每当插入或者更新记录时都会校验一下balance列的值是不是大于0，这就会影响到插入或更新的速度。仅仅是校验一行记录符不符合一致性需求倒也不是什么大问题，有的一致性需求简直变态，比方说银行会建立一张代表账单的表，里边儿记录了每个账户的每笔交易，每一笔交易完成后，都需要保证整个系统的余额等于所有账户的收入减去所有账户的支出。如果在数据库层面实现这个一致性需求的话，每次发生交易时，都需要将所有的收入加起来减去所有的支出，再将所有的账户余额加起来，看看两个值相不相等。如果账单表里有几亿条记录，光是这个校验的过程可能就要跑好几个小时，这样的性能代价是完全承受不起的。现实生活中复杂的一致性需求比比皆是，而由于性能问题把一致性需求交给数据库去解决这是不现实的，所以这个锅就甩给了业务端程序员。比方说我们的account表，我们也可以不建立触发器，只要编写业务的程序员在自己的业务代码里判断一下，当某个操作会将balance列的值更新为小于0的值时，就不执行该操作就好了！ 原子性和隔离性都会对一致性产生影响，比如我们现实世界中转账操作完成后，有一个一致性需求就是参与转账的账户的总的余额是不变的。如果数据库不遵循原子性要求，也就是转了一半就不转了，那最后就是不符合一致性需求的；类似的，如果数据库不遵循隔离性要求，也就是说可能不符合一致性需求了。所以说，数据库某些操作的原子性和隔离性都是保证一致性的一种手段，在操作执行完成后保证符合所有既定的约束则是一种结果。那满足原子性和隔离性的操作一定就满足一致性么？那倒也不一定，那不满足原子性和隔离性的操作就一定不满足一致性么？这也不一定，只要最后的结果符合所有现实世界中的约束，那么就是符合一致性的。 4.持久性（Durability）当现实世界的一个状态转换完成后，这个转换的结果将永久的保留，这个规则被MySQL称为持久性。当把现实世界的状态转换映射到数据库世界时，持久性意味着该转换对应的数据库操作所修改的数据都应该在磁盘上保留下来，不论之后发生了什么事故，本次转换造成的影响都不应该被丢失掉。 二，事务的概念我们把原子性（Atomicity）、隔离性（Isolation）、一致性（Consistency）和持久性（Durability）这四个词对应的英文单词首字母提取出来就是A、I、C、D，稍微变换一下顺序可以组成一个完整的英文单词：ACID。MySQL叔为了方便起见，把需要保证原子性、隔离性、一致性和持久性的一个或多个数据库操作称之为一个事务（英文名是：transaction）。 我们现在知道事务是一个抽象的概念，它其实对应着一个或多个数据库操作，MySQL根据这些操作所执行的不同阶段把事务大致上划分成了这么几个状态： 活动的（active）事务对应的数据库操作正在执行过程中时，我们就说该事务处在活动的状态。 部分提交的（partially committed）当事务中的最后一个操作执行完成，但由于操作都在内存中执行，所造成的影响并没有刷新到磁盘时，我们就说该事务处在部分提交的状态。 失败的（failed）当事务处在活动的或者部分提交的状态时，可能遇到了某些错误（数据库自身的错误、操作系统错误或者直接断电等）而无法继续执行，或者人为的停止当前事务的执行，我们就说该事务处在失败的状态。 中止的（aborted）如果事务执行了半截而变为失败的状态，那么就需要把已经修改的数据调整为未修改之前的数据，换句话说，就是要撤销失败事务对当前数据库造成的影响。书面一点的话，我们把这个撤销的过程称之为回滚。当回滚操作执行完毕时，也就是数据库恢复到了执行事务之前的状态，我们就说该事务处在了中止的状态。 提交的（committed）当一个处在部分提交的状态的事务将修改过的数据都同步到磁盘上之后，我们就可以说该事务处在了提交的状态。 随着事务对应的数据库操作执行到不同阶段，事务的状态也在不断变化，一个基本的状态转换图如下所示： 从图中大家也可以看出了，只有当事务处于提交的或者中止的状态时，一个事务的生命周期才算是结束了。对于已经提交的事务来说，该事务对数据库所做的修改将永久生效，对于处于中止状态的事务，该事务对数据库所做的所有修改都会被回滚到没执行该事务之前的状态。 三，MySQL中事务的语法我们说事务的本质其实只是一系列数据库操作，只不过这些数据库操作符合ACID特性而已，那么MySQL中如何将某些操作放到一个事务里去执行的呢？ 1.开启事务我们可以使用下边两种语句之一来开启一个事务： BEGIN [WORK];BEGIN语句代表开启一个事务，后边的单词WORK可有可无。开启事务后，就可以继续写若干条语句，这些语句都属于刚刚开启的这个事务。 1234mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; 加入事务的语句... START TRANSACTION;START TRANSACTION语句和BEGIN语句有着相同的功效，都标志着开启一个事务，比如这样：不过比BEGIN语句牛逼一点儿的是，可以在START TRANSACTION语句后边跟随几个修饰符，就是它们几个： 1234mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&gt; 加入事务的语句... READ ONLY：标识当前事务是一个只读事务，也就是属于该事务的数据库操作只能读取数据，而不能修改数据。 其实只读事务中只是不允许修改那些其他事务也能访问到的表中的数据，对于临时表来说（我们使用CREATE TMEPORARY TABLE创建的表），由于它们只能在当前会话中可见，所以只读事务其实也是可以对临时表进行增、删、改操作的。 READ WRITE：标识当前事务是一个读写事务，也就是属于该事务的数据库操作既可以读取数据，也可以修改数据。 WITH CONSISTENT SNAPSHOT：启动一致性读。 比如我们想开启一个只读事务的话，直接把READ ONLY这个修饰符加在START TRANSACTION语句后边就好，比如这样： 1START TRANSACTION READ ONLY; 如果我们想在START TRANSACTION后边跟随多个修饰符的话，可以使用逗号将修饰符分开，比如开启一个只读事务和一致性读，就可以这样写： 1START TRANSACTION READ ONLY, WITH CONSISTENT SNAPSHOT; 或者开启一个读写事务和一致性读，就可以这样写： 1START TRANSACTION READ WRITE, WITH CONSISTENT SNAPSHOT 不过这里需要注意的一点是，READ ONLY和READ WRITE是用来设置所谓的事务访问模式的，就是以只读还是读写的方式来访问数据库中的数据，一个事务的访问模式不能同时既设置为只读的也设置为读写的，所以我们不能同时把READ ONLY和READ WRITE放到START TRANSACTION语句后边。另外，如果我们不显式指定事务的访问模式，那么该事务的访问模式就是读写模式。 2.提交事务开启事务之后就可以继续写需要放到该事务中的语句了，当最后一条语句写完了之后，我们就可以提交该事务了，提交的语句也很简单： 1COMMIT [WORK] COMMIT语句就代表提交一个事务，后边的WORK可有可无。转账举例： 12345678910111213mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; UPDATE account SET balance = balance + 10 WHERE id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; COMMIT;Query OK, 0 rows affected (0.00 sec) 3.手动中止事务如果我们写了几条语句之后发现上边的某条语句写错了，我们可以手动的使用下边这个语句来将数据库恢复到事务执行之前的样子： 1ROLLBACK [WORK] ROLLBACK语句就代表中止并回滚一个事务，后边的WORK可有可无类似的。转账举例： 12345678910111213mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; UPDATE account SET balance = balance + 1 WHERE id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; ROLLBACK;Query OK, 0 rows affected (0.00 sec) 这里需要强调一下，ROLLBACK语句是我们程序员手动的去回滚事务时才去使用的，如果事务在执行过程中遇到了某些错误而无法继续执行的话，事务自身会自动的回滚。 我们这里所说的开启、提交、中止事务的语法只是针对使用黑框框时通过mysql客户端程序与服务器进行交互时控制事务的语法，如果大家使用的是别的客户端程序，比如JDBC之类的，那需要参考相应的文档来看看如何控制事务。 4.支持事务的存储引擎MySQL中并不是所有存储引擎都支持事务的功能，目前只有InnoDB和NDB存储引擎支持（NDB存储引擎不是我们的重点），如果某个事务中包含了修改使用不支持事务的存储引擎的表，那么对该使用不支持事务的存储引擎的表所做的修改将无法进行回滚。比方说我们有两个表，tbl1使用支持事务的存储引擎InnoDB，tbl2使用不支持事务的存储引擎MyISAM，它们的建表语句如下所示： 1234567CREATE TABLE tbl1 ( i int) engine=InnoDB;CREATE TABLE tbl2 ( i int) ENGINE=MyISAM; 我们看看先开启一个事务，写一条插入语句后再回滚该事务，tbl1和tbl2的表现有什么不同： 1234567891011121314mysql&gt; SELECT * FROM tbl1;Empty set (0.00 sec)mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO tbl1 VALUES(1);Query OK, 1 row affected (0.00 sec)mysql&gt; ROLLBACK;Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM tbl1;Empty set (0.00 sec) 可以看到，对于使用支持事务的存储引擎的tbl1表来说，我们在插入一条记录再回滚后，tbl1就恢复到没有插入记录时的状态了。再看看tbl2表的表现： 12345678910111213141516171819mysql&gt; SELECT * FROM tbl2;Empty set (0.00 sec)mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO tbl2 VALUES(1);Query OK, 1 row affected (0.00 sec)mysql&gt; ROLLBACK;Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; SELECT * FROM tbl2;+------+| i |+------+| 1 |+------+1 row in set (0.00 sec) 可以看到，虽然我们使用了ROLLBACK语句来回滚事务，但是插入的那条记录还是留在了tbl2表中。 5.自动提交MySQL中有一个系统变量autocommit： 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;autocommit&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| autocommit | ON |+---------------+-------+1 row in set (0.01 sec) 可以看到它的默认值为ON，也就是说默认情况下，如果我们不显式的使用START TRANSACTION或者BEGIN语句开启一个事务，那么每一条语句都算是一个独立的事务，这种特性称之为事务的自动提交。假如我们在转账时不以START TRANSACTION或者BEGIN语句显式的开启一个事务，那么下边这两条语句就相当于放到两个独立的事务中去执行： 12UPDATE account SET balance = balance - 10 WHERE id = 1;UPDATE account SET balance = balance + 10 WHERE id = 2; 当然，如果我们想关闭这种自动提交的功能，可以使用下边两种方法之一： 显式的的使用START TRANSACTION或者BEGIN语句开启一个事务。这样在本次事务提交或者回滚前会暂时关闭掉自动提交的功能。 把系统变量autocommit的值设置为OFF，就像这样：这样的话，我们写入的多条语句就算是属于同一个事务了，直到我们显式的写出COMMIT语句来把这个事务提交掉，或者显式的写出ROLLBACK语句来把这个事务回滚掉。 1SET autocommit = OFF; 6.隐式提交当我们使用START TRANSACTION或者BEGIN语句开启了一个事务，或者把系统变量autocommit的值设置为OFF时，事务就不会进行自动提交，但是如果我们输入了某些语句之后就会悄悄的提交掉，就像我们输入了COMMIT语句了一样，这种因为某些特殊的语句而导致事务提交的情况称为隐式提交，这些会导致事务隐式提交的语句包括： 定义或修改数据库对象的数据定义语言（Data definition language，缩写为：DDL）。所谓的数据库对象，指的就是数据库、表、视图、存储过程等等这些东西。当我们使用CREATE、ALTER、DROP等语句去修改这些所谓的数据库对象时，就会隐式的提交前边语句所属于的事务，就像这样： 1234567BEGIN;SELECT ... # 事务中的一条语句UPDATE ... # 事务中的一条语句... # 事务中的其它语句CREATE TABLE ... # 此语句会隐式的提交前边语句所属于的事务 隐式使用或修改mysql数据库中的表当我们使用ALTER USER、CREATE USER、DROP USER、GRANT、RENAME USER、REVOKE、SET PASSWORD等语句时也会隐式的提交前边语句所属于的事务。 事务控制或关于锁定的语句当我们在一个事务还没提交或者回滚时就又使用START TRANSACTION或者BEGIN语句开启了另一个事务时，会隐式的提交上一个事务，比如这样：或者当前的autocommit系统变量的值为OFF，我们手动把它调为ON时，也会隐式的提交前边语句所属的事务。或者使用LOCK TABLES、UNLOCK TABLES等关于锁定的语句也会隐式的提交前边语句所属的事务。 1234567BEGIN;SELECT ... # 事务中的一条语句UPDATE ... # 事务中的一条语句... # 事务中的其它语句BEGIN; # 此语句会隐式的提交前边语句所属于的事务 加载数据的语句比如我们使用LOAD DATA语句来批量往数据库中导入数据时，也会隐式的提交前边语句所属的事务。 关于MySQL复制的一些语句使用START SLAVE、STOP SLAVE、RESET SLAVE、CHANGE MASTER TO等语句时也会隐式的提交前边语句所属的事务。 其它的一些语句使用ANALYZE TABLE、CACHE INDEX、CHECK TABLE、FLUSH、 LOAD INDEX INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE、RESET等语句也会隐式的提交前边语句所属的事务。 7.保存点如果你开启了一个事务，并且已经敲了很多语句，忽然发现上一条语句有点问题，你只好使用ROLLBACK语句来让数据库状态恢复到事务执行之前的样子，然后一切从头再来，总有一种一夜回到解放前的感觉。所以MySQL提出了一个保存点（英文：savepoint）的概念，就是在事务对应的数据库语句中打几个点，我们在调用ROLLBACK语句时可以指定会滚到哪个点，而不是回到最初的原点。定义保存点的语法如下： 1SAVEPOINT 保存点名称; 当我们想回滚到某个保存点时，可以使用下边这个语句（下边语句中的单词WORK和SAVEPOINT是可有可无的）： 1ROLLBACK [WORK] TO [SAVEPOINT] 保存点名称; 不过如果ROLLBACK语句后边不跟随保存点名称的话，会直接回滚到事务执行之前的状态。 如果我们想删除某个保存点，可以使用这个语句： 1RELEASE SAVEPOINT 保存点名称; 下边还是以转账的例子展示一下保存点的用法，在执行完扣除第一个账户的钱10元的语句之后打一个保存点： 12345678910111213141516171819202122232425262728293031323334353637383940414243mysql&gt; SELECT * FROM account;+----+--------+---------+| id | name | balance |+----+--------+---------+| 1 | 狗哥 | 11 || 2 | 猫爷 | 2 |+----+--------+---------+2 rows in set (0.00 sec)mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; SAVEPOINT s1; # 一个保存点Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM account;+----+--------+---------+| id | name | balance |+----+--------+---------+| 1 | 狗哥 | 1 || 2 | 猫爷 | 2 |+----+--------+---------+2 rows in set (0.00 sec)mysql&gt; UPDATE account SET balance = balance + 1 WHERE id = 2; # 更新错了Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; ROLLBACK TO s1; # 回滚到保存点s1处Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM account;+----+--------+---------+| id | name | balance |+----+--------+---------+| 1 | 狗哥 | 1 || 2 | 猫爷 | 2 |+----+--------+---------+2 rows in set (0.00 sec)","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[十二]InnoDB之BufferPool","slug":"MySQL/MySQL[十二]InnoDB之BufferPool","date":"2022-01-11T03:17:09.017Z","updated":"2022-01-11T03:24:53.735Z","comments":true,"path":"2022/01/11/MySQL/MySQL[十二]InnoDB之BufferPool/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E5%8D%81%E4%BA%8C]InnoDB%E4%B9%8BBufferPool/","excerpt":"","text":"一，缓存的重要性对于使用InnoDB作为存储引擎的表来说，不管是用于存储用户数据的索引（包括聚簇索引和二级索引），还是各种系统数据，都是以页的形式存放在表空间中的，而所谓的表空间只不过是InnoDB对文件系统上一个或几个实际文件的抽象，也就是说我们的数据说到底还是存储在磁盘上的。但是磁盘太慢了，所以InnoDB存储引擎在处理客户端的请求时，当需要访问某个页的数据时，就会把完整的页的数据全部加载到内存中，也就是说即使我们只需要访问一个页的一条记录，那也需要先把整个页的数据加载到内存中。将整个页加载到内存中后就可以进行读写访问了，在进行完读写访问之后并不着急把该页对应的内存空间释放掉，而是将其缓存起来，这样将来有请求再次访问该页面时，就可以省去磁盘IO的开销了。 二，InnoDB的Buffer Pool 1.啥是个Buffer Pool为了缓存磁盘中的页，在MySQL服务器启动的时候就向操作系统申请了一片连续的内存，叫做Buffer Pool（中文名是缓冲池）。那它有多大呢？这个其实看我们机器的配置，默认情况下Buffer Pool只有128M大小，但是可以在启动服务器的时候配置innodb_buffer_pool_size参数的值，它表示Buffer Pool的大小，就像这样： 12[server]innodb_buffer_pool_size = 268435456 其中，268435456的单位是字节，也就是我指定Buffer Pool的大小为256M。需要注意的是，Buffer Pool也不能太小，最小值为5M(当小于该值时会自动设置成5M)。 2.Buffer Pool内部组成Buffer Pool中默认的缓存页大小和在磁盘上默认的页大小是一样的，都是16KB。为了更好的管理这些在Buffer Pool中的缓存页，InnoDB为每一个缓存页都创建了一些所谓的控制信息，这些控制信息包括该页所属的表空间编号、页号、缓存页在Buffer Pool中的地址、链表节点信息、一些锁信息以及LSN信息（锁和LSN先忽略），当然还有一些别的控制信息，暂时省略。 每个缓存页对应的控制信息占用的内存大小是相同的，我们就把每个页对应的控制信息占用的一块内存称为一个控制块，控制块和缓存页是一一对应的，它们都被存放到 Buffer Pool 中，其中控制块被存放到 Buffer Pool 的前边，缓存页被存放到 Buffer Pool 后边。 每一个控制块都对应一个缓存页，那在分配足够多的控制块和缓存页后，可能剩余的那点儿空间不够一对控制块和缓存页的大小，这个用不到的那点儿内存空间就被称为碎片。当然，如果把Buffer Pool的大小设置的刚刚好的话，也可能不会产生碎片。 每个控制块大约占用缓存页大小的5%，在MySQL5.7.21这个版本中，每个控制块占用的大小是808字节。而我们设置的innodb_buffer_pool_size并不包含这部分控制块占用的内存空间大小，也就是说InnoDB在为Buffer Pool向操作系统申请连续的内存空间时，这片连续的内存空间一般会比innodb_buffer_pool_size的值大5%左右。 3.free链表的管理当我们最初启动MySQL服务器的时候，需要完成对Buffer Pool的初始化过程，就是先向操作系统申请Buffer Pool的内存空间，然后把它划分成若干对控制块和缓存页。但是此时并没有真实的磁盘页被缓存到Buffer Pool中（因为还没有用到），之后随着程序的运行，会不断的有磁盘上的页被缓存到Buffer Pool中。那么问题来了，从磁盘上读取一个页到Buffer Pool中的时候该放到哪个缓存页的位置呢？或者说怎么区分Buffer Pool中哪些缓存页是空闲的，哪些已经被使用了呢？我们最好在某个地方记录一下Buffer Pool中哪些缓存页是可用的，我们可以把所有空闲的缓存页对应的控制块作为一个节点放到一个链表中，这个链表也可以被称作free链表（或者说空闲链表）。刚刚完成初始化的Buffer Pool中所有的缓存页都是空闲的，所以每一个缓存页对应的控制块都会被加入到free链表中。 为了管理好这个free链表，特意为这个链表定义了一个基节点，里边儿包含着链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。这里需要注意的是，链表的基节点占用的内存空间并不包含在为Buffer Pool申请的一大片连续内存空间之内，而是单独申请的一块内存空间。 链表基节点占用的内存空间并不大，在MySQL5.7.21这个版本里，每个基节点只占用40字节大小。后边我们即将介绍许多不同的链表，它们的基节点和free链表的基节点的内存分配方式是一样的，都是单独申请的一块40字节大小的内存空间，并不包含在为Buffer Pool申请的一大片连续内存空间之内。 有了这个free链表之后，每当需要从磁盘中加载一个页到Buffer Pool中时，就从free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上（就是该页所在的表空间、页号之类的信息），然后把该缓存页对应的free链表节点从链表中移除，表示该缓存页已经被使用了。 4.缓存页的哈希处理当我们需要访问某个页中的数据时，就会把该页从磁盘加载到Buffer Pool中，如果该页已经在Buffer Pool中的话直接使用就可以了。那么问题也就来了，我们怎么知道该页在不在Buffer Pool中呢？难不成需要依次遍历Buffer Pool中各个缓存页么？ 我们其实是根据表空间号 + 页号来定位一个页的，也就相当于表空间号 + 页号是一个key，缓存页就是对应的value，怎么通过一个key来快速找着一个value呢？那肯定是哈希表。 所以我们可以用表空间号 + 页号作为key，缓存页作为value创建一个哈希表，在需要访问某个页的数据时，先从哈希表中根据表空间号 + 页号看看有没有对应的缓存页，如果有，直接使用该缓存页就好，如果没有，那就从free链表中选一个空闲的缓存页，然后把磁盘中对应的页加载到该缓存页的位置。 5.flush链表的管理如果我们修改了Buffer Pool中某个缓存页的数据，那它就和磁盘上的页不一致了，这样的缓存页也被称为脏页（英文名：dirty page）。最简单的做法就是每发生一次修改就立即同步到磁盘上对应的页上，但是频繁的往磁盘中写数据会严重的影响程序的性能。所以每次修改缓存页后，我们一般一般异步同步磁盘。 但是如果不立即同步到磁盘的话，那之后再同步的时候我们怎么知道Buffer Pool中哪些页是脏页，哪些页从来没被修改过呢？创建一个存储脏页的链表，凡是修改过的缓存页对应的控制块都会作为一个节点加入到一个链表中，因为这个链表节点对应的缓存页都是需要被刷新到磁盘上的，所以也叫flush链表。链表的构造和free链表差不多。 6.LRU链表的管理6.1 缓存不够的窘境Buffer Pool对应的内存大小毕竟是有限的，如果需要缓存的页占用的内存大小超过了Buffer Pool大小，也就是free链表中已经没有多余的空闲缓存页咋办？当然是把某些旧的缓存页从Buffer Pool中移除，然后再把新的页放进来， 那么移除哪些缓存页呢？ 我们设立Buffer Pool的初衷就是想减少和磁盘的IO交互，最好每次在访问某个页的时候它都已经被缓存到Buffer Pool中了。假设我们一共访问了n次页，那么被访问的页已经在缓存中的次数除以n就是所谓的缓存命中率，我们的期望就是让缓存命中率越高越好。所以是留下最近很频繁使用的。 6.2简单的LRU链表管理Buffer Pool的缓存页其实也是这个道理，当Buffer Pool中不再有空闲的缓存页时，就需要淘汰掉部分最近很少使用的缓存页。怎么知道哪些缓存页最近频繁使用，哪些最近很少使用呢？我们可以再创建一个链表，由于这个链表是为了按照最近最少使用的原则去淘汰缓存页的，所以这个链表可以被称为LRU链表（LRU的英文全称：Least Recently Used）。当我们需要访问某个页时，可以这样处理LRU链表： 如果该页不在Buffer Pool中，在把该页从磁盘加载到Buffer Pool中的缓存页时，就把该缓存页对应的控制块作为节点塞到链表的头部。 如果该页已经缓存在Buffer Pool中，则直接把该页对应的控制块移动到LRU链表的头部。 也就是说：只要我们使用到某个缓存页，就把该缓存页调整到LRU链表的头部，这样LRU链表尾部就是最近最少使用的缓存页了。 所以当Buffer Pool中的空闲缓存页使用完时，到LRU链表的尾部找些缓存页淘汰。 6.3划分区域的LRU链表上边的这个简单的LRU链表有问题，因为存在这两种比较尴尬的情况： 情况一：InnoDB提供了一个服务——预读（英文名：read ahead）。所谓预读，就是InnoDB认为执行当前的请求可能之后会读取某些页面，就预先把它们加载到Buffer Pool中。根据触发方式的不同，预读又可以细分为下边两种： 线性预读InnoDB提供了一个系统变量innodb_read_ahead_threshold，如果顺序访问了某个区（extent）的页面超过这个系统变量的值，就会触发一次异步读取下一个区中全部的页面到Buffer Pool的请求，异步读取意味着从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行。这个innodb_read_ahead_threshold系统变量的值默认是56，我们可以在服务器启动时通过启动参数或者服务器运行过程中直接调整该系统变量的值，不过它是一个全局变量，注意使用SET GLOBAL命令来修改。 InnoDB是怎么实现异步读取的呢？在Windows或者Linux平台上，可能是直接调用操作系统内核提供的AIO接口，在其它类Unix操作系统中，使用了一种模拟AIO接口的方式来实现异步读取，其实就是让别的线程去读取需要预读的页面。 随机预读如果Buffer Pool中已经缓存了某个区的13个连续的页面，不论这些页面是不是顺序读取的，都会触发一次异步读取本区中所有其的页面到Buffer Pool的请求。InnoDB同时提供了innodb_random_read_ahead系统变量，它的默认值为OFF，也就意味着InnoDB并不会默认开启随机预读的功能，如果我们想开启该功能，可以通过修改启动参数或者直接使用SET GLOBAL命令把该变量的值设置为ON。 如果预读到Buffer Pool中的页成功的被使用到，那就可以极大的提高语句执行的效率。可是如果用不到呢？这些预读的页都会放到LRU链表的头部，但是如果此时Buffer Pool的容量不太大而且很多预读的页面都没有用到的话，这就会导致处在LRU链表尾部的一些缓存页会很快的被淘汰掉，也就是所谓的劣币驱逐良币，会大大降低缓存命中率。 情况二：有一些扫描全表的查询语句（比如没有建立合适的索引或者压根儿没有WHERE子句的查询）。扫描全表意味着将访问到该表所在的所有页！假设这个表中记录非常多的话，那该表会占用特别多的页，当需要访问这些页时，会把它们统统都加载到Buffer Pool中，这也就意味着Buffer Pool中的所有页都被换了一次，其他查询语句在执行时又得执行一次从磁盘加载到Buffer Pool的操作。而这种全表扫描的语句执行的频率也不高，每次执行都要把Buffer Pool中的缓存页换一次，这严重的影响到其他查询对 Buffer Pool的使用，从而大大降低了缓存命中率。 总结一下上边说的可能降低Buffer Pool的两种情况： 加载到Buffer Pool中的页不一定被用到。 如果非常多的使用频率偏低的页被同时加载到Buffer Pool时，可能会把那些使用频率非常高的页从Buffer Pool中淘汰掉。 因为有这两种情况的存在，所以InnoDB把这个LRU链表按照一定比例分成两截，分别是： 一部分存储使用频率非常高的缓存页，所以这一部分链表也叫做热数据，或者称young区域。 另一部分存储使用频率不是很高的缓存页，所以这一部分链表也叫做冷数据，或者称old区域。 我们是按照某个比例将LRU链表分成两半的，不是某些节点固定是young区域的，某些节点固定是old区域的，随着程序的运行，某个节点所属的区域也可能发生变化。那这个划分成两截的比例怎么确定呢？对于InnoDB存储引擎来说，我们可以通过查看系统变量innodb_old_blocks_pct的值来确定old区域在LRU链表中所占的比例，比方说这样： 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;innodb_old_blocks_pct&#x27;;+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| innodb_old_blocks_pct | 37 |+-----------------------+-------+1 row in set (0.01 sec) 从结果可以看出来，默认情况下，old区域在LRU链表中所占的比例是37%，也就是说old区域大约占LRU链表的3/8。这个比例我们是可以设置的，我们可以在启动时修改innodb_old_blocks_pct参数来控制old区域在LRU链表中所占的比例，比方说这样修改配置文件： 12[server]innodb_old_blocks_pct = 40 这样我们在启动服务器后，old区域占LRU链表的比例就是40%。当然，如果在服务器运行期间，我们也可以修改这个系统变量的值，不过需要注意的是，这个系统变量属于全局变量，一经修改，会对所有客户端生效，所以我们只能这样修改： 1SET GLOBAL innodb_old_blocks_pct = 40; 有了这个被划分成young和old区域的LRU链表之后，InnoDB就可以针对我们上边提到的两种可能降低缓存命中率的情况进行优化： 针对预读的页面可能不进行后续访问情况的优化InnoDB规定，当磁盘上的某个页面在初次加载到Buffer Pool中的某个缓存页时，该缓存页对应的控制块会被放到old区域的头部。这样针对预读到Buffer Pool却不进行后续访问的页面就会被逐渐从old区域逐出，而不会影响young区域中被使用比较频繁的缓存页。 针对全表扫描时，短时间内访问大量使用频率非常低的页面情况的优化在进行全表扫描时，虽然首次被加载到Buffer Pool的页被放到了old区域的头部，但是后续会被马上访问到，每次进行访问的时候又会把该页放到young区域的头部，这样仍然会把那些使用频率比较高的页面给顶下去。全表扫描有一个特点，那就是它的执行频率非常低，而且在执行全表扫描的过程中，即使某个页面中有很多条记录，也就是去多次访问这个页面所花费的时间也是非常少的。所以我们只需要规定，在对某个处在old区域的缓存页进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该页面就不会被从old区域移动到young区域的头部，否则将它移动到young区域的头部。上述的这个间隔时间是由系统变量innodb_old_blocks_time控制的： 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;innodb_old_blocks_time&#x27;;+------------------------+-------+| Variable_name | Value |+------------------------+-------+| innodb_old_blocks_time | 1000 |+------------------------+-------+1 row in set (0.01 sec) 这个innodb_old_blocks_time的默认值是1000，它的单位是毫秒，也就意味着对于从磁盘上被加载到LRU链表的old区域的某个页来说，如果第一次和最后一次访问该页面的时间间隔小于1s（很明显在一次全表扫描的过程中，多次访问一个页面中的时间不会超过1s），那么该页是不会被加入到young区域的。 当然，像innodb_old_blocks_pct一样，我们也可以在服务器启动或运行时设置innodb_old_blocks_time的值。 这里需要注意的是，如果我们把innodb_old_blocks_time的值设置为0，那么每次我们访问一个页面时就会把该页面放到young区域的头部。 综上所述，正是因为将LRU链表划分为young和old区域这两个部分，又添加了innodb_old_blocks_time这个系统变量，才使得预读机制和全表扫描造成的缓存命中率降低的问题得到了遏制，因为用不到的预读页面以及全表扫描的页面都只会被放到old区域，而不影响young区域中的缓存页。 6.4 更进一步优化LRU链表对于young区域的缓存页来说，我们每次访问一个缓存页就要把它移动到LRU链表的头部，这样开销太大了，毕竟在young区域的缓存页都是热点数据，也就是可能被经常访问的，这样频繁的对LRU链表进行节点移动操作不太好，为了解决这个问题其实我们还可以提出一些优化策略，比如只有被访问的缓存页位于young区域的1/4的后边，才会被移动到LRU链表头部，这样就可以降低调整LRU链表的频率，从而提升性能（也就是说如果某个缓存页对应的节点在young区域的1/4中，再次访问该缓存页时也不会将其移动到LRU链表头部）。 介绍随机预读的时候曾说，如果Buffer Pool中有某个区的13个连续页面就会触发随机预读，这其实是不严谨的（但是MySQL文档就是这么说的），其实还要求这13个页面是非常热的页面，所谓的非常热，指的是这些页面在整个young区域的头1/4处。 还有针对LRU链表的优化措施，核心就是尽量高效的提高 Buffer Pool 的缓存命中率。 7.其他的一些链表为了更好的管理Buffer Pool中的缓存页，除了我们上边提到的一些措施，InnoDB还引进了其他的一些链表，比如unzip LRU链表用于管理解压页，zip clean链表用于管理没有被解压的压缩页，zip free数组中每一个元素都代表一个链表，它们组成所谓的伙伴系统来为压缩页提供内存空间等等，为了更好的管理这个Buffer Pool引入了各种链表或其他数据结构。 8.刷新脏页到磁盘后台有专门的线程每隔一段时间负责把脏页刷新到磁盘，这样可以不影响用户线程处理正常的请求。主要有两种刷新路径： 从LRU链表的冷数据中刷新一部分页面到磁盘。后台线程会定时从LRU链表尾部开始扫描一些页面，扫描的页面数量可以通过系统变量innodb_lru_scan_depth来指定，如果从里边儿发现脏页，会把它们刷新到磁盘。这种刷新页面的方式被称之为BUF_FLUSH_LRU。 从flush链表中刷新一部分页面到磁盘。后台线程也会定时从flush链表中刷新一部分页面到磁盘，刷新的速率取决于当时系统是不是很繁忙。这种刷新页面的方式被称之为BUF_FLUSH_LIST。 有时候后台线程刷新脏页的进度比较慢，导致用户线程在准备加载一个磁盘页到Buffer Pool时没有可用的缓存页，这时就会尝试看看LRU链表尾部有没有可以直接释放掉的未修改页面，如果没有的话会不得不将LRU链表尾部的一个脏页同步刷新到磁盘（和磁盘交互是很慢的，这会降低处理用户请求的速度）。这种刷新单个页面到磁盘中的刷新方式被称之为BUF_FLUSH_SINGLE_PAGE。 当然，有时候系统特别繁忙时，也可能出现用户线程批量的从flush链表中刷新脏页的情况，很显然在处理用户请求过程中去刷新脏页是一种严重降低处理速度的行为，这属于一种迫不得已的情况。 9.多个Buffer Pool实例Buffer Pool本质是InnoDB向操作系统申请的一块连续的内存空间，在多线程环境下，访问Buffer Pool中的各种链表都需要加锁处理，在Buffer Pool特别大而且多线程并发访问特别高的情况下，单一的Buffer Pool可能会影响请求的处理速度。所以在Buffer Pool特别大的时候，我们可以把它们拆分成若干个小的Buffer Pool，每个Buffer Pool都称为一个实例，它们都是独立的，独立的去申请内存空间，独立的管理各种链表，所以在多线程并发访问时并不会相互影响，从而提高并发处理能力。我们可以在服务器启动的时候通过设置innodb_buffer_pool_instances的值来修改Buffer Pool实例的个数，比方说这样： 12[server]innodb_buffer_pool_instances = 2 这样就表明我们要创建2个Buffer Pool实例。 每个Buffer Pool实例实际占多少内存空间呢？其实使用这个公式算出来的： 1innodb_buffer_pool_size/innodb_buffer_pool_instances 也就是总共的大小除以实例的个数，结果就是每个Buffer Pool实例占用的大小。 不过也不是说Buffer Pool实例创建的越多越好，分别管理各个Buffer Pool也是需要性能开销的，InnoDB规定：当innodb_buffer_pool_size的值小于1G的时候设置多个实例是无效的，InnoDB会默认把innodb_buffer_pool_instances 的值修改为1。而MySQL希望在Buffer Pool大于或等于1G的时候设置多个Buffer Pool实例。 10.innodb_buffer_pool_chunk_size在MySQL 5.7.5之前，Buffer Pool的大小只能在服务器启动时通过配置innodb_buffer_pool_size启动参数来调整大小，在服务器运行过程中是不允许调整该值的。不过MySQL在5.7.5以及之后的版本中支持了在服务器运行过程中调整Buffer Pool大小的功能，但是有一个问题，就是每次当我们要重新调整Buffer Pool大小时，都需要重新向操作系统申请一块连续的内存空间，然后将旧的Buffer Pool中的内容复制到这一块新空间，这是极其耗时的。所以MySQL决定不再一次性为某个Buffer Pool实例向操作系统申请一大片连续的内存空间，而是以一个所谓的chunk为单位向操作系统申请空间。也就是说一个Buffer Pool实例其实是由若干个chunk组成的，一个chunk就代表一片连续的内存空间，里边儿包含了若干缓存页与其对应的控制块。 正是因为发明了这个chunk的概念，我们在服务器运行期间调整Buffer Pool的大小时就是以chunk为单位增加或者删除内存空间，而不需要重新向操作系统申请一片大的内存，然后进行缓存页的复制。这个所谓的chunk的大小是我们在启动操作MySQL服务器时通过innodb_buffer_pool_chunk_size启动参数指定的，它的默认值是134217728，也就是128M。不过需要注意的是，innodb_buffer_pool_chunk_size的值只能在服务器启动时指定，在服务器运行过程中是不可以修改的。 为什么不允许在服务器运行过程中修改innodb_buffer_pool_chunk_size的值？因为innodb_buffer_pool_chunk_size的值代表InnoDB向操作系统申请的一片连续的内存空间的大小，如果你在服务器运行过程中修改了该值，就意味着要重新向操作系统申请连续的内存空间并且将原先的缓存页和它们对应的控制块复制到这个新的内存空间中，这是十分耗时的操作！ 另外，这个innodb_buffer_pool_chunk_size的值并不包含缓存页对应的控制块的内存空间大小，所以实际上InnoDB向操作系统申请连续内存空间时，每个chunk的大小要比innodb_buffer_pool_chunk_size的值大一些，约5%。 11.配置Buffer Pool时的注意事项 innodb_buffer_pool_size必须是innodb_buffer_pool_chunk_size × innodb_buffer_pool_instances的倍数（这主要是想保证每一个Buffer Pool实例中包含的chunk数量相同）。假设我们指定的innodb_buffer_pool_chunk_size的值是128M，innodb_buffer_pool_instances的值是16，那么这两个值的乘积就是2G，也就是说innodb_buffer_pool_size的值必须是2G或者2G的整数倍。比方说我们在启动MySQL服务器是这样指定启动参数的：默认的innodb_buffer_pool_chunk_size值是128M，指定的innodb_buffer_pool_instances的值是16，所以innodb_buffer_pool_size的值必须是2G或者2G的整数倍，上边例子中指定的innodb_buffer_pool_size的值是8G，符合规定，所以在服务器启动完成之后我们查看一下该变量的值就是我们指定的8G（8589934592字节）：如果我们指定的innodb_buffer_pool_size大于2G并且不是2G的整数倍，那么服务器会自动的把innodb_buffer_pool_size的值调整为2G的整数倍，比方说我们在启动服务器时指定的innodb_buffer_pool_size的值是9G：那么服务器会自动把innodb_buffer_pool_size的值调整为10G，10737418240字节。 1mysqld --innodb-buffer-pool-size=8G --innodb-buffer-pool-instances=16 1234567mysql&gt; show variables like &#x27;innodb_buffer_pool_size&#x27;;+-------------------------+------------+| Variable_name | Value |+-------------------------+------------+| innodb_buffer_pool_size | 8589934592 |+-------------------------+------------+1 row in set (0.00 sec) 1mysqld --innodb-buffer-pool-size=9G --innodb-buffer-pool-instances=16 1234567mysql&gt; show variables like &#x27;innodb_buffer_pool_size&#x27;;+-------------------------+-------------+| Variable_name | Value |+-------------------------+-------------+| innodb_buffer_pool_size | 10737418240 |+-------------------------+-------------+1 row in set (0.01 sec) 如果在服务器启动时，innodb_buffer_pool_chunk_size × innodb_buffer_pool_instances的值已经大于innodb_buffer_pool_size的值，那么innodb_buffer_pool_chunk_size的值会被服务器自动设置为innodb_buffer_pool_size/innodb_buffer_pool_instances的值。比方说我们在启动服务器时指定的innodb_buffer_pool_size的值为2G，innodb_buffer_pool_instances的值为16，innodb_buffer_pool_chunk_size的值为256M：由于256M × 16 = 4G，而4G &gt; 2G，所以innodb_buffer_pool_chunk_size值会被服务器改写为innodb_buffer_pool_size/innodb_buffer_pool_instances的值，也就是：2G/16 = 128M（134217728字节）。 1mysqld --innodb-buffer-pool-size=2G --innodb-buffer-pool-instances=16 --innodb-buffer-pool-chunk-size=256M 123456789101112131415mysql&gt; show variables like &#x27;innodb_buffer_pool_size&#x27;;+-------------------------+------------+| Variable_name | Value |+-------------------------+------------+| innodb_buffer_pool_size | 2147483648 |+-------------------------+------------+1 row in set (0.01 sec)mysql&gt; show variables like &#x27;innodb_buffer_pool_chunk_size&#x27;;+-------------------------------+-----------+| Variable_name | Value |+-------------------------------+-----------+| innodb_buffer_pool_chunk_size | 134217728 |+-------------------------------+-----------+1 row in set (0.00 sec) 12.Buffer Pool中存储的其它信息Buffer Pool的缓存页除了用来缓存磁盘上的页面以外，还可以存储锁信息、自适应哈希索引等信息。 13.查看Buffer Pool的状态信息MySQL给我们提供了SHOW ENGINE INNODB STATUS语句来查看关于InnoDB存储引擎运行过程中的一些状态信息，其中就包括Buffer Pool的一些信息，我们看一下（为了突出重点，我们只把输出中关于Buffer Pool的部分提取了出来）： 123456789101112131415161718192021222324252627mysql&gt; SHOW ENGINE INNODB STATUS\\G(...省略前边的许多状态)----------------------BUFFER POOL AND MEMORY----------------------Total memory allocated 13218349056;Dictionary memory allocated 4014231Buffer pool size 786432Free buffers 8174Database pages 710576Old database pages 262143Modified db pages 124941Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages made young 6195930012, not young 78247510485108.18 youngs/s, 226.15 non-youngs/sPages read 2748866728, created 29217873, written 4845680877160.77 reads/s, 3.80 creates/s, 190.16 writes/sBuffer pool hit rate 956 / 1000, young-making rate 30 / 1000 not 605 / 1000Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/sLRU len: 710576, unzip_LRU len: 118I/O sum[134264]:cur[144], unzip sum[16]:cur[0]--------------(...省略后边的许多状态)mysql&gt; 我们来详细看一下这里边的每个值都代表什么意思： Total memory allocated：代表Buffer Pool向操作系统申请的连续内存空间大小，包括全部控制块、缓存页、以及碎片的大小。 Dictionary memory allocated：为数据字典信息分配的内存空间大小，注意这个内存空间和Buffer Pool没啥关系，不包括在Total memory allocated中。 Buffer pool size：代表该Buffer Pool可以容纳多少缓存页，注意，单位是页！ Free buffers：代表当前Buffer Pool还有多少空闲缓存页，也就是free链表中还有多少个节点。 Database pages：代表LRU链表中的页的数量，包含young和old两个区域的节点数量。 Old database pages：代表LRU链表old区域的节点数量。 Modified db pages：代表脏页数量，也就是flush链表中节点的数量。 Pending reads：正在等待从磁盘上加载到Buffer Pool中的页面数量。当准备从磁盘中加载某个页面时，会先为这个页面在Buffer Pool中分配一个缓存页以及它对应的控制块，然后把这个控制块添加到LRU的old区域的头部，但是这个时候真正的磁盘页并没有被加载进来，Pending reads的值会跟着加1。 Pending writes LRU：即将从LRU链表中刷新到磁盘中的页面数量。 Pending writes flush list：即将从flush链表中刷新到磁盘中的页面数量。 Pending writes single page：即将以单个页面的形式刷新到磁盘中的页面数量。 Pages made young：代表LRU链表中曾经从old区域移动到young区域头部的节点数量。这里需要注意，一个节点每次只有从old区域移动到young区域头部时才会将Pages made young的值加1，也就是说如果该节点本来就在young区域，由于它符合在young区域1/4后边的要求，下一次访问这个页面时也会将它移动到young区域头部，但这个过程并不会导致Pages made young的值加1。 Page made not young：在将innodb_old_blocks_time设置的值大于0时，首次访问或者后续访问某个处在old区域的节点时由于不符合时间间隔的限制而不能将其移动到young区域头部时，Page made not young的值会加1。这里需要注意，对于处在young区域的节点，如果由于它在young区域的1/4处而导致它没有被移动到young区域头部，这样的访问并不会将Page made not young的值加1。 youngs/s：代表每秒从old区域被移动到young区域头部的节点数量。 non-youngs/s：代表每秒由于不满足时间限制而不能从old区域移动到young区域头部的节点数量。 Pages read、created、written：代表读取，创建，写入了多少页。后边跟着读取、创建、写入的速率。 Buffer pool hit rate：表示在过去某段时间，平均访问1000次页面，有多少次该页面已经被缓存到Buffer Pool了。 young-making rate：表示在过去某段时间，平均访问1000次页面，有多少次访问使页面移动到young区域的头部了。 需要注意的一点是，这里统计的将页面移动到**young**区域的头部次数不仅仅包含从**old**区域移动到**young**区域头部的次数，还包括从**young**区域移动到**young**区域头部的次数（访问某个**young**区域的节点，只要该节点在**young**区域的1/4处往后，就会把它移动到**young**区域的头部）。 not (young-making rate)：表示在过去某段时间，平均访问1000次页面，有多少次访问没有使页面移动到young区域的头部。 需要注意的一点是，这里统计的没有将页面移动到**young**区域的头部次数不仅仅包含因为设置了**innodb_old_blocks_time**系统变量而导致访问了**old**区域中的节点但没把它们移动到**young**区域的次数，还包含因为该节点在**young**区域的前1/4处而没有被移动到**young**区域头部的次数。 LRU len：代表LRU链表中节点的数量。 unzip_LRU：代表unzip_LRU链表中节点的数量。 I/O sum：最近50s读取磁盘页的总数。 I/O cur：现在正在读取的磁盘页数量。 I/O unzip sum：最近50s解压的页面数量。 I/O unzip cur：正在解压的页面数量。 三，总结 磁盘太慢，用内存作为缓存很有必要。 Buffer Pool本质上是InnoDB向操作系统申请的一段连续的内存空间，可以通过innodb_buffer_pool_size来调整它的大小。 Buffer Pool向操作系统申请的连续内存由控制块和缓存页组成，每个控制块和缓存页都是一一对应的，在填充足够多的控制块和缓存页的组合后，Buffer Pool剩余的空间可能产生不够填充一组控制块和缓存页，这部分空间不能被使用，也被称为碎片。 InnoDB使用了许多链表来管理Buffer Pool。 free链表中每一个节点都代表一个空闲的缓存页，在将磁盘中的页加载到Buffer Pool时，会从free链表中寻找空闲的缓存页。 为了快速定位某个页是否被加载到Buffer Pool，使用表空间号 + 页号作为key，缓存页作为value，建立哈希表。 在Buffer Pool中被修改的页称为脏页，脏页并不是立即刷新，而是被加入到flush链表中，待之后的某个时刻同步到磁盘上。 LRU链表分为young和old两个区域，可以通过innodb_old_blocks_pct来调节old区域所占的比例。首次从磁盘上加载到Buffer Pool的页会被放到old区域的头部，在innodb_old_blocks_time间隔时间内访问该页不会把它移动到young区域头部。在Buffer Pool没有可用的空闲缓存页时，会首先淘汰掉old区域的一些页。 我们可以通过指定innodb_buffer_pool_instances来控制Buffer Pool实例的个数，每个Buffer Pool实例中都有各自独立的链表，互不干扰。 自MySQL 5.7.5版本之后，可以在服务器运行过程中调整Buffer Pool大小。每个Buffer Pool实例由若干个chunk组成，每个chunk的大小可以在服务器启动时通过启动参数调整。 可以用下边的命令查看Buffer Pool的状态信息： 1SHOW ENGINE INNODB STATUS\\G","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[十一]高性能MySQL调优实战","slug":"MySQL/MySQL[十一]高性能MySQL调优实战","date":"2022-01-11T03:16:57.298Z","updated":"2022-01-11T03:24:28.380Z","comments":true,"path":"2022/01/11/MySQL/MySQL[十一]高性能MySQL调优实战/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E5%8D%81%E4%B8%80]%E9%AB%98%E6%80%A7%E8%83%BDMySQL%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/","excerpt":"","text":"一，数据库应该如何优化数据库优化有很多层面。 1.SQL与索引因为 SQL 语句是在我们的应用端编写的，所以第一步，我们可以在程序中对 SQL 语句进行优化，最终的目标是用到索引。这个是容易的也是最常用的优化手段。 2.表与存储引擎数据是存放在表里面的，表又是以不同的格式存放在存储引擎中的，所以我们可以选用特定的存储引擎，或者对表进行分区，对表结构进行拆分或者冗余处理，或者对表结构比如字段的定义进行优化。 3.架构对于数据库的服务，我们可以对它的架构进行优化。如果只有一台数据库的服务器，我们可以运行多个实例，做集群的方案，做负载均衡。或者基于主从复制实现读写分离，让写的服务都访问 master 服务器，读的请求都访问从服务器，slave 服务器自动 master 主服务器同步数据。或者在数据库前面加一层缓存，达到减少数据库的压力，提升访问速度的目的。为了分散数据库服务的存储压力和访问压力，我们也可以把不同的数据分布到不同的服务节点，这个就是分库分表（scale out）。 注意主从（replicate）和分片（shard）的区别： 主从通过数据冗余实现高可用，和实现读写分离。 分片通过拆分数据分散存储和访问压力。 4.配置数据库配置的优化，比如连接数，缓冲区大小等等，优化配置的目的都是为了更高效地利用硬件。 5.操作系统与硬件从上往下，成本收益比慢慢地在增加。所以肯定不是查询一慢就堆硬件，堆硬件叫做向上的扩展（scale up）。 二，慢日志查询1.概述MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10秒以上的语句。由他来查看哪些SQL超出了我们的最大忍耐时间值，比如一条sql执行超过5秒钟，我们就算慢SQL，希望能收集超过5秒的sql，结合explain进行全面分析。 2.实操默认情况下，MySQL数据库没有开启慢查询日志，需要我们手动来设置这个参数。 当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件。 2.1查看及开启①日志1SHOW VARIABLES LIKE &#x27;%slow_query_log%&#x27;; 默认情况下slow_query_log的值为OFF，表示慢查询日志是禁用的。 1set global slow_query_log=1; 只对窗口生效，重启服务失效。 ②时间1SHOW VARIABLES LIKE &#x27;%long_query_time%&#x27;; 1SET GLOBAL long_query_time=0.1; 全局变量设置，对所有客户端有效。但必须是设置后进行登录的客户端。 1SET SESSION long_query_time=0.1; #session可省略 对当前会话连接立即生效，对其他客户端无效。 假如运行时间正好等于long_query_time的情况，并不会被记录下来。也就是说，在mysql源码里是判断大于long_query_time，而非大于等于。 ③永久生效修改配置文件my.cnf（其它系统变量也是如此） [mysqld]下增加或修改参数 slow_query_log 和slow_query_log_file后，然后重启MySQL服务器。也即将如下两行配置进my.cnf文件 [1] 1234slow_query_log =1slow_query_log_file=/var/lib/mysql/yhd-slow.log long_query_time=3log_output=FILE 2.2Case记录慢SQL并后续分析 查询当前系统中有多少条慢查询记录 1SHOW GLOBAL STATUS LIKE &#x27;%Slow_queries%&#x27;; 3.日志分析工具-mysqldumpslow在生产环境中，如果要手工分析日志，查找、分析SQL，显然是个体力活，MySQL提供了日志分析工具mysqldumpslow。 查看mysqldumpslow的帮助信息（windows下需要安装perl环境） 1mysqldumpslow --help -a: 不将数字抽象成N，字符串抽象成S-s: 是表示按照何种方式排序；c: 访问次数l: 锁定时间r: 返回记录t: 查询时间al:平均锁定时间ar:平均返回记录数at:平均查询时间-t: 即为返回前面多少条的数据；-g: 后边搭配一个正则匹配模式，大小写不敏感的； 3.1常用SQL12345678得到返回记录集最多的10个SQLmysqldumpslow -s r -t 10 /var/lib/mysql/yhd-slow.log得到访问次数最多的10个SQLmysqldumpslow -s c -t 10 /var/lib/mysql/yhd-slow.log得到按照时间排序的前10条里面含有左连接的查询语句mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/yhd-slow.log另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现爆屏情况mysqldumpslow -s r -t 10 /var/lib/mysql/yhd-slow.log | more 4.SHOW PROCESSLIST作用：查询所有用户正在干什么。 如果出现不顺眼的：kill [id] 三，EXPLAIN调优实战1.准备数据员工表插入500w数据，部门表插入10w数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586CREATE TABLE `dept`( `id` INT(11) NOT NULL AUTO_INCREMENT, `deptName` VARCHAR(30) DEFAULT NULL, `address` VARCHAR(40) DEFAULT NULL, `ceo` INT NULL, PRIMARY KEY (`id`)) ENGINE = INNODB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8;CREATE TABLE `emp`( `id` INT(11) NOT NULL AUTO_INCREMENT, `empno` INT NOT NULL, `name` VARCHAR(20) DEFAULT NULL, `age` INT(3) DEFAULT NULL, `deptId` INT(11) DEFAULT NULL, PRIMARY KEY (`id`) #CONSTRAINT `fk_dept_id` FOREIGN KEY (`deptId`) REFERENCES `t_dept` (`id`)) ENGINE = INNODB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8;#生成随机字符串DELIMITER $$CREATE FUNCTION rand_string(n INT) RETURNS VARCHAR(255)BEGIN DECLARE chars_str VARCHAR(100) DEFAULT &#x27;abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ&#x27;; DECLARE return_str VARCHAR(255) DEFAULT &#x27;&#x27;; DECLARE i INT DEFAULT 0; WHILE i &lt; n DO SET return_str = CONCAT(return_str, SUBSTRING(chars_str, FLOOR(1 + RAND() * 52), 1)); SET i = i + 1; END WHILE; RETURN return_str;END $$#用于随机产生多少到多少的编号DELIMITER $$CREATE FUNCTION rand_num(from_num INT, to_num INT) RETURNS INT(11)BEGIN DECLARE i INT DEFAULT 0; SET i = FLOOR(from_num + RAND() * (to_num - from_num + 1)); RETURN i;END$$#创建往emp表中插入数据的存储过程DELIMITER $$CREATE PROCEDURE insert_emp(START INT, max_num INT)BEGIN DECLARE i INT DEFAULT 0; SET autocommit = 0; #设置手动提交事务 REPEAT #循环 SET i = i + 1; #赋值 INSERT INTO emp (empno, NAME, age, deptid) VALUES ((START + i), rand_string(6), rand_num(30, 50), rand_num(1, 10000)); UNTIL i = max_num END REPEAT; COMMIT; #提交事务END$$#创建往dept表中插入数据的存储过程DELIMITER $$CREATE PROCEDURE `insert_dept`(max_num INT)BEGIN DECLARE i INT DEFAULT 0; SET autocommit = 0; REPEAT SET i = i + 1; INSERT INTO dept (deptname, address, ceo) VALUES (rand_string(8), rand_string(10), rand_num(1, 500000)); UNTIL i = max_num END REPEAT; COMMIT;END$$#执行存储过程，往dept表添加10万条数据CALL insert_dept(100000);#执行存储过程，往emp表添加500万条数据CALL insert_emp(100000, 5000000); 2.批量删除索引建立好的索引在哪里？ 12SHOW INDEX FROM t_emp ; -- 只能查看索引，但不能删除。information_schema.STATISTICS -- 存储索引的表（元数据库，统计表），我们可以对表数据进行删除操作。 知识点 删除某一个索引 1DROP INDEX idx_xxx ON emp 查出该表有哪些索引，索引名–&gt;集合 12345678SHOW INDEX FROM t_emp-- 元数据：meta DATA 描述数据的数据SELECT index_nameFROM information_schema.STATISTICSWHERE table_name = &#x27;t_emp&#x27; AND table_schema = &#x27;mydb&#x27; AND index_name &lt;&gt; &#x27;PRIMARY&#x27; AND seq_in_index = 1 3.单表使用索引建立索引 12CREATE INDEX idx_age_deptid_name ON emp(age,deptid,NAME);CREATE INDEX idx_name ON emp(NAME); 3.1 全值匹配1234567891011121314151617181920# 单表查询-全值匹配EXPLAINSELECT SQL_NO_CACHE *FROM empWHERE emp.age = 30;EXPLAINSELECT SQL_NO_CACHE *FROM empWHERE emp.age = 30 and deptid = 4;EXPLAINSELECT SQL_NO_CACHE *FROM empWHERE emp.age = 30 and deptid = 4 AND emp.name = &#x27;abcd&#x27;; 3.2 最左前缀法则12345678# 单表查询-左前缀法则EXPLAIN SELECT * FROM emp WHERE age=1 AND deptid=1 AND NAME=&#x27;aaa&#x27;;EXPLAIN SELECT * FROM emp WHERE age=1 AND deptid=1;EXPLAIN SELECT * FROM emp WHERE age=1 AND NAME=&#x27;aaa&#x27; AND deptid=1;EXPLAIN SELECT * FROM emp WHERE deptid=1 AND NAME =&#x27;aaa&#x27;; 过滤条件要使用索引必须按照索引建立时的顺序，依次满足，一旦跳过某个字段，索引后面的字段都无法被使用。 3.3 索引列上计算/函数导致索引失效1234# 单表查询-操作索引列导致索引失效EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.name LIKE &#x27;abc%&#x27;;EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE LEFT(emp.name,3) = &#x27;abc&#x27;; 3.4 范围查询导致的索引失效12345678EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.name = &#x27;abc&#x27; AND emp.deptId &gt; 20 AND emp.age = 30 ; 应用开发中范围查询，例如： 金额查询，日期查询往往都是范围查询。应将查询条件放置where语句最后。 3.5 不等于(!= 或者&lt;&gt;)索引失效1EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.name &lt;&gt; &#x27;abc&#x27; ; 3.6 is not null无法使用索引，is null可使用索引1234EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE age IS NULL;#用到索引 EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE age IS NOT NULL;#未用到索引 3.7 like以%开头索引失效1EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE NAME LIKE &#x27;%aaa&#x27;; 3.8 类型转换导致索引失效1EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE NAME=123; 设计实体类属性时，一定要与数据库字段类型相对应，否则会出现类型转换的情况，导致索引失效。 4. 关联查询优化4.1 左外连接1explain select * from emp left join dept on emp.deptId=dept.id; 这种情况下，驱动表无法避免全表扫描，但是因为被驱动表的主键存在索引并且是两张表关联查询的关联条件，所以可以避免被驱动表的全表扫描。 4.2 内连接(TODO)内连接MySQL会自动为我们选择驱动表。 123456explain select * from dept straight_join emp on emp.deptId=dept.id;## 1. dept 全表扫描 10w## 2. emp deptid refexplain select * from dept join emp on emp.deptId=dept.id;## 1. emp 500w## 2. dept id ref 保证被驱动表的join字段被索引 left join 时，选择小表作为驱动表，大表作为被驱动表 inner join 时，mysql会自动将小结果集的表选为驱动表。选择相信mysql优化策略。 子查询尽量不要放在被驱动表，衍生表建不了索引。 能够直接多表关联的尽量直接关联，不用子查询。 两张表的连接查询，比方说 left join right、inner join 等，他们的连表方式是什么？ 连表查询一共三种算法：nlj bnl bka 算法 。 right join 底层，会给你转化为left join。 4.3 子查询优化1234567891011121314151617181920212223#①不推荐explain SELECT *FROM empWHERE emp.id NOT IN -- not in 导致无法对in进行优化，用不了exists (SELECT dept.ceo FROM dept WHERE dept.ceo IS NOT NULL) ; -- is not null 导致索引失效#②推荐explain SELECT emp.*FROM emp LEFT JOIN dept ON emp.id = dept.ceo -- 如果ceo没有索引，两张表都是全表扫描，如果ceo有索引，被驱动表就是ref级别WHERE dept.id IS NULL ;# 尝试在ceo创建索引后，确实是 create index idx_ceo on dept(ceo); 尽量不要使用not in 或者 not exists，会使索引失效。 MySQL自动做出的子查询优化，物化子查询，转为半连接 物化子查询：把子查询的结果查出来后，建立一个临时表，“物化”-&gt;变成一张内存临时表 半连接：把子查询转化为类似连接查询的方式，但又不是真正的连接查询，所以叫 半 连接优化 5.排序分组优化5.1 无过滤，不索引1234EXPLAIN SELECT SQL_NO_CACHE * FROM emp ORDER BY age,deptid; #没用上索引，Using filesort EXPLAIN SELECT SQL_NO_CACHE * FROM emp ORDER BY age,deptid LIMIT 10; #使用上索引 null 因为order by的字段顺序和索引的顺序一样，所以此时会先尝试内存排序，但是因为上面的sql没有limit，导致内存放不下，使用了文件排序（文件系统级别，相当于在磁盘做排序），所以第一条sql效率更低。 order后面的字段想要使用索引，必须要有过滤条件，limit也行。 5.2顺序错，必排序1234567891011121314EXPLAIN SELECT * FROM emp WHERE age=45 ORDER BY deptid;# Using index conditionEXPLAIN SELECT * FROM emp WHERE age=45 ORDER BY deptid,NAME;# Using index conditionEXPLAIN SELECT * FROM emp WHERE age=45 ORDER BY deptid,empno;# Using index condition; Using filesortEXPLAIN SELECT * FROM emp WHERE age=45 ORDER BY NAME,deptid;# Using index condition; Using filesortEXPLAIN SELECT * FROM emp WHERE deptid=45 ORDER BY age;# Using where; Using filesort 在SQL语句中的顺序一定要和定义索引中的字段顺序完全一致。 5.3 方向反，必排序1234EXPLAIN SELECT * FROM emp WHERE age=45 ORDER BY deptid DESC, NAME DESC ;#Using whereEXPLAIN SELECT * FROM emp WHERE age=45 ORDER BY deptid ASC, NAME DESC ;#Using index condition; Using filesort ORDER BY子句，尽量使用Index方式排序，避免使用FileSort方式排序 要么全升序、要么全降序。有升有降无法使用索引。 5.4 索引的选择 两个索引同时存在，mysql自动选择最优的方案，但是，随着数据量的变化，选择的索引也会随之变化的。 所有的排序都是在条件过滤之后才执行的，所以，如果条件过滤掉大部分数据的话，剩下几百几千条数据进行排序其实并不是很消耗性能，即使索引优化了排序，但实际提升性能很有限。 当【范围条件】和【group by 或者 order by】的字段出现二选一时，优先观察条件字段的过滤数量，如果过滤的数据足够多，而需要排序的数据并不多时，优先把索引放在范围（过滤条件）字段上。反之，亦然。 扫描行数的多少，就是explain里的rows，可以说明一个需要扫描的行数多，一个扫描行数少，扫描行数多，代表成本高，扫描行数少代表成本少。优化器最终是对比成本值的大小来选取索引的。准确的说，是MySQL基于成本，优化器是在server层。 有时候优化器会选择错索引为什么？ 主要是出在优化器预估行数上，这个涉及到了一条sql的执行流程，语法分析，词法分析之后，进入优化阶段，由优化器进行优化，在优化阶段，会尽可能的生成全部的执行计划，然后对比一下哪一个成本值最低，就选它，所以优化器有一个选择索引，选择表的连接顺序的过程，索引不同，成本不同，读表顺序不同，成本不同，索引的选取，需要存储引擎提供统计信息，innodb中，统计信息是随机采样，随机选取8个索引页，取平均值，当做该索引的全部情况，也就是部分代表整体，也就是最终导致rows那里是个预估值，而不是准确的。所以有时候MySQL选错了索引，有一定概率，是由于这个随机采样造成的。而随机采样的不准确，是由于数据不断添加导致索引页的分裂，导致有些页内数据较少。 解决方案： 执行一下alter table +表名 就可以使统计信息稍微准确点，他会重新构建索引，使索引页保持紧凑，这个就是B+树的分裂。 调整参数，加大InnoDB采样的页数，页数越大越精确，但性能消耗更高。一般不建议这么干。 在优化阶段，会对表中所有索引进行对比，优化器基于成本的原因，选择成本最低的索引，所以会错过最佳索引。带来的问题便是，执行速度很慢。 解决方案： 通过explain查看执行计划，结合sql条件查看可以利用哪些索引。 使用 force index(indexName)强制走指定索引。弊端就是后期若索引名发生改变，或索引被删除，该sql语句需要调整。 5.5 双路排序&amp;单路排序如果不在索引列上，filesort有两种算法： mysql就要启动双路排序和单路排序。 双路排序 MySQL 4.1之前是使用双路排序，字面意思就是两次扫描磁盘，最终得到数据， 读取行指针和order by列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出 从磁盘取排序字段，在buffer进行排序，再从磁盘取其他字段。 取一批数据，要对磁盘进行两次扫描，众所周知，I\\O是很耗时的，所以在mysql4.1之后，出现了第二种改进的算法，就是单路排序。 单路排序 从磁盘读取查询需要的所有列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出， 它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO，但是它会使用更多的空间， 因为它把每一行都保存在内存中了。 结论 由于单路是后出的，总体而言好过双路。 但是用单路有问题： 在sort_buffer中，单路比多路要多占用很多空间，因为单路是把所有字段都取出, 所以有可能取出的数据的总大小超出了sort_buffer的容量，导致每次只能取sort_buffer容量大小的数据，进行排序（创建tmp文件，多路合并），排完再取sort_buffer容量大小，再排……从而多次I/O。 单路本来想省一次I/O操作，反而导致了大量的I/O操作，反而得不偿失。 优化策略 增大sort_buffer_size参数的设置 增大max_length_for_sort_data参数的设置 减少select 后面的查询的字段。 提高order by的速度 Order by时select * 是一个大忌。只Query需要的字段， 这点非常重要。 当Query的字段大小总和小于max_length_for_sort_data 而且排序字段不是 TEXT|BLOB 类型时，会用改进后的算法——单路排序， 否则用老算法——多路排序。 两种算法的数据都有可能超出sort_buffer的容量，超出之后，会创建tmp文件进行合并排序，导致多次I/O，但是用单路排序算法的风险会更大一些，所以要提高sort_buffer_size。 尝试提高 sort_buffer_size 不管用哪种算法，提高这个参数都会提高效率，当然，要根据系统的能力去提高，因为这个参数是针对每个进程（connection）的 1M-8M之间调整。 MySQL5.7，InnoDB存储引擎默认值是1048576字节，1MB。 1SHOW VARIABLES LIKE &#x27;%sort_buffer_size%&#x27;; 尝试提高 max_length_for_sort_data 提高这个参数， 会增加用改进算法的概率。 但是如果设的太高，数据总容量超出sort_buffer_size的概率就增大，明显症状是高的磁盘I/O活动和低的处理器使用率。如果需要返回的列的总长度大于max_length_for_sort_data，使用双路算法，否则使用单路算法。1024-8192字节之间调整。 1SHOW VARIABLES LIKE &#x27;%max_length_for_sort_data%&#x27;; #默认1024字节 5.6 分组优化group by 使用索引的原则几乎跟order by一致 ，唯一区别： group by 先排序再分组，遵照索引建的最佳左前缀法则 当无法使用索引列，增大max_length_for_sort_data和sort_buffer_size参数的设置 where高于having,能写在where限定的条件就不要写在having中了 group by没有过滤条件，也可以用上索引。Order By 必须有过滤条件才能使用上索引。 6. 覆盖索引禁止使用select *，禁止查询与业务无关字段，尽量使用覆盖索引，防止回表。 覆盖索引减少了 IO 次数，减少了数据的访问量，可以大大地提升查询效率。 四，追踪优化器前面的原理篇详细分析过，在此不再赘述。 五， 分库分表从维度来说分成两种，一种是垂直，一种是水平。 垂直切分：基于表或字段划分，表结构不同。我们有单库的分表，也有多库的分库。 水平切分：基于数据划分，表结构相同，数据不同，也有同库的水平切分和多库的切分。 1.垂直切分垂直分表有两种，一种是单库的，一种是多库的。 1.1 单库垂直分表单库分表，比如：商户信息表，拆分成基本信息表，联系方式表，结算信息表，附件表等等。 可以考虑根据冷热点字段拆分，是否经常发生修改操作拆分，根据字段功能拆分。 1.2 多库垂直分表多库垂直分表就是把原来存储在一个库的不同的表，拆分到不同的数据库。 比如电商平台的消费系统：一开始，商品表，商品详情表，订单表，用户表，支付记录表，库存表，风控表都在一个库里面，随着数据的增长和业务的扩张，可以考虑将商品和商品详情表单独放到一个库，订单表单独放到一个库，支付记录单独放到一个库，库存表单独放到一个库，风控表单独放到一个库。 当我们对原来的一张表做了分库的处理，如果某些业务系统的数据还是有一个非常快的增长速度，比如说订单数据库的订单表，数据量达到了几个亿，这个时候硬件限制导致的性能问题还是会出现，所以从这个角度来说垂直切分并没有从根本上解决单库单表数据量过大的问题。在这个时候，我们还需要对我们的数据做一个水平的切分。 2.水平拆分当我们的客户表数量已经到达数千万甚至上亿的时候，单表的存储容量和查询效率都会出现问题，我们需要进一步对单张表的数据进行水平切分。水平切分的每个数据库的表结构都是一样的，只是存储的数据不一样，比如每个库存储 1000 万的数据。 水平切分也可以分成两种，一种是单库的，一种是多库的。 2.1 单库水平分表银行的交易流水表，所有进出的交易都需要登记这张表，因为绝大部分时候客户都是查询当天的交易和一个月以内的交易数据，所以我们根据使用频率把这张表拆分成三张表： 当天表：只存储当天的数据。 当月表：在夜间运行一个定时任务，前一天的数据，全部迁移到当月表。用的是 insert into select，然后 delete。 历史表：同样是通过定时任务，把登记时间超过 30 天的数据，迁移到 history历史表（历史表的数据非常大，我们按照月度，每个月建立分区）。 跟分区一样，这种方式虽然可以一定程度解决单表查询性能的问题，但是并不能解决单机存储瓶颈的问题。 2.2 多库水平分表比如客户表，我们拆分到多个库存储，表结构是完全一样的。 一般我们说的分库分表都是跨库的分表。 3. 分库分表带来的问题3.1 跨库关联查询比如查询合同信息的时候要关联客户数据，由于是合同数据和客户数据是在不同的数据库，那么我们肯定不能直接使用 join 的这种方式去做关联查询。 解决方案 ①字段冗余比如我们查询合同库的合同表的时候需要关联客户库的客户表，我们可以直接把一些经常关联查询的客户字段放到合同表，通过这种方式避免跨库关联查询的问题。 ②数据同步比如商户系统要查询产品系统的产品表，我们干脆在商户系统创建一张产品表，通过 ETL 或者其他方式定时同步产品数据。 ③全局表（广播表）比如行名行号信息被很多业务系统用到，如果我们放在核心系统，每个系统都要去关联查询，这个时候我们可以在所有的数据库都存储相同的基础数据。 ④ER表我们有些表的数据是存在逻辑的主外键关系的，比如订单表 order_info，存的是汇总的商品数，商品金额；订单明细表 order_detail，是每个商品的价格，个数等等。或者叫做从属关系，父表和子表的关系。他们之间会经常有关联查询的操作，如果父表的数据和子表的数据分别存储在不同的数据库，跨库关联查询也比较麻烦。所以我们能不能把父表的数据和从属于父表的数据落到一个节点上呢？ 比如 order_id=1001 的数据在 node1，它所有的明细数据也放到 node1；order_id=1002 的数据在 node2，它所有的明细数据都放到 node2，这样在关联查询的时候依然是在一个数据库。 上面的思路都是通过合理的数据分布避免跨库关联查询，实际上在我们的业务中，也是尽量不要用跨库关联查询，如果出现了这种情况，就要分析一下业务或者数据拆分是不是合理。如果还是出现了需要跨库关联的情况，那我们就只能用最后一种办法。 ⑤系统层组装在不同的数据库节点把符合条件数据的数据查询出来，然后重新组装，返回给客户端。 3.2 分布式事务具体分布式事务会单独写一篇文章 3.3 排序，翻页，函数计算问题跨节点多库进行查询时，会出现 limit 分页，order by 排序的问题。比如有两个节点，节点 1 存的是奇数 id=1,3,5,7,9……；节点 2 存的是偶数 id=2,4,6,8,10…… 执行 select * from user_info order by id limit 0,10 需要在两个节点上各取出 10 条，然后合并数据，重新排序。 max、min、sum、count 之类的函数在进行计算的时候，也需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。 3.4 全局主键避重MySQL 的数据库里面字段有一个自增的属性，Oracle 也有 Sequence 序列。如果是一个数据库，那么可以保证 ID 是不重复的，但是水平分表以后，每个表都按照自己的规律自增，肯定会出现 ID 重复的问题，这个时候我们就不能用本地自增的方式了。 解决方案 ①UUIDUUID 标准形式包含 32 个 16 进制数字，分为 5 段，形式为 8-4-4-4-12 的 36 个字符，例如：c4e7956c-03e7-472c-8909-d733803e79a9。 UUID 是主键是最简单的方案，本地生成，性能高，没有网络耗时。但缺点也很明显，由于 UUID 非常长，会占用大量的存储空间；另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在 InnoDB 中，UUID 的无序性会引起数据位置频繁变动，导致分页。 ②数据库把序号维护在数据库的一张表中。这张表记录了全局主键的类型、位数、起始值，当前值。当其他应用需要获得全局 ID 时，先 for update 锁行，取到值+1 后并且更新后返回。并发性比较差。 ③redis基于 Redis 的 INT 自增的特性，使用批量的方式降低数据库的写压力，每次获取一段区间的 ID 号段，用完之后再去数据库获取，可以大大减轻数据库的压力。 ④雪花算法优点：毫秒数在高位，生成的 ID 整体上按时间趋势递增；不依赖第三方系统，稳定性和效率较高，理论上 QPS 约为 409.6w/s(1000*2^12)，并且整个分布式系统内不会产生 ID 碰撞；可根据自身业务灵活分配 bit 位。 不足就在于：强依赖机器时钟，如果时钟回拨，则可能导致生成 ID 重复。 4. 多数据源/读写数据源的解决方案分析一下 SQL 执行经过的流程： DAO——Mapper（ORM）——JDBC——代理——数据库服务 4.1 客户端DAO 层在我们连接到某一个数据源之前，我们先根据配置的分片规则，判断需要连接到哪些节点，再建立连接。 Spring 中提供了一个抽象类 AbstractRoutingDataSource，可以实现数据源的动态切换。 123456789101）aplication.properties 定义多个数据源2）创建@TargetDataSource 注解3）创建 DynamicDataSource 继承 AbstractRoutingDataSource4）多数据源配置类 DynamicDataSourceConfig5）创建切面类 DataSourceAspect，对添加了@TargetDataSource 注解的类进行拦截设置数据源。6）在 启 动 类 上 自 动 装 配 数 据 源 配 置@Import(&#123;DynamicDataSourceConfig.class&#125;)7）在 实 现 类 上 加 上 注 解 ， 如 @TargetDataSource(name =DataSourceNames.SECOND)，调用 在 DAO 层实现的优势：不需要依赖 ORM 框架，即使替换了 ORM 框架也不受影响。实现简单（不需要解析 SQL 和路由规则），可以灵活地定制。 缺点：不能复用，不能跨语言。 4.2 ORM框架层比如我们用 MyBatis 连接数据库，也可以指定数据源。我们可以基于 MyBatis 插件的拦截机制（拦截 query 和 update 方法），实现数据源的选择。 4.3 驱动层不管是MyBatis还是Hibernate，还是Spring的JdbcTemplate，本质上都是对JDBC的封装，所以第三层就是驱动层。比如 Sharding-JDBC，就是对 JDBC 的对象进行了封装。JDBC 的核心对象： DataSource：数据源 Connection：数据库连接 Statement：语句对象 ResultSet：结果集 那我们只要对这几个对象进行封装或者拦截或者代理，就可以实现分片的操作。 4.4 代理层前面三种都是在客户端实现的，也就是说不同的项目都要做同样的改动，不同的编程语言也有不同的实现，所以我们能不能把这种选择数据源和实现路由的逻辑提取出来，做成一个公共的服务给所有的客户端使用呢？ 这个就是第四层，代理层。比如 Mycat 和 Sharding-Proxy，都是属于这一层。 4.5 数据库服务某些特定的数据库或者数据库的特定版本可以实现这个功能。 六，主从复制1. 基本原理 MySQL复制过程分成三步： master将改变记录到二进制日志（binary log）。这些记录过程叫做二进制日志事件，binary log events； slave将master的binary log events拷贝到它的中继日志（relay log）； slave重做中继日志中的事件，将改变应用到自己的数据库中。 MySQL复制是异步的且串行化的，slave会从master读取binlog来进行数据同步。 2.与Redis主从复制的差别 redis主从复制是将主机的所有数据都拷贝给从机，并且是近乎实时的。 mysql主从复制不会将建立连接以前的数据发送给从机，并且是异步，且串行化的。 3.复制的基本原则每个slave只有一个master 每个slave只能有一个唯一的服务器ID 每个master可以有多个salve 4.复制的最大问题延时 全同步可以避免，但性能会极差，正常情况下半同步，且容忍一部分数据不一致。如果不容忍数据不一致，只有强制读主。 5.一主一从常见配置 MySQL版本一致且后台以服务运行 主从配置都在【mysqld】节点下，且全部小写 主机修改my.ini文件 主服务器唯一ID server-id=1 启用二进制日志 设置不要复制的数据库 设置需要复制的数据库 设置logbin格式 log-bin=自己的本地路径/data/mysqlbin binlog-ignore-db=mysql binlog-do-db=需要复制的主数据库名字 binlog_fromat=STATEMENT(默认) 七，硬件层面的配置1.选择合适的CPU数据库分为两大类，在线事务处理和在线分析处理。 InnoDB储存引擎一般应用于OLTP的数据库应用，这种应用的特点如下： 用户操作的并发量大 事务处理时间一般比较短 查询的语句较为简单，一般都走索引 复杂查询比较少 在当前的MySQL数据库版本中，一条SQL语句只能在一个CPU工作，并不支持多CPU。若cpu支持多核，innodb版本应该选择1.1或者更高。另外如果是多核cpu，可以通过修改参数innodb_read_io_threads和innodb_write_io_threads来增大IO的线程，这样也可以更充分的利用cpu的多核性能。 2.内存的重要性内存大小直接反映数据库的性能。Innodb存储引擎既缓存数据，又缓存索引，并且将它们缓存于一个很大的缓冲池中，即InnoDB Buffer Pool。因此，内存的大小直接影像数据库的性能。 3.磁盘对数据库性能的影响4.合理设置RAID类型5.操作系统的选择6.文件系统的选择","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[十]Explain&optimizer trace","slug":"MySQL/MySQL[十]Explain&optimizer trace","date":"2022-01-11T03:16:42.428Z","updated":"2022-01-11T03:24:05.355Z","comments":true,"path":"2022/01/11/MySQL/MySQL[十]Explain&optimizer trace/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E5%8D%81]Explain&optimizer%20trace/","excerpt":"","text":"一，Explain一条查询语句在经过MySQL查询优化器的各种基于成本和规则的优化会后生成一个所谓的执行计划，这个执行计划展示了接下来具体执行查询的方式，比如多表连接的顺序是什么，对于每个表采用什么访问方法来具体执行查询等等。MySQL为我们提供了EXPLAIN语句来帮助我们查看某个查询语句的具体执行计划，如果我们想看看某个查询的执行计划的话，可以在具体的查询语句前边加一个EXPLAIN，就像这样： 其实除了以SELECT开头的查询语句，其余的DELETE、INSERT、REPLACE以及UPDATE语句前边都可以加上EXPLAIN这个词儿，用来查看这些语句的执行计划，不过我们这里对SELECT语句更感兴趣，所以后边只会以SELECT语句为例来描述EXPLAIN语句的用法。我们先把EXPLAIN语句输出的各个列的作用先大致罗列一下： 列名 描述 id 在一个大的查询语句中每个SELECT关键字都对应一个唯一的id select_type SELECT关键字对应的那个查询的类型 table 表名 partitions 匹配的分区信息 type 针对单表的访问方法 possible_keys 可能用到的索引 key 实际上使用的索引 key_len 实际使用到的索引长度 ref 当使用索引列等值查询时，与索引列进行等值匹配的对象信息 rows 预估的需要读取的记录条数 filtered 某个表经过搜索条件过滤后剩余记录条数的百分比 Extra 一些额外的信息 我们前面创建过一张single_table表： 123456789101112131415CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3)) Engine=InnoDB CHARSET=utf8; 1.执行计划输出中各列详解table不论我们的查询语句有多复杂，里边儿包含了多少个表，到最后也是需要对每个表进行单表访问的，所以MySQL规定EXPLAIN语句输出的每条记录都对应着某个单表的访问方法，该条记录的table列代表着该表的表名。所以我们看一条比较简单的查询语句： 这个查询语句只涉及对s1表的单表查询，所以EXPLAIN输出中只有一条记录，其中的table列的值是s1，表明这条记录是用来说明对s1表的单表访问方法的。 下边我们看一下一个连接查询的执行计划： 可以看到这个连接查询的执行计划中有两条记录，这两条记录的table列分别是s1和s2，这两条记录用来分别说明对s1表和s2表的访问方法是什么。 id我们知道我们写的查询语句一般都以SELECT关键字开头，比较简单的查询语句里只有一个SELECT关键字，比如下边这个查询语句： 1SELECT * FROM s1 WHERE key1 = &#x27;a&#x27;; 稍微复杂一点的连接查询中也只有一个SELECT关键字，比如： 123SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key1 WHERE s1.common_field = &#x27;a&#x27;; 但是下边两种情况下在一条查询语句中会出现多个SELECT关键字： 查询中包含子查询的情况比如下边这个查询语句中就包含2个SELECT关键字： 12SELECT * FROM s1 WHERE key1 IN (SELECT key3 FROM s2); 查询中包含UNION语句的情况比如下边这个查询语句中也包含2个SELECT关键字： 1SELECT * FROM s1 UNION SELECT * FROM s2; 查询语句中每出现一个SELECT关键字，MySQL就会为它分配一个唯一的id值。这个id值就是EXPLAIN语句的第一个列，比如下边这个查询中只有一个SELECT关键字，所以EXPLAIN的结果中也就只有一条id列为1的记录： 对于连接查询来说，一个SELECT关键字后边的FROM子句中可以跟随多个表，所以在连接查询的执行计划中，每个表都会对应一条记录，但是这些记录的id值都是相同的，比如： 可以看到，上述连接查询中参与连接的s1和s2表分别对应一条记录，但是这两条记录对应的id值都是1。在连接查询的执行计划中，每个表都会对应一条记录，这些记录的id列的值是相同的，出现在前边的表表示驱动表，出现在后边的表表示被驱动表。所以从上边的EXPLAIN输出中我们可以看出，查询优化器准备让s1表作为驱动表，让s2表作为被驱动表来执行查询。 对于包含子查询的查询语句来说，就可能涉及多个SELECT关键字，所以在包含子查询的查询语句的执行计划中，每个SELECT关键字都会对应一个唯一的id值，比如这样： 从输出结果中我们可以看到，s1表在外层查询中，外层查询有一个独立的SELECT关键字，所以第一条记录的id值就是1，s2表在子查询中，子查询有一个独立的SELECT关键字，所以第二条记录的id值就是2。 查询优化器可能对涉及子查询的查询语句进行重写，从而转换为连接查询。所以如果我们想知道查询优化器对某个包含子查询的语句是否进行了重写，直接查看执行计划就好了，比如说： 虽然我们的查询语句是一个子查询，但是执行计划中s1和s2表对应的记录的id值全部是1，这就表明了查询优化器将子查询转换为了连接查询。 对于包含UNION子句的查询语句来说，每个SELECT关键字对应一个id值也是没错的，不过还是有点儿特别，比方说下边这个查询： 这个语句的执行计划的第三条记录是个什么？为什么id值是NULL，而且table名也不大对？UNION子句会把多个查询的结果集合并起来并对结果集中的记录进行去重，怎么去重呢？MySQL使用的是内部的临时表。正如上边的查询计划中所示，UNION子句是为了把id为1的查询和id为2的查询的结果集合并起来并去重，所以在内部创建了一个临时表（就是执行计划第三条记录的table列的名称），id为NULL表明这个临时表是为了合并两个查询的结果集而创建的。 跟UNION对比起来，UNION ALL就不需要为最终的结果集进行去重，它只是单纯的把多个查询的结果集中的记录合并成一个并返回给用户，所以也就不需要使用临时表。所以在包含UNION ALL子句的查询的执行计划中，就没有那个id为NULL的记录，如下所示： select_type通过上边的内容我们知道，一条大的查询语句里边可以包含若干个SELECT关键字，每个SELECT关键字代表着一个小的查询语句，而每个SELECT关键字的FROM子句中都可以包含若干张表（这些表用来做连接查询），每一张表都对应着执行计划输出中的一条记录，对于在同一个SELECT关键字中的表来说，它们的id值是相同的。 MySQL为每一个SELECT关键字代表的小查询都定义了一个称之为select_type的属性，意思是我们只要知道了某个小查询的select_type属性，就知道了这个小查询在整个大查询中有什么作用。 名称 描述 SIMPLE Simple SELECT (not using UNION or subqueries) PRIMARY Outermost SELECT UNION Second or later SELECT statement in a UNION UNION RESULT Result of a UNION SUBQUERY First SELECT in subquery DEPENDENT SUBQUERY First SELECT in subquery, dependent on outer query DEPENDENT UNION Second or later SELECT statement in a UNION, dependent on outer query DERIVED Derived table MATERIALIZED Materialized subquery UNCACHEABLE SUBQUERY A subquery for which the result cannot be cached and must be re-evaluated for each row of the outer query UNCACHEABLE UNION The second or later select in a UNION that belongs to an uncacheable subquery (see UNCACHEABLE SUBQUERY) SIMPLE查询语句中不包含UNION或者子查询的查询都算作是SIMPLE类型，比方说下边这个单表查询的select_type的值就是SIMPLE：当然，连接查询也算是SIMPLE类型，比如： PRIMARY对于包含UNION、UNION ALL或者子查询的大查询来说，它是由几个小查询组成的，其中最左边的那个查询的select_type值就是PRIMARY，比方说：从结果中可以看到，最左边的小查询SELECT * FROM s1对应的是执行计划中的第一条记录，它的select_type值就是PRIMARY。 UNION对于包含UNION或者UNION ALL的大查询来说，它是由几个小查询组成的，其中除了最左边的那个小查询以外，其余的小查询的select_type值就是UNION，可以对比上一个例子的效果，这就不多举例子了。 UNION RESULTMySQL选择使用临时表来完成UNION查询的去重工作，针对该临时表的查询的select_type就是UNION RESULT，例子上边有，就不赘述了。 SUBQUERY如果包含子查询的查询语句不能够转为对应的semi-join的形式，并且该子查询是不相关子查询，并且查询优化器决定采用将该子查询物化的方案来执行该子查询时，该子查询的第一个SELECT关键字代表的那个查询的select_type就是SUBQUERY，比如下边这个查询：可以看到，外层查询的select_type就是PRIMARY，子查询的select_type就是SUBQUERY。由于select_type为SUBQUERY的子查询会被物化，所以只需要执行一遍。 DEPENDENT SUBQUERY如果包含子查询的查询语句不能够转为对应的semi-join的形式，并且该子查询是相关子查询，则该子查询的第一个SELECT关键字代表的那个查询的select_type就是DEPENDENT SUBQUERY，比如下边这个查询： select_type为DEPENDENT SUBQUERY的查询可能会被执行多次。 DEPENDENT UNION在包含UNION或者UNION ALL的大查询中，如果各个小查询都依赖于外层查询的话，那除了最左边的那个小查询之外，其余的小查询的select_type的值就是DEPENDENT UNION。说的有些绕哈，比方说下边这个查询：这个查询比较复杂，大查询里包含了一个子查询，子查询里又是由UNION连起来的两个小查询。从执行计划中可以看出来，SELECT key1 FROM s2 WHERE key1 = &#39;a&#39;这个小查询由于是子查询中第一个查询，所以它的select_type是DEPENDENT SUBQUERY，而SELECT key1 FROM s1 WHERE key1 = &#39;b&#39;这个查询的select_type就是DEPENDENT UNION。 DERIVED对于采用物化的方式执行的包含派生表的查询，该派生表对应的子查询的select_type就是DERIVED，比方说下边这个查询：从执行计划中可以看出，id为2的记录就代表子查询的执行方式，它的select_type是DERIVED，说明该子查询是以物化的方式执行的。id为1的记录代表外层查询，它的table列显示的是``，表示该查询是针对将派生表物化之后的表进行查询的。 如果派生表可以通过和外层查询合并的方式执行的话，执行计划又是另一番景象。 MATERIALIZED当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询时，该子查询对应的select_type属性就是MATERIALIZED，比如下边这个查询：执行计划的第三条记录的id值为2，说明该条记录对应的是一个单表查询，从它的select_type值为MATERIALIZED可以看出，查询优化器是要把子查询先转换成物化表。然后看执行计划的前两条记录的id值都为1，说明这两条记录对应的表进行连接查询，需要注意的是第二条记录的table列的值是``，说明该表其实就是id为2对应的子查询执行之后产生的物化表，然后将s1和该物化表进行连接查询。 UNCACHEABLE SUBQUERY不常用 UNCACHEABLE UNION不常用 partitions一般情况下我们的查询语句的执行计划的partitions列的值都是NULL。 type执行计划的一条记录就代表着MySQL对某个表的执行查询时的访问方法，其中的type列就表明了这个访问方法是什么，比方说下边这个查询： 可以看到type列的值是ref，表明MySQL即将使用ref访问方法来执行对s1表的查询。但是我们之前只分析过对使用InnoDB存储引擎的表进行单表访问的一些访问方法，完整的访问方法如下：system，const，eq_ref，ref，fulltext，ref_or_null，index_merge，unique_subquery，index_subquery，range，index，ALL。接下来我们详细看一下： system当表中只有一条记录并且该表使用的存储引擎的统计数据是精确的，比如MyISAM、Memory，那么对该表的访问方法就是system。比方说我们新建一个MyISAM表，并为其插入一条记录：然后我们看一下查询这个表的执行计划：可以看到type列的值就是system了。 12345mysql&gt; CREATE TABLE t(i int) Engine=MyISAM;Query OK, 0 rows affected (0.05 sec)mysql&gt; INSERT INTO t VALUES(1);Query OK, 1 row affected (0.01 sec) 把表改成使用InnoDB存储引擎，执行计划的type列是ALL。 const当我们根据主键或者唯一二级索引列与常数进行等值匹配时，对单表的访问方法就是const，比如： eq_ref在连接查询时，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一二级索引是联合索引的话，所有的索引列都必须进行等值比较），则对该被驱动表的访问方法就是eq_ref，比方说：从执行计划的结果中可以看出，MySQL打算将s1作为驱动表，s2作为被驱动表，重点关注s2的访问方法是eq_ref，表明在访问s2表的时候可以通过主键的等值匹配来进行访问。 ref当通过普通的二级索引列与常量进行等值匹配时来查询某个表，那么对该表的访问方法就可能是ref。 fulltext全文索引,意义不大。 ref_or_null当对普通二级索引进行等值匹配查询，该索引列的值也可以是NULL值时，那么对该表的访问方法就可能是ref_or_null，比如说： index_merge在某些场景下可以使用Intersection、Union、Sort-Union这三种索引合并的方式来执行查询，我们看一下执行计划中是怎么体现MySQL使用索引合并的方式来对某个表执行查询的：从执行计划的type列的值是index_merge就可以看出，MySQL打算使用索引合并的方式来执行对s1表的查询。 unique_subquery类似于两表连接中被驱动表的eq_ref访问方法，unique_subquery是针对在一些包含IN子查询的查询语句中，如果查询优化器决定将IN子查询转换为EXISTS子查询，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的type列的值就是unique_subquery，比如下边的这个查询语句：可以看到执行计划的第二条记录的type值就是unique_subquery，说明在执行子查询时会使用到id列的索引。 index_subqueryindex_subquery与unique_subquery类似，只不过访问子查询中的表时使用的是普通的索引，比如这样： range如果使用索引获取某些范围区间的记录，那么就可能使用到range访问方法，比如下边的这个查询：或者： index当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是index，比如这样：上述查询中的搜索列表中只有key_part2一个列，而且搜索条件中也只有key_part3一个列，这两个列又恰好包含在idx_key_part这个索引中，可是搜索条件key_part3不能直接使用该索引进行ref或者range方式的访问，只能扫描整个idx_key_part索引的记录，所以查询计划的type列的值就是index。 对于使用InnoDB存储引擎的表来说，二级索引的记录只包含索引列和主键列的值，而聚簇索引中包含用户定义的全部列以及一些隐藏列，所以扫描二级索引的代价比直接全表扫描，也就是扫描聚簇索引的代价更低一些。 ALL最熟悉的全表扫描直接看例子： 一般来说，这些访问方法按照我们介绍它们的顺序性能依次变差。其中除了All这个访问方法外，其余的访问方法都能用到索引，除了index_merge访问方法外，其余的访问方法都最多只能用到一个索引。 possible_keys和key在EXPLAIN语句输出的执行计划中，possible_keys列表示在某个查询语句中，对某个表执行单表查询时可能用到的索引有哪些，key列表示实际用到的索引有哪些，比方说下边这个查询： 上述执行计划的possible_keys列的值是idx_key1,idx_key3，表示该查询可能使用到idx_key1,idx_key3两个索引，然后key列的值是idx_key3，表示经过查询优化器计算使用不同索引的成本后，最后决定使用idx_key3来执行查询比较划算。 不过有一点比较特别，就是在使用index访问方法来查询某个表时，possible_keys列是空的，而key列展示的是实际使用到的索引，比如这样： 另外需要注意的一点是，possible_keys列中的值并不是越多越好，可能使用的索引越多，查询优化器计算查询成本时就得花费更长时间，所以如果可以的话，尽量删除那些用不到的索引。 key_lenkey_len列表示当优化器决定使用某个索引执行查询时，该索引记录的最大长度，它是由这三个部分构成的： 对于使用固定长度类型的索引列来说，它实际占用的存储空间的最大长度就是该固定值，对于指定字符集的变长类型的索引列来说，比如某个索引列的类型是VARCHAR(100)，使用的字符集是utf8，那么该列实际占用的最大存储空间就是100 × 3 = 300个字节。 如果该索引列可以存储NULL值，则key_len比不可以存储NULL值时多1个字节。 对于变长字段来说，都会有2个字节的空间来存储该变长列的实际长度。 比如下边这个查询： 由于id列的类型是INT，并且不可以存储NULL值，所以在使用该列的索引时key_len大小就是4。当索引列可以存储NULL值时，比如： 可以看到key_len列就变成了5，比使用id列的索引时多了1。 对于可变长度的索引列来说，比如下边这个查询： 由于key1列的类型是VARCHAR(100)，所以该列实际最多占用的存储空间就是300字节，又因为该列允许存储NULL值，所以key_len需要加1，又因为该列是可变长度列，所以key_len需要加2，所以最后ken_len的值就是303。 这里需要强调的一点是，执行计划的生成是在MySQL server层中的功能，并不是针对具体某个存储引擎的功能，MySQL在执行计划中输出key_len列主要是为了让我们区分某个使用联合索引的查询具体用了几个索引列，而不是为了准确的说明针对某个具体存储引擎存储变长字段的实际长度占用的空间到底是占用1个字节还是2个字节。比方说下边这个使用到联合索引idx_key_part的查询： 我们可以从执行计划的key_len列中看到值是303，这意味着MySQL在执行上述查询中只能用到idx_key_part索引的一个索引列，而下边这个查询： 这个查询的执行计划的ken_len列的值是606，说明执行这个查询的时候可以用到联合索引idx_key_part的两个索引列。 ref当使用索引列等值匹配的条件去执行查询时，也就是在访问方法是const、eq_ref、ref、ref_or_null、unique_subquery、index_subquery其中之一时，ref列展示的就是与索引列作等值匹配的东东是个啥，比如只是一个常数或者是某个列。 可以看到ref列的值是const，表明在使用idx_key1索引执行查询时，与key1列作等值匹配的对象是一个常数，当然有时候更复杂一点： 可以看到对被驱动表s2的访问方法是eq_ref，而对应的ref列的值是yhd.s1.id，这说明在对被驱动表进行访问时会用到PRIMARY索引，也就是聚簇索引与一个列进行等值匹配的条件，于s2表的id作等值匹配的对象就是yhd.s1.id列（注意这里把数据库名也写出来了）。 有的时候与索引列进行等值匹配的对象是一个函数，比方说下边这个查询： 我们看执行计划的第二条记录，可以看到对s2表采用ref访问方法执行查询，然后在查询计划的ref列里输出的是func，说明与s2表的key1列进行等值匹配的对象是一个函数。 rows如果查询优化器决定使用全表扫描的方式对某个表执行查询时，执行计划的rows列就代表预计需要扫描的行数，如果使用索引来执行查询时，执行计划的rows列就代表预计扫描的索引记录行数。比如下边这个查询： 我们看到执行计划的rows列的值是1，这意味着查询优化器在经过分析使用idx_key1进行查询的成本之后，觉得满足key1 &gt; &#39;z&#39;这个条件的记录只有1条。 filtered之前在分析连接查询的成本时提出过一个condition filtering的概念，就是MySQL在计算驱动表扇出时采用的一个策略： 如果使用的是全表扫描的方式执行的单表查询，那么计算驱动表扇出时需要估计出满足搜索条件的记录到底有多少条。 如果使用的是索引执行的单表扫描，那么计算驱动表扇出的时候需要估计出满足除使用到对应索引的搜索条件外的其他搜索条件的记录有多少条。 比方说下边这个查询： 从执行计划的key列中可以看出来，该查询使用idx_key1索引来执行查询，从rows列可以看出满足key1 &gt; &#39;z&#39;的记录有1条。执行计划的filtered列就代表查询优化器预测在这1条记录中，有多少条记录满足其余的搜索条件，也就是common_field = &#39;a&#39;这个条件的百分比。此处filtered列的值是10.00，说明查询优化器预测在1条记录中有10.00%的记录满足common_field = &#39;a&#39;这个条件。 对于单表查询来说，这个filtered列的值没什么意义，我们更关注在连接查询中驱动表对应的执行计划记录的filtered值，比方说下边这个查询： 从执行计划中可以看出来，查询优化器打算把s1当作驱动表，s2当作被驱动表。我们可以看到驱动表s1表的执行计划的rows列为997219， filtered列为10.00，这意味着驱动表s1的扇出值就是997219 × 10.00% = 99721.9，这说明还要对被驱动表执行大约99721.9次查询。 Extra顾名思义，Extra列是用来说明一些额外信息的，我们可以通过这些额外信息来更准确的理解MySQL到底将如何执行给定的查询语句。 No tables used当查询语句的没有FROM子句时将会提示该额外信息，比如： Impossible WHERE查询语句的WHERE子句永远为FALSE时将会提示该额外信息，比方说： No matching min/max row当查询列表处有MIN或者MAX聚集函数，但是并没有符合WHERE子句中的搜索条件的记录时，将会提示该额外信息，比方说： Using index当我们的查询列表以及搜索条件中只包含属于某个索引的列，也就是在可以使用索引覆盖的情况下，在Extra列将会提示该额外信息。比方说下边这个查询中只需要用到idx_key1而不需要回表操作： Using index condition有些搜索条件中虽然出现了索引列，但却不能使用到索引，比如下边这个查询：其中的key1 &gt; &#39;z&#39;可以使用到索引，但是key1 LIKE &#39;%a&#39;却无法使用到索引，在以前版本的MySQL中，是按照下边步骤来执行这个查询的： 1SELECT * FROM s1 WHERE key1 &gt; &#x27;z&#x27; AND key1 LIKE &#x27;%a&#x27;; 先根据key1 &gt; &#39;z&#39;这个条件，从二级索引idx_key1中获取到对应的二级索引记录。 根据上一步骤得到的二级索引记录中的主键值进行回表，找到完整的用户记录再检测该记录是否符合key1 LIKE &#39;%a&#39;这个条件，将符合条件的记录加入到最后的结果集。 但是虽然key1 LIKE &#39;%a&#39;不能组成范围区间参与range访问方法的执行，但这个条件毕竟只涉及到了key1列，所以MySQL把上边的步骤改进了一下： 先根据key1 &gt; &#39;z&#39;这个条件，定位到二级索引idx_key1中对应的二级索引记录。 对于指定的二级索引记录，先不着急回表，而是先检测一下该记录是否满足key1 LIKE &#39;%a&#39;这个条件，如果这个条件不满足，则该二级索引记录压根儿就没必要回表。 对于满足key1 LIKE &#39;%a&#39;这个条件的二级索引记录执行回表操作。 我们说回表操作其实是一个随机IO，比较耗时，所以上述修改虽然只改进了一点点，但是可以省去好多回表操作的成本。MySQL把他们的这个改进称之为索引条件下推（英文名：Index Condition Pushdown）。如果在查询语句的执行过程中将要使用索引条件下推这个特性，在Extra列中将会显示Using index condition，比如这样： Using where当我们使用全表扫描来执行对某个表的查询，并且该语句的WHERE子句中有针对该表的搜索条件时，在Extra列中会提示上述额外信息。比如下边这个查询：当使用索引访问来执行对某个表的查询，并且该语句的WHERE子句中有除了该索引包含的列之外的其他搜索条件时，在Extra列中也会提示上述额外信息。比如下边这个查询虽然使用idx_key1索引执行查询，但是搜索条件中除了包含key1的搜索条件key1 = &#39;a&#39;，还有包含common_field的搜索条件，所以Extra列会显示Using where的提示： Using join buffer (Block Nested Loop)在连接查询执行过程中，当被驱动表不能有效的利用索引加快访问速度，MySQL一般会为其分配一块名叫join buffer的内存块来加快查询速度，也就是我们所讲的基于块的嵌套循环算法，比如下边这个查询语句：可以在对s2表的执行计划的Extra列显示了两个提示： Using join buffer (Block Nested Loop)：这是因为对表s2的访问不能有效利用索引，只好退而求其次，使用join buffer来减少对s2表的访问次数，从而提高性能。 Using where：可以看到查询语句中有一个s1.common_field = s2.common_field条件，因为s1是驱动表，s2是被驱动表，所以在访问s2表时，s1.common_field的值已经确定下来了，所以实际上查询s2表的条件就是s2.common_field = 一个常数，所以提示了Using where额外信息。 Not exists当我们使用左（外）连接时，如果WHERE子句中包含要求被驱动表的某个列等于NULL值的搜索条件，而且那个列又是不允许存储NULL值的，那么在该表的执行计划的Extra列就会提示Not exists额外信息，比如这样：上述查询中s1表是驱动表，s2表是被驱动表，s2.id列是不允许存储NULL值的，而WHERE子句中又包含s2.id IS NULL的搜索条件，这意味着必定是驱动表的记录在被驱动表中找不到匹配ON子句条件的记录才会把该驱动表的记录加入到最终的结果集，所以对于某条驱动表中的记录来说，如果能在被驱动表中找到1条符合ON子句条件的记录，那么该驱动表的记录就不会被加入到最终的结果集，也就是说我们没有必要到被驱动表中找到全部符合ON子句条件的记录，这样可以稍微节省一点性能。 右（外）连接可以被转换为左（外）连接，所以就不提右（外）连接的情况了。 Using intersect(...)、Using union(...)和Using sort_union(...)如果执行计划的Extra列出现了Using intersect(...)提示，说明准备使用Intersect索引合并的方式执行查询，括号中的...表示需要进行索引合并的索引名称；如果出现了Using union(...)提示，说明准备使用Union索引合并的方式执行查询；出现了Using sort_union(...)提示，说明准备使用Sort-Union索引合并的方式执行查询。比如这个查询的执行计划：其中Extra列就显示了Using intersect(idx_key3,idx_key1)，表明MySQL即将使用idx_key3和idx_key1这两个索引进行Intersect索引合并的方式执行查询。 Zero limit当我们的LIMIT子句的参数为0时，表示不打算从表中读出任何记录，将会提示该额外信息，比如这样： Using filesort有一些情况下对结果集中的记录进行排序是可以使用到索引的，比如下边这个查询：这个查询语句可以利用idx_key1索引直接取出key1列的10条记录，然后再进行回表操作就好了。但是很多情况下排序操作无法使用到索引，只能在内存中（记录较少的时候）或者磁盘中（记录较多的时候）进行排序，MySQL把这种在内存中或者磁盘上进行排序的方式统称为文件排序（英文名：filesort）。如果某个查询需要使用文件排序的方式执行查询，就会在执行计划的Extra列中显示Using filesort提示，比如这样：需要注意的是，如果查询中需要使用filesort的方式进行排序的记录非常多，那么这个过程是很耗费性能的，我们最好想办法将使用文件排序的执行方式改为使用索引进行排序。 Using temporary在许多查询的执行过程中，MySQL可能会借助临时表来完成一些功能，比如去重、排序之类的，比如我们在执行许多包含DISTINCT、GROUP BY、UNION等子句的查询过程中，如果不能有效利用索引来完成查询，MySQL很有可能寻求通过建立内部的临时表来执行查询。如果查询中使用到了内部的临时表，在执行计划的Extra列将会显示Using temporary提示，比方说这样：再比如：不知道大家注意到没有，上述执行计划的Extra列不仅仅包含Using temporary提示，还包含Using filesort提示，可是我们的查询语句中明明没有写ORDER BY子句呀？这是因为MySQL会在包含GROUP BY子句的查询中默认添加上ORDER BY子句，也就是说上述查询其实和下边这个查询等价： 1EXPLAIN SELECT common_field, COUNT(*) AS amount FROM s1 GROUP BY common_field ORDER BY common_field; 如果我们并不想为包含GROUP BY子句的查询进行排序，需要我们显式的写上ORDER BY NULL，就像这样：​ ​ 这回执行计划中就没有Using filesort的提示了，也就意味着执行查询时可以省去对记录进行文件排序的成本了。​ 另外，执行计划中出现Using temporary并不是一个好的征兆，因为建立与维护临时表要付出很大成本的，所以我们最好能使用索引来替代掉使用临时表，比方说下边这个包含GROUP BY子句的查询就不需要使用临时表：​ ​ 从Extra的Using index的提示里我们可以看出，上述查询只需要扫描idx_key1索引就可以搞定了，不再需要临时表了。 Start temporary, End temporary查询优化器会优先尝试将IN子查询转换成semi-join，而semi-join又有好多种执行策略，当执行策略为DuplicateWeedout时，也就是通过建立临时表来实现为外层查询中的记录进行去重操作时，驱动表查询执行计划的Extra列将显示Start temporary提示，被驱动表查询执行计划的Extra列将显示End temporary提示，就是这样： LooseScan在将In子查询转为semi-join时，如果采用的是LooseScan执行策略，则在驱动表执行计划的Extra列就是显示LooseScan提示，比如这样： FirstMatch(tbl_name)在将In子查询转为semi-join时，如果采用的是FirstMatch执行策略，则在被驱动表执行计划的Extra列就是显示FirstMatch(tbl_name)提示，比如这样： 2.Json格式的执行计划我们上边介绍的EXPLAIN语句输出中缺少了一个衡量执行计划好坏的重要属性 —— 成本。不过MySQL贴心的为我们提供了一种查看某个执行计划花费的成本的方式： 在EXPLAIN单词和真正的查询语句中间加上FORMAT=JSON。 这样我们就可以得到一个json格式的执行计划，里边儿包含该计划花费的成本，比如这样： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586mysql&gt; EXPLAIN FORMAT=JSON SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key2 WHERE s1.common_field = &#x27;a&#x27;\\G*************************** 1. row ***************************EXPLAIN: &#123; &quot;query_block&quot;: &#123; &quot;select_id&quot;: 1, # 整个查询语句只有1个SELECT关键字，该关键字对应的id号为1 &quot;cost_info&quot;: &#123; &quot;query_cost&quot;: &quot;3197.16&quot; # 整个查询的执行成本预计为3197.16 &#125;, &quot;nested_loop&quot;: [ # 几个表之间采用嵌套循环连接算法执行 # 以下是参与嵌套循环连接算法的各个表的信息 &#123; &quot;table&quot;: &#123; &quot;table_name&quot;: &quot;s1&quot;, # s1表是驱动表 &quot;access_type&quot;: &quot;ALL&quot;, # 访问方法为ALL，意味着使用全表扫描访问 &quot;possible_keys&quot;: [ # 可能使用的索引 &quot;idx_key1&quot; ], &quot;rows_examined_per_scan&quot;: 9688, # 查询一次s1表大致需要扫描9688条记录 &quot;rows_produced_per_join&quot;: 968, # 驱动表s1的扇出是968 &quot;filtered&quot;: &quot;10.00&quot;, # condition filtering代表的百分比 &quot;cost_info&quot;: &#123; &quot;read_cost&quot;: &quot;1840.84&quot;, # 稍后解释 &quot;eval_cost&quot;: &quot;193.76&quot;, # 稍后解释 &quot;prefix_cost&quot;: &quot;2034.60&quot;, # 单次查询s1表总共的成本 &quot;data_read_per_join&quot;: &quot;1M&quot; # 读取的数据量 &#125;, &quot;used_columns&quot;: [ # 执行查询中涉及到的列 &quot;id&quot;, &quot;key1&quot;, &quot;key2&quot;, &quot;key3&quot;, &quot;key_part1&quot;, &quot;key_part2&quot;, &quot;key_part3&quot;, &quot;common_field&quot; ], # 对s1表访问时针对单表查询的条件 &quot;attached_condition&quot;: &quot;((`xiaohaizi`.`s1`.`common_field` = &#x27;a&#x27;) and (`xiaohaizi`.`s1`.`key1` is not null))&quot; &#125; &#125;, &#123; &quot;table&quot;: &#123; &quot;table_name&quot;: &quot;s2&quot;, # s2表是被驱动表 &quot;access_type&quot;: &quot;ref&quot;, # 访问方法为ref，意味着使用索引等值匹配的方式访问 &quot;possible_keys&quot;: [ # 可能使用的索引 &quot;idx_key2&quot; ], &quot;key&quot;: &quot;idx_key2&quot;, # 实际使用的索引 &quot;used_key_parts&quot;: [ # 使用到的索引列 &quot;key2&quot; ], &quot;key_length&quot;: &quot;5&quot;, # key_len &quot;ref&quot;: [ # 与key2列进行等值匹配的对象 &quot;xiaohaizi.s1.key1&quot; ], &quot;rows_examined_per_scan&quot;: 1, # 查询一次s2表大致需要扫描1条记录 &quot;rows_produced_per_join&quot;: 968, # 被驱动表s2的扇出是968（由于后边没有多余的表进行连接，所以这个值也没啥用） &quot;filtered&quot;: &quot;100.00&quot;, # condition filtering代表的百分比 # s2表使用索引进行查询的搜索条件 &quot;index_condition&quot;: &quot;(`xiaohaizi`.`s1`.`key1` = `xiaohaizi`.`s2`.`key2`)&quot;, &quot;cost_info&quot;: &#123; &quot;read_cost&quot;: &quot;968.80&quot;, # 稍后解释 &quot;eval_cost&quot;: &quot;193.76&quot;, # 稍后解释 &quot;prefix_cost&quot;: &quot;3197.16&quot;, # 单次查询s1、多次查询s2表总共的成本 &quot;data_read_per_join&quot;: &quot;1M&quot; # 读取的数据量 &#125;, &quot;used_columns&quot;: [ # 执行查询中涉及到的列 &quot;id&quot;, &quot;key1&quot;, &quot;key2&quot;, &quot;key3&quot;, &quot;key_part1&quot;, &quot;key_part2&quot;, &quot;key_part3&quot;, &quot;common_field&quot; ] &#125; &#125; ] &#125;&#125;1 row in set, 2 warnings (0.00 sec) &quot;cost_info&quot;里边的成本是怎么计算出来的？先看s1表的&quot;cost_info&quot;部分： 123456&quot;cost_info&quot;: &#123; &quot;read_cost&quot;: &quot;1840.84&quot;, &quot;eval_cost&quot;: &quot;193.76&quot;, &quot;prefix_cost&quot;: &quot;2034.60&quot;, &quot;data_read_per_join&quot;: &quot;1M&quot;&#125; read_cost是由下边这两部分组成的： IO成本 检测rows × (1 - filter)条记录的CPU成本 rows和filter都是我们前边介绍执行计划的输出列，在JSON格式的执行计划中，rows相当于rows_examined_per_scan，filtered名称不变。 eval_cost是这样计算的：检测 rows × filter条记录的成本。 prefix_cost就是单独查询s1表的成本，也就是：read_cost + eval_cost data_read_per_join表示在此次查询中需要读取的数据量，我们就不多唠叨这个了。 其实没必要关注MySQL为啥使用这么古怪的方式计算出read_cost和eval_cost，关注prefix_cost是查询s1表的成本就好了。 对于s2表的&quot;cost_info&quot;部分是这样的： 123456&quot;cost_info&quot;: &#123; &quot;read_cost&quot;: &quot;968.80&quot;, &quot;eval_cost&quot;: &quot;193.76&quot;, &quot;prefix_cost&quot;: &quot;3197.16&quot;, &quot;data_read_per_join&quot;: &quot;1M&quot;&#125; 由于s2表是被驱动表，所以可能被读取多次，这里的read_cost和eval_cost是访问多次s2表后累加起来的值，主要关注里边儿的prefix_cost的值代表的是整个连接查询预计的成本，也就是单次查询s1表和多次查询s2表后的成本的和，也就是： 1968.80 + 193.76 + 2034.60 = 3197.16 3.Extented EXPLAIN在我们使用EXPLAIN语句查看了某个查询的执行计划后，紧接着还可以使用SHOW WARNINGS语句查看与这个查询的执行计划有关的一些扩展信息，比如这样： 可以看到SHOW WARNINGS展示出来的信息有三个字段，分别是Level、Code、Message。我们最常见的就是Code为1003的信息，当Code值为1003时，Message字段展示的信息类似于查询优化器将我们的查询语句重写后的语句。比如我们上边的查询本来是一个左（外）连接查询，但是有一个s2.common_field IS NOT NULL的条件，着就会导致查询优化器把左（外）连接查询优化为内连接查询，从SHOW WARNINGS的Message字段也可以看出来，原本的LEFT JOIN已经变成了JOIN。 我们说Message字段展示的信息类似于查询优化器将我们的查询语句重写后的语句，并不是等价于，也就是说Message字段展示的信息并不是标准的查询语句，在很多情况下并不能直接运行，它只能作为帮助我们理解查MySQL将如何执行查询语句的一个参考依据而已。 二，optimizer trace对于MySQL 5.6以及之前的版本来说，查询优化器就像是一个黑盒子一样，只能通过EXPLAIN语句查看到最后优化器决定使用的执行计划，却无法知道它为什么做这个决策。 在MySQL 5.6以及之后的版本中，MySQL提出了一个optimizer trace的功能，这个功能可以让我们方便的查看优化器生成执行计划的整个过程，这个功能的开启与关闭由系统变量optimizer_trace决定，我们看一下： 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;optimizer_trace&#x27;;+-----------------+--------------------------+| Variable_name | Value |+-----------------+--------------------------+| optimizer_trace | enabled=off,one_line=off |+-----------------+--------------------------+1 row in set (0.02 sec) 可以看到enabled值为off，表明这个功能默认是关闭的。 one_line的值是控制输出格式的，如果为on那么所有输出都将在一行中展示，不适合人阅读，所以我们就保持其默认值为off吧。 如果想打开这个功能，必须首先把enabled的值改为on，就像这样： 12mysql&gt; SET optimizer_trace=&quot;enabled=on&quot;;Query OK, 0 rows affected (0.00 sec) 然后我们就可以输入我们想要查看优化过程的查询语句，当该查询语句执行完成后，就可以到information_schema数据库下的OPTIMIZER_TRACE表中查看完整的优化过程。这个OPTIMIZER_TRACE表有4个列，分别是： QUERY：表示我们的查询语句。 TRACE：表示优化过程的JSON格式文本。 MISSING_BYTES_BEYOND_MAX_MEM_SIZE：由于优化过程可能会输出很多，如果超过某个限制时，多余的文本将不会被显示，这个字段展示了被忽略的文本字节数。 INSUFFICIENT_PRIVILEGES：表示是否没有权限查看优化过程，默认值是0，只有某些特殊情况下才会是1，我们暂时不关心这个字段的值。 完整的使用optimizer trace功能的步骤总结如下： 1234567891011121314# 1. 打开optimizer trace功能 (默认情况下它是关闭的):SET optimizer_trace=&quot;enabled=on&quot;;# 2. 这里输入查询语句SELECT ...; # 3. 从OPTIMIZER_TRACE表中查看上一个查询的优化过程SELECT * FROM information_schema.OPTIMIZER_TRACE;# 4. 可能还要观察其他语句执行的优化过程，重复上边的第2、3步...# 5. 当停止查看语句的优化过程时，把optimizer trace功能关闭SET optimizer_trace=&quot;enabled=off&quot;; 现在我们有一个搜索条件比较多的查询语句，它的执行计划如下： 可以看到该查询可能使用到的索引有3个，那么为什么优化器最终选择了idx_key2而不选择其他的索引或者直接全表扫描呢？这时候就可以通过otpimzer trace功能来查看优化器的具体工作过程： 123456789SET optimizer_trace=&quot;enabled=on&quot;;SELECT * FROM s1 WHERE key1 &gt; &#x27;z&#x27; AND key2 &lt; 1000000 AND key3 IN (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;) AND common_field = &#x27;abc&#x27;; SELECT * FROM information_schema.OPTIMIZER_TRACE\\G 直接看一下通过查询OPTIMIZER_TRACE表得到的输出： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281*************************** 1. row ***************************# 分析的查询语句是什么QUERY: SELECT * FROM s1 WHERE key1 &gt; &#x27;z&#x27; AND key2 &lt; 1000000 AND key3 IN (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;) AND common_field = &#x27;abc&#x27;# 优化的具体过程TRACE: &#123; &quot;steps&quot;: [ &#123; &quot;join_preparation&quot;: &#123; # prepare阶段 &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;IN_uses_bisection&quot;: true &#125;, &#123; &quot;expanded_query&quot;: &quot;/* select#1 */ select `s1`.`id` AS `id`,`s1`.`key1` AS `key1`,`s1`.`key2` AS `key2`,`s1`.`key3` AS `key3`,`s1`.`key_part1` AS `key_part1`,`s1`.`key_part2` AS `key_part2`,`s1`.`key_part3` AS `key_part3`,`s1`.`common_field` AS `common_field` from `s1` where ((`s1`.`key1` &gt; &#x27;z&#x27;) and (`s1`.`key2` &lt; 1000000) and (`s1`.`key3` in (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)) and (`s1`.`common_field` = &#x27;abc&#x27;))&quot; &#125; ] /* steps */ &#125; /* join_preparation */ &#125;, &#123; &quot;join_optimization&quot;: &#123; # optimize阶段 &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;condition_processing&quot;: &#123; # 处理搜索条件 &quot;condition&quot;: &quot;WHERE&quot;, # 原始搜索条件 &quot;original_condition&quot;: &quot;((`s1`.`key1` &gt; &#x27;z&#x27;) and (`s1`.`key2` &lt; 1000000) and (`s1`.`key3` in (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)) and (`s1`.`common_field` = &#x27;abc&#x27;))&quot;, &quot;steps&quot;: [ &#123; # 等值传递转换 &quot;transformation&quot;: &quot;equality_propagation&quot;, &quot;resulting_condition&quot;: &quot;((`s1`.`key1` &gt; &#x27;z&#x27;) and (`s1`.`key2` &lt; 1000000) and (`s1`.`key3` in (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)) and (`s1`.`common_field` = &#x27;abc&#x27;))&quot; &#125;, &#123; # 常量传递转换 &quot;transformation&quot;: &quot;constant_propagation&quot;, &quot;resulting_condition&quot;: &quot;((`s1`.`key1` &gt; &#x27;z&#x27;) and (`s1`.`key2` &lt; 1000000) and (`s1`.`key3` in (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)) and (`s1`.`common_field` = &#x27;abc&#x27;))&quot; &#125;, &#123; # 去除没用的条件 &quot;transformation&quot;: &quot;trivial_condition_removal&quot;, &quot;resulting_condition&quot;: &quot;((`s1`.`key1` &gt; &#x27;z&#x27;) and (`s1`.`key2` &lt; 1000000) and (`s1`.`key3` in (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)) and (`s1`.`common_field` = &#x27;abc&#x27;))&quot; &#125; ] /* steps */ &#125; /* condition_processing */ &#125;, &#123; # 替换虚拟生成列 &quot;substitute_generated_columns&quot;: &#123; &#125; /* substitute_generated_columns */ &#125;, &#123; # 表的依赖信息 &quot;table_dependencies&quot;: [ &#123; &quot;table&quot;: &quot;`s1`&quot;, &quot;row_may_be_null&quot;: false, &quot;map_bit&quot;: 0, &quot;depends_on_map_bits&quot;: [ ] /* depends_on_map_bits */ &#125; ] /* table_dependencies */ &#125;, &#123; &quot;ref_optimizer_key_uses&quot;: [ ] /* ref_optimizer_key_uses */ &#125;, &#123; # 预估不同单表访问方法的访问成本 &quot;rows_estimation&quot;: [ &#123; &quot;table&quot;: &quot;`s1`&quot;, &quot;range_analysis&quot;: &#123; &quot;table_scan&quot;: &#123; # 全表扫描的行数以及成本 &quot;rows&quot;: 9688, &quot;cost&quot;: 2036.7 &#125; /* table_scan */, # 分析可能使用的索引 &quot;potential_range_indexes&quot;: [ &#123; &quot;index&quot;: &quot;PRIMARY&quot;, # 主键不可用 &quot;usable&quot;: false, &quot;cause&quot;: &quot;not_applicable&quot; &#125;, &#123; &quot;index&quot;: &quot;idx_key2&quot;, # idx_key2可能被使用 &quot;usable&quot;: true, &quot;key_parts&quot;: [ &quot;key2&quot; ] /* key_parts */ &#125;, &#123; &quot;index&quot;: &quot;idx_key1&quot;, # idx_key1可能被使用 &quot;usable&quot;: true, &quot;key_parts&quot;: [ &quot;key1&quot;, &quot;id&quot; ] /* key_parts */ &#125;, &#123; &quot;index&quot;: &quot;idx_key3&quot;, # idx_key3可能被使用 &quot;usable&quot;: true, &quot;key_parts&quot;: [ &quot;key3&quot;, &quot;id&quot; ] /* key_parts */ &#125;, &#123; &quot;index&quot;: &quot;idx_key_part&quot;, # idx_keypart不可用 &quot;usable&quot;: false, &quot;cause&quot;: &quot;not_applicable&quot; &#125; ] /* potential_range_indexes */, &quot;setup_range_conditions&quot;: [ ] /* setup_range_conditions */, &quot;group_index_range&quot;: &#123; &quot;chosen&quot;: false, &quot;cause&quot;: &quot;not_group_by_or_distinct&quot; &#125; /* group_index_range */, # 分析各种可能使用的索引的成本 &quot;analyzing_range_alternatives&quot;: &#123; &quot;range_scan_alternatives&quot;: [ &#123; # 使用idx_key2的成本分析 &quot;index&quot;: &quot;idx_key2&quot;, # 使用idx_key2的范围区间 &quot;ranges&quot;: [ &quot;NULL &lt; key2 &lt; 1000000&quot; ] /* ranges */, &quot;index_dives_for_eq_ranges&quot;: true, # 是否使用index dive &quot;rowid_ordered&quot;: false, # 使用该索引获取的记录是否按照主键排序 &quot;using_mrr&quot;: false, # 是否使用mrr &quot;index_only&quot;: false, # 是否是索引覆盖访问 &quot;rows&quot;: 12, # 使用该索引获取的记录条数 &quot;cost&quot;: 15.41, # 使用该索引的成本 &quot;chosen&quot;: true # 是否选择该索引 &#125;, &#123; # 使用idx_key1的成本分析 &quot;index&quot;: &quot;idx_key1&quot;, # 使用idx_key1的范围区间 &quot;ranges&quot;: [ &quot;z &lt; key1&quot; ] /* ranges */, &quot;index_dives_for_eq_ranges&quot;: true, # 同上 &quot;rowid_ordered&quot;: false, # 同上 &quot;using_mrr&quot;: false, # 同上 &quot;index_only&quot;: false, # 同上 &quot;rows&quot;: 266, # 同上 &quot;cost&quot;: 320.21, # 同上 &quot;chosen&quot;: false, # 同上 &quot;cause&quot;: &quot;cost&quot; # 因为成本太大所以不选择该索引 &#125;, &#123; # 使用idx_key3的成本分析 &quot;index&quot;: &quot;idx_key3&quot;, # 使用idx_key3的范围区间 &quot;ranges&quot;: [ &quot;a &lt;= key3 &lt;= a&quot;, &quot;b &lt;= key3 &lt;= b&quot;, &quot;c &lt;= key3 &lt;= c&quot; ] /* ranges */, &quot;index_dives_for_eq_ranges&quot;: true, # 同上 &quot;rowid_ordered&quot;: false, # 同上 &quot;using_mrr&quot;: false, # 同上 &quot;index_only&quot;: false, # 同上 &quot;rows&quot;: 21, # 同上 &quot;cost&quot;: 28.21, # 同上 &quot;chosen&quot;: false, # 同上 &quot;cause&quot;: &quot;cost&quot; # 同上 &#125; ] /* range_scan_alternatives */, # 分析使用索引合并的成本 &quot;analyzing_roworder_intersect&quot;: &#123; &quot;usable&quot;: false, &quot;cause&quot;: &quot;too_few_roworder_scans&quot; &#125; /* analyzing_roworder_intersect */ &#125; /* analyzing_range_alternatives */, # 对于上述单表查询s1最优的访问方法 &quot;chosen_range_access_summary&quot;: &#123; &quot;range_access_plan&quot;: &#123; &quot;type&quot;: &quot;range_scan&quot;, &quot;index&quot;: &quot;idx_key2&quot;, &quot;rows&quot;: 12, &quot;ranges&quot;: [ &quot;NULL &lt; key2 &lt; 1000000&quot; ] /* ranges */ &#125; /* range_access_plan */, &quot;rows_for_plan&quot;: 12, &quot;cost_for_plan&quot;: 15.41, &quot;chosen&quot;: true &#125; /* chosen_range_access_summary */ &#125; /* range_analysis */ &#125; ] /* rows_estimation */ &#125;, &#123; # 分析各种可能的执行计划 #（对多表查询这可能有很多种不同的方案，单表查询的方案上边已经分析过了，直接选取idx_key2就好） &quot;considered_execution_plans&quot;: [ &#123; &quot;plan_prefix&quot;: [ ] /* plan_prefix */, &quot;table&quot;: &quot;`s1`&quot;, &quot;best_access_path&quot;: &#123; &quot;considered_access_paths&quot;: [ &#123; &quot;rows_to_scan&quot;: 12, &quot;access_type&quot;: &quot;range&quot;, &quot;range_details&quot;: &#123; &quot;used_index&quot;: &quot;idx_key2&quot; &#125; /* range_details */, &quot;resulting_rows&quot;: 12, &quot;cost&quot;: 17.81, &quot;chosen&quot;: true &#125; ] /* considered_access_paths */ &#125; /* best_access_path */, &quot;condition_filtering_pct&quot;: 100, &quot;rows_for_plan&quot;: 12, &quot;cost_for_plan&quot;: 17.81, &quot;chosen&quot;: true &#125; ] /* considered_execution_plans */ &#125;, &#123; # 尝试给查询添加一些其他的查询条件 &quot;attaching_conditions_to_tables&quot;: &#123; &quot;original_condition&quot;: &quot;((`s1`.`key1` &gt; &#x27;z&#x27;) and (`s1`.`key2` &lt; 1000000) and (`s1`.`key3` in (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)) and (`s1`.`common_field` = &#x27;abc&#x27;))&quot;, &quot;attached_conditions_computation&quot;: [ ] /* attached_conditions_computation */, &quot;attached_conditions_summary&quot;: [ &#123; &quot;table&quot;: &quot;`s1`&quot;, &quot;attached&quot;: &quot;((`s1`.`key1` &gt; &#x27;z&#x27;) and (`s1`.`key2` &lt; 1000000) and (`s1`.`key3` in (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)) and (`s1`.`common_field` = &#x27;abc&#x27;))&quot; &#125; ] /* attached_conditions_summary */ &#125; /* attaching_conditions_to_tables */ &#125;, &#123; # 再稍稍的改进一下执行计划 &quot;refine_plan&quot;: [ &#123; &quot;table&quot;: &quot;`s1`&quot;, &quot;pushed_index_condition&quot;: &quot;(`s1`.`key2` &lt; 1000000)&quot;, &quot;table_condition_attached&quot;: &quot;((`s1`.`key1` &gt; &#x27;z&#x27;) and (`s1`.`key3` in (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)) and (`s1`.`common_field` = &#x27;abc&#x27;))&quot; &#125; ] /* refine_plan */ &#125; ] /* steps */ &#125; /* join_optimization */ &#125;, &#123; &quot;join_execution&quot;: &#123; # execute阶段 &quot;select#&quot;: 1, &quot;steps&quot;: [ ] /* steps */ &#125; /* join_execution */ &#125; ] /* steps */&#125;# 因优化过程文本太多而丢弃的文本字节大小，值为0时表示并没有丢弃MISSING_BYTES_BEYOND_MAX_MEM_SIZE: 0# 权限字段INSUFFICIENT_PRIVILEGES: 01 row in set (0.00 sec) 这只是优化器执行过程中的一小部分，MySQL可能会在之后的版本中添加更多的优化过程信息。不过杂乱之中其实还是蛮有规律的，优化过程大致分为了三个阶段： prepare阶段 optimize阶段 execute阶段 我们所说的基于成本的优化主要集中在optimize阶段，对于单表查询来说，我们主要关注optimize阶段的&quot;rows_estimation&quot;这个过程，这个过程深入分析了对单表查询的各种执行方案的成本；对于多表连接查询来说，我们更多需要关注&quot;considered_execution_plans&quot;这个过程，这个过程里会写明各种不同的连接方式所对应的成本。反正优化器最终会选择成本最低的那种方案来作为最终的执行计划，也就是我们使用EXPLAIN语句所展现出的那种方案。 如果对使用EXPLAIN语句展示出的对某个查询的执行计划很不理解，可以尝试使用optimizer trace功能来详细了解每一种执行方案对应的成本。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[九]基于规则的优化&子查询优化","slug":"MySQL/MySQL[九]基于规则的优化&子查询优化","date":"2022-01-11T03:16:30.409Z","updated":"2022-01-11T03:23:03.085Z","comments":true,"path":"2022/01/11/MySQL/MySQL[九]基于规则的优化&子查询优化/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E4%B9%9D]%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E4%BC%98%E5%8C%96&%E5%AD%90%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/","excerpt":"","text":"MySQL依据一些规则，把语句转换成某种可以比较高效执行的形式，这个过程也可以被称作查询重写。 1.条件化简我们编写的查询语句的搜索条件本质上是一个表达式，这些表达式可能比较繁杂，或者不能高效的执行，MySQL的查询优化器会为我们简化这些表达式。 1.1移除不必要的括号有时候表达式里有许多无用的括号，比如这样： 1((a = 5 AND b = c) OR ((a &gt; c) AND (c &lt; 5))) 优化器会把那些用不到的括号给干掉，就是这样： 1(a = 5 and b = c) OR (a &gt; c AND c &lt; 5) 1.2常量传递有时候某个表达式是某个列和某个常量做等值匹配，比如这样： 1a = 5 当这个表达式和其他涉及列a的表达式使用AND连接起来时，可以将其他表达式中的a的值替换为5，比如这样： 1a = 5 AND b &gt; a 就可以被转换为： 1a = 5 AND b &gt; 5 用OR的表达式不能进行能量传递是因为OR两边的条件是取并集的，或者说互不相关。 1.3 等值传递有时候多个列之间存在等值匹配的关系，比如这样： 1a = b and b = c and c = 5 这个表达式可以被简化为： 1a = 5 and b = 5 and c = 5 1.4移除没用的条件对于一些明显永远为TRUE或者FALSE的表达式，优化器会移除掉它们，比如这个表达式： 1(a &lt; 1 and b = b) OR (a = 6 OR 5 != 5) 很明显，b = b这个表达式永远为TRUE，5 != 5这个表达式永远为FALSE，所以简化后的表达式就是这样的： 1(a &lt; 1 and TRUE) OR (a = 6 OR FALSE) 可以继续被简化为 1a &lt; 1 OR a = 6 1.5表达式计算在查询开始执行之前，如果表达式中只包含常量的话，它的值会被先计算出来，比如这个： 1a = 5 + 1 因为5 + 1这个表达式只包含常量，所以就会被化简成： 1a = 6 但是这里需要注意的是，如果某个列并不是以单独的形式作为表达式的操作数时，比如出现在函数中，出现在某个更复杂表达式中，就像这样： 1ABS(a) &gt; 5 或者： 1-a &lt; -8 优化器是不会尝试对这些表达式进行化简的。我们前边说过只有搜索条件中索引列和常数使用某些运算符连接起来才可能使用到索引，所以如果可以的话，最好让索引列以单独的形式出现在表达式中。 1.6HAVING&amp;WHERE子句的合并如果查询语句中没有出现诸如SUM、MAX等等的聚集函数以及GROUP BY子句，优化器就把HAVING子句和WHERE子句合并起来。 1.7常量表检测MySQL觉得下边这两种查询运行的特别快： 查询的表中一条记录没有，或者只有一条记录。 使用主键等值匹配或者唯一二级索引列等值匹配作为搜索条件来查询某个表。 MySQL觉得这两种查询花费的时间特别少，少到可以忽略，所以也把通过这两种方式查询的表称之为常量表（英文名：constant tables）。优化器在分析一个查询语句时，先首先执行常量表查询，然后把查询中涉及到该表的条件全部替换成常数，最后再分析其余表的查询成本，比方说这个查询语句： 123SELECT * FROM table1 INNER JOIN table2 ON table1.column1 = table2.column2 WHERE table1.primary_key = 1; 很明显，这个查询可以使用主键和常量值的等值匹配来查询table1表，也就是在这个查询中table1表相当于常量表，在分析对table2表的查询成本之前，就会执行对table1表的查询，并把查询中涉及table1表的条件都替换掉，也就是上边的语句会被转换成这样： 12SELECT table1表记录的各个字段的常量值, table2.* FROM table1 INNER JOIN table2 ON table1表column1列的常量值 = table2.column2; 2.外连接消除内连接的驱动表和被驱动表的位置可以相互转换，而左（外）连接和右（外）连接的驱动表和被驱动表是固定的。这就导致内连接可能通过优化表的连接顺序来降低整体的查询成本，而外连接却无法优化表的连接顺序。我在之前的文章创建了两个表： 123456789CREATE TABLE t1 ( m1 int, n1 char(1)) Engine=InnoDB, CHARSET=utf8;CREATE TABLE t2 ( m2 int, n2 char(1)) Engine=InnoDB, CHARSET=utf8; 再看一下表的数据 12345678910111213141516171819mysql&gt; SELECT * FROM t1;+------+------+| m1 | n1 |+------+------+| 1 | a || 2 | b || 3 | c |+------+------+3 rows in set (0.00 sec)mysql&gt; SELECT * FROM t2;+------+------+| m2 | n2 |+------+------+| 2 | b || 3 | c || 4 | d |+------+------+3 rows in set (0.00 sec) 外连接和内连接的本质区别就是：对于外连接的驱动表的记录来说，如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用NULL值填充；而内连接的驱动表的记录如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录会被舍弃。查询效果就是这样： 123456789101112131415161718mysql&gt; SELECT * FROM t1 INNER JOIN t2 ON t1.m1 = t2.m2;+------+------+------+------+| m1 | n1 | m2 | n2 |+------+------+------+------+| 2 | b | 2 | b || 3 | c | 3 | c |+------+------+------+------+2 rows in set (0.00 sec)mysql&gt; SELECT * FROM t1 LEFT JOIN t2 ON t1.m1 = t2.m2;+------+------+------+------+| m1 | n1 | m2 | n2 |+------+------+------+------+| 2 | b | 2 | b || 3 | c | 3 | c || 1 | a | NULL | NULL |+------+------+------+------+3 rows in set (0.00 sec) 对于上边例子中的（左）外连接来说，由于驱动表t1中m1=1, n1=&#39;a&#39;的记录无法在被驱动表t2中找到符合ON子句条件t1.m1 = t2.m2的记录，所以就直接把这条记录加入到结果集，对应的t2表的m2和n2列的值都设置为NULL。 右（外）连接和左（外）连接其实只在驱动表的选取方式上是不同的，其余方面都是一样的，所以优化器会首先把右（外）连接查询转换成左（外）连接查询。 凡是不符合WHERE子句中条件的记录都不会参与连接。只要我们在搜索条件中指定关于被驱动表相关列的值不为NULL，那么外连接中在被驱动表中找不到符合ON子句条件的驱动表记录也就被排除出最后的结果集了，也就是说：在这种情况下：外连接和内连接也就没有什么区别了！比方说这个查询： 12345678mysql&gt; SELECT * FROM t1 LEFT JOIN t2 ON t1.m1 = t2.m2 WHERE t2.n2 IS NOT NULL;+------+------+------+------+| m1 | n1 | m2 | n2 |+------+------+------+------+| 2 | b | 2 | b || 3 | c | 3 | c |+------+------+------+------+2 rows in set (0.01 sec) 由于指定了被驱动表t2的n2列不允许为NULL，所以上边的t1和t2表的左（外）连接查询和内连接查询是一样一样的。当然，我们也可以不用显式的指定被驱动表的某个列IS NOT NULL，只要隐含的有这个意思就行了，比方说这样： 1234567mysql&gt; SELECT * FROM t1 LEFT JOIN t2 ON t1.m1 = t2.m2 WHERE t2.m2 = 2;+------+------+------+------+| m1 | n1 | m2 | n2 |+------+------+------+------+| 2 | b | 2 | b |+------+------+------+------+1 row in set (0.00 sec) 在这个例子中，我们在WHERE子句中指定了被驱动表t2的m2列等于2，也就相当于间接的指定了m2列不为NULL值，所以上边的这个左（外）连接查询其实和下边这个内连接查询是等价的： 1234567mysql&gt; SELECT * FROM t1 INNER JOIN t2 ON t1.m1 = t2.m2 WHERE t2.m2 = 2;+------+------+------+------+| m1 | n1 | m2 | n2 |+------+------+------+------+| 2 | b | 2 | b |+------+------+------+------+1 row in set (0.00 sec) 我们把这种在外连接查询中，指定的WHERE子句中包含被驱动表中的列不为NULL值的条件称之为空值拒绝（英文名：reject-NULL）。在被驱动表的WHERE子句符合空值拒绝的条件后，外连接和内连接可以相互转换。这种转换带来的好处就是查询优化器可以通过评估表的不同连接顺序的成本，选出成本最低的那种连接顺序来执行查询。 3.子查询优化3.1子查询语法3.1.1按返回的结果集区分子查询因为子查询本身也算是一个查询，所以可以按照它们返回的不同结果集类型而把这些子查询分为不同的类型： 标量子查询那些只返回一个单一值的子查询称之为标量子查询，比如这样：或者这样：这两个查询语句中的子查询都返回一个单一的值，也就是一个标量。这些标量子查询可以作为一个单一值或者表达式的一部分出现在查询语句的各个地方。 1SELECT (SELECT m1 FROM t1 LIMIT 1); 1SELECT * FROM t1 WHERE m1 = (SELECT MIN(m2) FROM t2); 行子查询顾名思义，就是返回一条记录的子查询，不过这条记录需要包含多个列（只包含一个列就成了标量子查询了）。比如这样：其中的(SELECT m2, n2 FROM t2 LIMIT 1)就是一个行子查询，整条语句的含义就是要从t1表中找一些记录，这些记录的m1和n1列分别等于子查询结果中的m2和n2列。 1SELECT * FROM t1 WHERE (m1, n1) = (SELECT m2, n2 FROM t2 LIMIT 1); 列子查询列子查询自然就是查询出一个列的数据喽，不过这个列的数据需要包含多条记录（只包含一条记录就成了标量子查询了）。比如这样：其中的(SELECT m2 FROM t2)就是一个列子查询，表明查询出t2表的m2列的值作为外层查询IN语句的参数。 1SELECT * FROM t1 WHERE m1 IN (SELECT m2 FROM t2); 表子查询顾名思义，就是子查询的结果既包含很多条记录，又包含很多个列，比如这样：其中的(SELECT m2, n2 FROM t2)就是一个表子查询，这里需要和行子查询对比一下，行子查询中我们用了LIMIT 1来保证子查询的结果只有一条记录，表子查询中不需要这个限制。 1SELECT * FROM t1 WHERE (m1, n1) IN (SELECT m2, n2 FROM t2); 3.1.2按与外层查询关系来区分子查询 不相关子查询如果子查询可以单独运行出结果，而不依赖于外层查询的值，我们就可以把这个子查询称之为不相关子查询。我们前边介绍的那些子查询全部都可以看作不相关子查询，所以也就不举例子了哈。 相关子查询如果子查询的执行需要依赖于外层查询的值，我们就可以把这个子查询称之为相关子查询。比如：例子中的子查询是(SELECT m2 FROM t2 WHERE n1 = n2)，可是这个查询中有一个搜索条件是n1 = n2，别忘了n1是表t1的列，也就是外层查询的列，也就是说子查询的执行需要依赖于外层查询的值，所以这个子查询就是一个相关子查询。 1SELECT * FROM t1 WHERE m1 IN (SELECT m2 FROM t2 WHERE n1 = n2); 3.1.3 子查询语法注意事项 子查询必须用小括号扩起来。 在SELECT子句中的子查询必须是标量子查询。 在想要得到标量子查询或者行子查询，但又不能保证子查询的结果集只有一条记录时，应该使用LIMIT 1语句来限制记录数量。 对于[NOT] IN/ANY/SOME/ALL子查询来说，子查询中不允许有LIMIT语句。比如这样是非法的：因为[NOT] IN/ANY/SOME/ALL子查询不支持LIMIT语句，所以子查询中的这些语句也就是多余的了： 1mysql&gt; SELECT * FROM t1 WHERE m1 IN (SELECT * FROM t2 LIMIT 2); ORDER BY子句：子查询的结果其实就相当于一个集合，集合里的值排不排序一点儿都不重要。 DISTINCT语句：集合里的值去不去重也没啥意义。 没有聚集函数以及HAVING子句的GROUP BY子句。 对于这些冗余的语句，查询优化器在一开始就把它们给干掉了。 不允许在一条语句中增删改某个表的记录时同时还对该表进行子查询。 1mysql&gt; DELETE FROM t1 WHERE m1 &lt; (SELECT MAX(m1) FROM t1); 3.2 子查询的执行还是复用前面的表： 123456789101112131415CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3)) Engine=InnoDB CHARSET=utf8; 我们假设有两个表s1、s2与这个single_table表的构造是相同的，而且这两个表里边儿有10000条记录。 3.2.1 标量/行子查询的执行方式我们经常在下边两个场景中使用到标量子查询或者行子查询： SELECT子句中，我们前边说过的在查询列表中的子查询必须是标量子查询。 子查询使用=、&gt;、&lt;、&gt;=、&lt;=、&lt;&gt;、!=、&lt;=&gt;等操作符和某个操作数组成一个布尔表达式，这样的子查询必须是标量子查询或者行子查询。 对于上述两种场景中的不相关标量子查询或者行子查询来说，它们的执行方式是简单的，比方说下边这个查询语句： 12SELECT * FROM s1 WHERE key1 = (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27; LIMIT 1); 先单独执行(SELECT common_field FROM s2 WHERE key3 = &#39;a&#39; LIMIT 1)这个子查询。 然后在将上一步子查询得到的结果当作外层查询的参数再执行外层查询SELECT * FROM s1 WHERE key1 = ...。 也就是说，对于包含不相关的标量子查询或者行子查询的查询语句来说，MySQL会分别独立的执行外层查询和子查询，就当作两个单表查询就好了。 对于相关的标量子查询或者行子查询来说，比如下边这个查询： 12SELECT * FROM s1 WHERE key1 = (SELECT common_field FROM s2 WHERE s1.key3 = s2.key3 LIMIT 1); 3.2.2 IN子查询优化① 物化表的提出12SELECT * FROM s1 WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27;); 对于不相关的IN子查询来说，如果子查询的结果集中的记录条数很少，那么把子查询和外层查询分别看成两个单独的单表查询效率还行，但是如果单独执行子查询后的结果集太多的话，就会导致这些问题： 结果集太多，可能内存中都放不下。 对于外层查询来说，如果子查询的结果集太多，那就意味着IN子句中的参数特别多，这就导致： 无法有效的使用索引，只能对外层查询进行全表扫描。 在对外层查询执行全表扫描时，由于IN子句中的参数太多，这会导致检测一条记录是否符合和IN子句中的参数匹配花费的时间太长。 所以MySQL并不直接将不相关子查询的结果集当作外层查询的参数，而是将该结果集写入一个临时表里。 该临时表的列就是子查询结果集中的列。 写入临时表的记录会被去重。我们说IN语句是判断某个操作数在不在某个集合中，集合中的值重不重复对整个IN语句的结果并没有影响，所以我们在将结果集写入临时表时对记录进行去重可以让临时表变得更小。 临时表如何对记录进行去重？只要为表中记录的所有列建立主键或者唯一索引就好了嘛～ 一般情况下子查询结果集不会大的离谱，所以会为它建立基于内存的使用Memory存储引擎的临时表，而且会为该表建立哈希索引。如果子查询的结果集非常大，超过了系统变量tmp_table_size或者max_heap_table_size，临时表会转而使用基于磁盘的存储引擎来保存结果集中的记录，索引类型也对应转变为B+树索引。 IN语句的本质就是判断某个操作数在不在某个集合里，如果集合中的数据建立了哈希索引，那么这个匹配的过程就是超级快的。 MySQL把这个将子查询结果集中的记录保存到临时表的过程称之为物化。为了方便起见，我们就把那个存储子查询结果集的临时表称之为物化表。正因为物化表中的记录都建立了索引（基于内存的物化表有哈希索引，基于磁盘的有B+树索引），通过索引执行IN语句判断某个操作数在不在子查询结果集中变得非常快，从而提升了子查询语句的性能。 ② 物化表转连接再看一下最开始的那个查询语句： 12SELECT * FROM s1 WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27;); 当我们把子查询进行物化之后，假设子查询物化表的名称为materialized_table，该物化表存储的子查询结果集的列为m_val，那么这个查询其实可以从下边两种角度来看待： 从表s1的角度来看待，整个查询的意思其实是：对于s1表中的每条记录来说，如果该记录的key1列的值在子查询对应的物化表中，则该记录会被加入最终的结果集。画个图表示一下就是这样： 从子查询物化表的角度来看待，整个查询的意思其实是：对于子查询物化表的每个值来说，如果能在s1表中找到对应的key1列的值与该值相等的记录，那么就把这些记录加入到最终的结果集。画个图表示一下就是这样： 也就是说其实上边的查询就相当于表s1和子查询物化表materialized_table进行内连接： 1SELECT s1.* FROM s1 INNER JOIN materialized_table ON key1 = m_val; 转化成内连接之后就有意思了，查询优化器可以评估不同连接顺序需要的成本是多少，选取成本最低的那种查询方式执行查询。我们分析一下上述查询中使用外层查询的表s1和物化表materialized_table进行内连接的成本都是由哪几部分组成的： 如果使用s1表作为驱动表的话，总查询成本由下边几个部分组成： 物化子查询时需要的成本 扫描s1表时的成本 s1表中的记录数量 × 通过m_val = xxx对materialized_table表进行单表访问的成本（我们前边说过物化表中的记录是不重复的，并且为物化表中的列建立了索引，所以这个步骤显然是非常快的）。 如果使用materialized_table表作为驱动表的话，总查询成本由下边几个部分组成： 物化子查询时需要的成本 扫描物化表时的成本 物化表中的记录数量 × 通过key1 = xxx对s1表进行单表访问的成本（非常庆幸key1列上建立了索引，所以这个步骤是非常快的）。 MySQL查询优化器会通过运算来选择上述成本更低的方案来执行查询。 ③ 将子查询转换为semi-join虽然将子查询进行物化之后再执行查询都会有建立临时表的成本，但是不管怎么说，我们见识到了将子查询转换为连接的强大作用，能不能不进行物化操作直接把子查询转换为连接呢？ 12SELECT * FROM s1 WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27;); 我们可以把这个查询理解成：对于s1表中的某条记录，如果我们能在s2表（准确的说是执行完WHERE s2.key3 = &#39;a&#39;之后的结果集）中找到一条或多条记录，这些记录的common_field的值等于s1表记录的key1列的值，那么该条s1表的记录就会被加入到最终的结果集。这个过程其实和把s1和s2两个表连接起来的效果很像： 123SELECT s1.* FROM s1 INNER JOIN s2 ON s1.key1 = s2.common_field WHERE s2.key3 = &#x27;a&#x27;; 只不过我们不能保证对于s1表的某条记录来说，在s2表（准确的说是执行完WHERE s2.key3 = &#39;a&#39;之后的结果集）中有多少条记录满足s1.key1 = s2.common_field这个条件，不过我们可以分三种情况讨论： 情况一：对于s1表的某条记录来说，s2表中没有任何记录满足s1.key1 = s2.common_field这个条件，那么该记录自然也不会加入到最后的结果集。 情况二：对于s1表的某条记录来说，s2表中有且只有1条记录满足s1.key1 = s2.common_field这个条件，那么该记录会被加入最终的结果集。 情况三：对于s1表的某条记录来说，s2表中至少有2条记录满足s1.key1 = s2.common_field这个条件，那么该记录会被多次加入最终的结果集。 对于s1表的某条记录来说，由于我们只关心s2表中是否存在记录满足s1.key1 = s2.common_field这个条件，而不关心具体有多少条记录与之匹配，又因为有情况三的存在，我们上边所说的IN子查询和两表连接之间并不完全等价。但是将子查询转换为连接又真的可以充分发挥优化器的作用，所以MySQL在这里提出了一个新概念 — 半连接。将s1表和s2表进行半连接的意思就是：对于s1表的某条记录来说，我们只关心在s2表中是否存在与之匹配的记录，而不关心具体有多少条记录与之匹配，最终的结果集中只保留s1表的记录。我们假设MySQL内部是这么改写上边的子查询的： 123SELECT s1.* FROM s1 SEMI JOIN s2 ON s1.key1 = s2.common_field WHERE key3 = &#x27;a&#x27;; semi-join只是在MySQL内部采用的一种执行子查询的方式，MySQL并没有提供面向用户的semi-join语法，所以我们不需要，也不能尝试把上边这个语句放到mysql客户端执行。 怎么实现这种所谓的半连接呢？ Table pullout （子查询中的表上拉）当子查询的查询列表处只有主键或者唯一索引列时，可以直接把子查询中的表上拉到外层查询的FROM子句中，并把子查询中的搜索条件合并到外层查询的搜索条件中，比如这个由于key2列是s2表的唯一二级索引列，所以我们可以直接把s2表上拉到外层查询的FROM子句中，并且把子查询中的搜索条件合并到外层查询的搜索条件中，上拉之后的查询就是这样的：为什么当子查询的查询列表处只有主键或者唯一索引列时，就可以直接将子查询转换为连接查询呢？主键或者唯一索引列中的数据本身就是不重复的，所以对于同一条s1表中的记录，不可能找到两条以上的符合s1.key2 = s2.key2的记录。 12SELECT * FROM s1 WHERE key2 IN (SELECT key2 FROM s2 WHERE key3 = &#x27;a&#x27;); 123SELECT s1.* FROM s1 INNER JOIN s2 ON s1.key2 = s2.key2 WHERE s2.key3 = &#x27;a&#x27;; DuplicateWeedout execution strategy （重复值消除）对于这个查询来说：转换为半连接查询后，s1表中的某条记录可能在s2表中有多条匹配的记录，所以该条记录可能多次被添加到最后的结果集中，为了消除重复，我们可以建立一个临时表，比方说这个临时表长这样：这样在执行连接查询的过程中，每当某条s1表中的记录要加入结果集时，就首先把这条记录的id值加入到这个临时表里，如果添加成功，说明之前这条s1表中的记录并没有加入最终的结果集，现在把该记录添加到最终的结果集；如果添加失败，说明之前这条s1表中的记录已经加入过最终的结果集，这里直接把它丢弃就好了，这种使用临时表消除semi-join结果集中的重复值的方式称之为DuplicateWeedout。 12SELECT * FROM s1 WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27;); 123CREATE TABLE tmp ( id PRIMARY KEY); LooseScan execution strategy （松散扫描）大家看这个查询：在子查询中，对于s2表的访问可以使用到key1列的索引，而恰好子查询的查询列表处就是key1列，这样在将该查询转换为半连接查询后，如果将s2作为驱动表执行查询的话，那么执行过程就是这样：如图所示，在s2表的idx_key1索引中，值为&#39;aa&#39;的二级索引记录一共有3条，那么只需要取第一条的值到s1表中查找s1.key3 = &#39;aa&#39;的记录，如果能在s1表中找到对应的记录，那么就把对应的记录加入到结果集。依此类推，其他值相同的二级索引记录，也只需要取第一条记录的值到s1表中找匹配的记录，这种虽然是扫描索引，但只取值相同的记录的第一条去做匹配操作的方式称之为松散扫描。 12SELECT * FROM s1 WHERE key3 IN (SELECT key1 FROM s2 WHERE key1 &gt; &#x27;a&#x27; AND key1 &lt; &#x27;b&#x27;); Semi-join Materialization execution strategy我们之前介绍的先把外层查询的IN子句中的不相关子查询进行物化，然后再进行外层查询的表和物化表的连接本质上也算是一种semi-join，只不过由于物化表中没有重复的记录，所以可以直接将子查询转为连接查询。 FirstMatch execution strategy （首次匹配）FirstMatch是一种最原始的半连接执行方式，先取一条外层查询的中的记录，然后到子查询的表中寻找符合匹配条件的记录，如果能找到一条，则将该外层查询的记录放入最终的结果集并且停止查找更多匹配的记录，如果找不到则把该外层查询的记录丢弃掉；然后再开始取下一条外层查询中的记录，重复上边这个过程。 对于某些使用IN语句的相关子查询，比方这个查询： 12SELECT * FROM s1 WHERE key1 IN (SELECT common_field FROM s2 WHERE s1.key3 = s2.key3); 它也可以很方便的转为半连接，转换后的语句类似这样： 12SELECT s1.* FROM s1 SEMI JOIN s2 ON s1.key1 = s2.common_field AND s1.key3 = s2.key3; 然后就可以使用我们上边介绍过的DuplicateWeedout、LooseScan、FirstMatch等半连接执行策略来执行查询，当然，如果子查询的查询列表处只有主键或者唯一二级索引列，还可以直接使用table pullout的策略来执行查询，但是，由于相关子查询并不是一个独立的查询，所以不能转换为物化表来执行查询。 ④ semi-join的适用条件当然，并不是所有包含IN子查询的查询语句都可以转换为semi-join，只有形如这样的查询才可以被转换为semi-join： 12SELECT ... FROM outer_tables WHERE expr IN (SELECT ... FROM inner_tables ...) AND ... 或者这样的形式也可以： 12SELECT ... FROM outer_tables WHERE (oe1, oe2, ...) IN (SELECT ie1, ie2, ... FROM inner_tables ...) AND ... 用文字总结一下，只有符合下边这些条件的子查询才可以被转换为semi-join： 该子查询必须是和IN语句组成的布尔表达式，并且在外层查询的WHERE或者ON子句中出现。 外层查询也可以有其他的搜索条件，只不过和IN子查询的搜索条件必须使用AND连接起来。 该子查询必须是一个单一的查询，不能是由若干查询由UNION连接起来的形式。 该子查询不能包含GROUP BY或者HAVING语句或者聚集函数。 … 还有一些条件比较少见…. ⑤ 不适用于semi-join的情况对于一些不能将子查询转位semi-join的情况，典型的比如下边这几种： 外层查询的WHERE条件中有其他搜索条件与IN子查询组成的布尔表达式使用OR连接起来 123SELECT * FROM s1 WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27;) OR key2 &gt; 100; 使用NOT IN而不是IN的情况 12SELECT * FROM s1 WHERE key1 NOT IN (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27;) 在SELECT子句中的IN子查询的情况 1SELECT key1 IN (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27;) FROM s1 ; 子查询中包含GROUP BY、HAVING或者聚集函数的情况 12SELECT * FROM s1 WHERE key2 IN (SELECT COUNT(*) FROM s2 GROUP BY key1); 子查询中包含UNION的情况 12345SELECT * FROM s1 WHERE key1 IN ( SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27; UNION SELECT common_field FROM s2 WHERE key3 = &#x27;b&#x27;); MySQL仍然会尝试优化不能转为semi-join查询的子查询，那就是： 对于不相关子查询来说，可以尝试把它们物化之后再参与查询比如我们上边提到的这个查询：先将子查询物化，然后再判断key1是否在物化表的结果集中可以加快查询执行的速度。 12SELECT * FROM s1 WHERE key1 NOT IN (SELECT common_field FROM s2 WHERE key3 = &#x27;a&#x27;) 这里将子查询物化之后不能转为和外层查询的表的连接，只能是先扫描s1表，然后对s1表的某条记录来说，判断该记录的key1值在不在物化表中。 不管子查询是相关的还是不相关的，都可以把IN子查询尝试转为EXISTS子查询其实对于任意一个IN子查询来说，都可以被转为EXISTS子查询，通用的例子如下：可以被转换为：当然这个过程中有一些特殊情况，比如在outer_expr或者inner_expr值为NULL的情况下就比较特殊。因为有NULL值作为操作数的表达式结果往往是NULL，比方说：而EXISTS子查询的结果肯定是TRUE或者FASLE：但是，我们大部分使用IN子查询的场景是把它放在WHERE或者ON子句中，而WHERE或者ON子句是不区分NULL和FALSE的，比方说：所以只要我们的IN子查询是放在WHERE或者ON子句中的，那么IN -&gt; EXISTS的转换就是没问题的。说了这么多，为啥要转换呢？这是因为不转换的话可能用不到索引，比方说下边这个查询：这个查询中的子查询是一个相关子查询，而且子查询执行的时候不能使用到索引，但是将它转为EXISTS子查询后却可以使用到索引：转为EXISTS子查询时便可以使用到s2表的idx_key3索引了。需要注意的是，如果IN子查询不满足转换为semi-join的条件，又不能转换为物化表或者转换为物化表的成本太大，那么它就会被转换为EXISTS查询。 1outer_expr IN (SELECT inner_expr FROM ... WHERE subquery_where) 1EXISTS (SELECT inner_expr FROM ... WHERE subquery_where AND outer_expr=inner_expr) 1234567891011121314151617181920212223mysql&gt; SELECT NULL IN (1, 2, 3);+-------------------+| NULL IN (1, 2, 3) |+-------------------+| NULL |+-------------------+1 row in set (0.00 sec)mysql&gt; SELECT 1 IN (1, 2, 3);+----------------+| 1 IN (1, 2, 3) |+----------------+| 1 |+----------------+1 row in set (0.00 sec)mysql&gt; SELECT NULL IN (NULL);+----------------+| NULL IN (NULL) |+----------------+| NULL |+----------------+1 row in set (0.00 sec) 1234567891011121314151617181920212223mysql&gt; SELECT EXISTS (SELECT 1 FROM s1 WHERE NULL = 1);+------------------------------------------+| EXISTS (SELECT 1 FROM s1 WHERE NULL = 1) |+------------------------------------------+| 0 |+------------------------------------------+1 row in set (0.01 sec)mysql&gt; SELECT EXISTS (SELECT 1 FROM s1 WHERE 1 = NULL);+------------------------------------------+| EXISTS (SELECT 1 FROM s1 WHERE 1 = NULL) |+------------------------------------------+| 0 |+------------------------------------------+1 row in set (0.00 sec)mysql&gt; SELECT EXISTS (SELECT 1 FROM s1 WHERE NULL = NULL);+---------------------------------------------+| EXISTS (SELECT 1 FROM s1 WHERE NULL = NULL) |+---------------------------------------------+| 0 |+---------------------------------------------+1 row in set (0.00 sec) 12345mysql&gt; SELECT 1 FROM s1 WHERE NULL;Empty set (0.00 sec)mysql&gt; SELECT 1 FROM s1 WHERE FALSE;Empty set (0.00 sec) 123SELECT * FROM s1 WHERE key1 IN (SELECT key3 FROM s2 where s1.common_field = s2.common_field) OR key2 &gt; 1000; 123SELECT * FROM s1 WHERE EXISTS (SELECT 1 FROM s2 where s1.common_field = s2.common_field AND s2.key3 = s1.key1) OR key2 &gt; 1000; 在MySQL5.5以及之前的版本没有引进semi-join和物化的方式优化子查询时，优化器都会把IN子查询转换为EXISTS子查询。 ⑥ 阶段梳理 如果IN子查询符合转换为semi-join的条件，查询优化器会优先把该子查询转换为semi-join，然后再考虑下边5种执行半连接的策略中哪个成本最低： Table pullout DuplicateWeedout LooseScan Materialization FirstMatch 选择成本最低的那种执行策略来执行子查询。 如果IN子查询不符合转换为semi-join的条件，那么查询优化器会从下边两种策略中找出一种成本更低的方式执行子查询： 先将子查询物化之后再执行查询 执行IN to EXISTS转换。 3.2.3 ANY/ALL子查询优化如果ANY/ALL子查询是不相关子查询的话，它们在很多场合都能转换成我们熟悉的方式去执行，比方说： 原始表达式 转换为 &lt; ANY (SELECT inner_expr …) &lt; (SELECT MAX(inner_expr) …) &gt; ANY (SELECT inner_expr …) &gt; (SELECT MIN(inner_expr) …) &lt; ALL (SELECT inner_expr …) &lt; (SELECT MIN(inner_expr) …) &gt; ALL (SELECT inner_expr …) &gt; (SELECT MAX(inner_expr) …) 3.2.4 [NOT] EXISTS子查询的执行如果[NOT] EXISTS子查询是不相关子查询，可以先执行子查询，得出该[NOT] EXISTS子查询的结果是TRUE还是FALSE，并重写原先的查询语句，比如对这个查询来说： 123SELECT * FROM s1 WHERE EXISTS (SELECT 1 FROM s2 WHERE key1 = &#x27;a&#x27;) OR key2 &gt; 100; 因为这个语句里的子查询是不相关子查询，所以优化器会首先执行该子查询，假设该EXISTS子查询的结果为TRUE，那么接着优化器会重写查询为： 12SELECT * FROM s1 WHERE TRUE OR key2 &gt; 100; 进一步简化后就变成了： 12SELECT * FROM s1 WHERE TRUE; 对于相关的[NOT] EXISTS子查询来说，比如这个查询： 12SELECT * FROM s1 WHERE EXISTS (SELECT 1 FROM s2 WHERE s1.common_field = s2.common_field); 这个查询只能按照普通的那种执行相关子查询的方式来执行。不过如果[NOT] EXISTS子查询中如果可以使用索引的话，那查询速度也会加快不少，比如： 12SELECT * FROM s1 WHERE EXISTS (SELECT 1 FROM s2 WHERE s1.common_field = s2.key1); 上边这个EXISTS子查询中可以使用idx_key1来加快查询速度。 3.2.5 对于派生表的优化我们前边说过把子查询放在外层查询的FROM子句后，那么这个子查询的结果相当于一个派生表，比如下边这个查询： 123SELECT * FROM ( SELECT id AS d_id, key3 AS d_key3 FROM s2 WHERE key1 = &#x27;a&#x27; ) AS derived_s1 WHERE d_key3 = &#x27;a&#x27;; 子查询( SELECT id AS d_id, key3 AS d_key3 FROM s2 WHERE key1 = &#39;a&#39;)的结果就相当于一个派生表，这个表的名称是derived_s1，该表有两个列，分别是d_id和d_key3。 对于含有派生表的查询，MySQL提供了两种执行策略： 把派生表物化我们可以将派生表的结果集写到一个内部的临时表中，然后就把这个物化表当作普通表一样参与查询。当然，在对派生表进行物化时，MySQL使用了一种称为延迟物化的策略，也就是在查询中真正使用到派生表时才会去尝试物化派生表，而不是还没开始执行查询就把派生表物化掉。比方说对于下边这个含有派生表的查询来说：如果采用物化派生表的方式来执行这个查询的话，那么执行时首先会到s2表中找出满足s2.key2 = 1的记录，如果找不到，说明参与连接的s2表记录就是空的，所以整个查询的结果集就是空的，所以也就没有必要去物化查询中的派生表了。 12345SELECT * FROM ( SELECT * FROM s1 WHERE key1 = &#x27;a&#x27; ) AS derived_s1 INNER JOIN s2 ON derived_s1.key1 = s2.key1 WHERE s2.key2 = 1; 将派生表和外层的表合并，也就是将查询重写为没有派生表的形式我们来看这个包含派生表的查询：这个查询本质上就是想查看s1表中满足key1 = &#39;a&#39;条件的的全部记录，所以和下边这个语句是等价的：对于一些稍微复杂的包含派生表的语句，比如我们上边提到的那个：我们可以将派生表与外层查询的表合并，然后将派生表中的搜索条件放到外层查询的搜索条件中，就像这样：这样通过将外层查询和派生表合并的方式成功的消除了派生表，也就意味着我们没必要再付出创建和访问临时表的成本了。可是并不是所有带有派生表的查询都能被成功的和外层查询合并，当派生表中有这些语句就不可以和外层查询合并： 1SELECT * FROM (SELECT * FROM s1 WHERE key1 = &#x27;a&#x27;) AS derived_s1; 1SELECT * FROM s1 WHERE key1 = &#x27;a&#x27;; 12345SELECT * FROM ( SELECT * FROM s1 WHERE key1 = &#x27;a&#x27; ) AS derived_s1 INNER JOIN s2 ON derived_s1.key1 = s2.key1 WHERE s2.key2 = 1; 123SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key1 WHERE s1.key1 = &#x27;a&#x27; AND s2.key2 = 1; 聚集函数，比如MAX()、MIN()、SUM()… DISTINCT GROUP BY HAVING LIMIT UNION 或者 UNION ALL 派生表对应的子查询的SELECT子句中含有另一个子查询 … 还有些不常用的情况… 所以MySQL在执行带有派生表的时候，优先尝试把派生表和外层查询合并掉，如果不行的话，再把派生表物化掉执行查询。 4.总结MySQL会对用户编写的SQL语句进行重写操作，比如： 移除不必要的括号 常量传递 移除没用的条件 表达式计算 HAVING&amp;WHERE子句的合并 常量表检测 在被驱动表的WHERE子句符合空值拒绝条件的时候，外连接&amp;内连接可以相互转换。 子查询可以按照不同维度进行不同分类，比如按照子查询返回的结果集分类： 标量子查询 行子查询 列子查询 表子查询 按照与外层查询的关系来分类： 不相关子查询 相关子查询 MySQL对in查询进行了很多优化。如果in子查询符合转换为半连接的条件，查询优化器会优先把该子查询转换为半连接，然后再考虑下面五种执行半连接查询的策略中哪个成本最低，最后选择成本最低的执行策略来执行子查询。 table pullout duplicate weedout looseScan Semj-join Materialization FirstMatch 如果IN子查询不符合转换为半连接的条件，查询优化器会从下面的两种策略里面找出一种成本更低的方式去执行子查询： 先将子查询物化，在执行子查询 执行in到exists的转换 MySQL在处理带有派生表的语句的时候，优先尝试把派生表和外层查询进行合并；如果不行，再把派生表物化掉，然后执行查询。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[八]InnoDB统计数据收集原理","slug":"MySQL/MySQL[八]InnoDB统计数据收集原理","date":"2022-01-11T03:16:18.849Z","updated":"2022-01-11T03:22:22.716Z","comments":true,"path":"2022/01/11/MySQL/MySQL[八]InnoDB统计数据收集原理/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E5%85%AB]InnoDB%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%8E%9F%E7%90%86/","excerpt":"","text":"本篇我们来分析下InnoDB存储引擎的统计数据收集策略。 1.统计数据的存储方式InnoDB提供了两种存储统计数据的方式： 永久性的统计数据这种统计数据存储在磁盘上，也就是服务器重启之后这些统计数据还在。 非永久性的统计数据这种统计数据存储在内存中，当服务器关闭时这些这些统计数据就都被清除掉了，等到服务器重启之后，在某些适当的场景下才会重新收集这些统计数据。 MySQL提供了系统变量innodb_stats_persistent来控制到底采用哪种方式去存储统计数据。在MySQL 5.6.6之前，innodb_stats_persistent的值默认是OFF，也就是说InnoDB的统计数据默认是存储到内存的，之后的版本中innodb_stats_persistent的值默认是ON，也就是统计数据默认被存储到磁盘中。 不过InnoDB默认是以表为单位来收集和存储统计数据的，也就是说我们可以把某些表的统计数据（以及该表的索引统计数据）存储在磁盘上，把另一些表的统计数据存储在内存中。 我们可以在创建和修改表的时候通过指定STATS_PERSISTENT属性来指明该表的统计数据存储方式： 123CREATE TABLE 表名 (...) Engine=InnoDB, STATS_PERSISTENT = (1|0);ALTER TABLE 表名 Engine=InnoDB, STATS_PERSISTENT = (1|0); 当STATS_PERSISTENT=1时，表明我们想把该表的统计数据永久的存储到磁盘上，当STATS_PERSISTENT=0时，表明我们想把该表的统计数据临时的存储到内存中。如果我们在创建表时未指定STATS_PERSISTENT属性，那默认采用系统变量innodb_stats_persistent的值作为该属性的值。 2.永久性统计数据当我们选择把某个表以及该表索引的统计数据存放到磁盘上时，实际上是把这些统计数据存储到了两个表里： 12345678mysql&gt; SHOW TABLES FROM mysql LIKE &#x27;innodb%&#x27;;+---------------------------+| Tables_in_mysql (innodb%) |+---------------------------+| innodb_index_stats || innodb_table_stats |+---------------------------+2 rows in set (0.01 sec) 可以看到，这两个表都位于mysql系统数据库下边，其中： innodb_table_stats存储了关于表的统计数据，每一条记录对应着一个表的统计数据。 innodb_index_stats存储了关于索引的统计数据，每一条记录对应着一个索引的一个统计项的统计数据。 看一下这两个表里边都有什么以及表里的数据是如何生成的。 2.1 innodb_table_stats直接看一下这个innodb_table_stats表中的各个列都是干嘛的： 字段名 描述 database_name 数据库名 table_name 表名 last_update 本条记录最后更新时间 n_rows 表中记录的条数 clustered_index_size 表的聚簇索引占用的页面数量 sum_of_other_index_sizes 表的其他索引占用的页面数量 注意这个表的主键是(database_name,table_name)，也就是innodb_table_stats表的每条记录代表着一个表的统计信息。 12345678910mysql&gt; SELECT * FROM mysql.innodb_table_stats;+---------------+---------------+---------------------+--------+----------------------+--------------------------+| database_name | table_name | last_update | n_rows | clustered_index_size | sum_of_other_index_sizes |+---------------+---------------+---------------------+--------+----------------------+--------------------------+| mysql | gtid_executed | 2021-12-14 00:00:08 | 0 | 1 | 0 || sys | sys_config | 2021-12-14 00:00:09 | 6 | 1 | 0 || yhd | person_info | 2021-12-19 00:27:39 | 0 | 1 | 1 || yhd | single_table | 2021-12-19 02:13:19 | 910545 | 3109 | 5836 |+---------------+---------------+---------------------+--------+----------------------+--------------------------+4 rows in set (0.00 sec) 可以看到single_table表的统计信息就对应着mysql.innodb_table_stats的第三条记录。几个重要统计信息项的值如下： n_rows的值是9693，表明single_table表中大约有9693条记录，注意这个数据是估计值。 clustered_index_size的值是97，表明single_table表的聚簇索引占用97个页面，这个值是也是一个估计值。 sum_of_other_index_sizes的值是175，表明single_table表的其他索引一共占用175个页面，这个值是也是一个估计值。 2.1.1 n_rows统计项的收集为啥n_rows这个统计项的值是估计值呢？InnoDB`统计一个表中有多少行记录的套路是这样的： 按照一定算法（并不是纯粹随机的）选取几个叶子节点页面，计算每个页面中主键值记录数量，然后计算平均一个页面中主键值的记录数量乘以全部叶子节点的数量就算是该表的n_rows值。 真实的计算过程比这个稍微复杂一些，不过大致上就是这样。 可以看出来这个n_rows值精确与否取决于统计时采样的页面数量，MySQL为我们准备了一个名为innodb_stats_persistent_sample_pages的系统变量来控制使用永久性的统计数据时，计算统计数据时采样的页面数量。该值设置的越大，统计出的n_rows值越精确，但是统计耗时也就最久；该值设置的越小，统计出的n_rows值越不精确，但是统计耗时特别少。所以在实际使用是需要我们去权衡利弊，该系统变量的默认值是20。 我们前边说过，不过InnoDB默认是以表为单位来收集和存储统计数据的，我们也可以单独设置某个表的采样页面的数量，设置方式就是在创建或修改表的时候通过指定STATS_SAMPLE_PAGES属性来指明该表的统计数据存储方式： 123CREATE TABLE 表名 (...) Engine=InnoDB, STATS_SAMPLE_PAGES = 具体的采样页面数量;ALTER TABLE 表名 Engine=InnoDB, STATS_SAMPLE_PAGES = 具体的采样页面数量; 如果我们在创建表的语句中并没有指定STATS_SAMPLE_PAGES属性的话，将默认使用系统变量innodb_stats_persistent_sample_pages的值作为该属性的值。 2.1.2 clustered_index_size和sum_of_other_index_sizes统计项的收集这两个统计项的收集过程如下： 从数据字典里找到表的各个索引对应的根页面位置。系统表SYS_INDEXES里存储了各个索引对应的根页面信息。 从根页面的Page Header里找到叶子节点段和非叶子节点段对应的Segment Header。在每个索引的根页面的Page Header部分都有两个字段： PAGE_BTR_SEG_LEAF：表示B+树叶子段的Segment Header信息。 PAGE_BTR_SEG_TOP：表示B+树非叶子段的Segment Header信息。 从叶子节点段和非叶子节点段的Segment Header中找到这两个段对应的INODE Entry结构。这个是Segment Header结构： 从对应的INODE Entry结构中可以找到该段对应所有零散的页面地址以及FREE、NOT_FULL、FULL链表的基节点。这个是INODE Entry结构： 直接统计零散的页面有多少个，然后从那三个链表的List Length字段中读出该段占用的区的大小，每个区占用64个页，所以就可以统计出整个段占用的页面。这个是链表基节点的示意图： 分别计算聚簇索引的叶子结点段和非叶子节点段占用的页面数，它们的和就是clustered_index_size的值，按照同样的套路把其余索引占用的页面数都算出来，加起来之后就是sum_of_other_index_sizes的值。 注意，我们说一个段的数据在非常多时（超过32个页面），会以区为单位来申请空间，这里头的问题是以区为单位申请空间中有一些页可能并没有使用，但是在统计clustered_index_size和sum_of_other_index_sizes时都把它们算进去了，所以说聚簇索引和其他的索引占用的页面数可能比这两个值要小一些。 2.2 innodb_index_stats直接看一下这个innodb_index_stats表中的各个列： 字段名 描述 database_name 数据库名 table_name 表名 index_name 索引名 last_update 本条记录最后更新时间 stat_name 统计项的名称 stat_value 对应的统计项的值 sample_size 为生成统计数据而采样的页面数量 stat_description 对应的统计项的描述 注意这个表的主键是(database_name,table_name,index_name,stat_name)，其中的stat_name是指统计项的名称，也就是说innodb_index_stats表的每条记录代表着一个索引的一个统计项。我们直接看一下关于single_table表的索引统计数据都有些什么： 1234567891011121314151617181920212223242526mysql&gt; SELECT * FROM mysql.innodb_index_stats WHERE table_name = &#x27;single_table&#x27;;+---------------+--------------+--------------+---------------------+--------------+------------+-------------+-----------------------------------+| database_name | table_name | index_name | last_update | stat_name | stat_value | sample_size | stat_description |+---------------+--------------+--------------+---------------------+--------------+------------+-------------+-----------------------------------+| yhd | single_table | PRIMARY | 2021-12-19 02:13:19 | n_diff_pfx01 | 910518 | 20 | id || yhd | single_table | PRIMARY | 2021-12-19 02:13:19 | n_leaf_pages | 3097 | NULL | Number of leaf pages in the index || yhd | single_table | PRIMARY | 2021-12-19 02:13:19 | size | 3109 | NULL | Number of pages in the index || yhd | single_table | idx_key1 | 2021-12-19 02:13:19 | n_diff_pfx01 | 8 | 10 | key1 || yhd | single_table | idx_key1 | 2021-12-19 02:13:19 | n_diff_pfx02 | 882192 | 20 | key1,id || yhd | single_table | idx_key1 | 2021-12-19 02:13:19 | n_leaf_pages | 828 | NULL | Number of leaf pages in the index || yhd | single_table | idx_key1 | 2021-12-19 02:13:19 | size | 993 | NULL | Number of pages in the index || yhd | single_table | idx_key3 | 2021-12-19 02:13:19 | n_diff_pfx01 | 8 | 10 | key3 || yhd | single_table | idx_key3 | 2021-12-19 02:13:19 | n_diff_pfx02 | 910072 | 20 | key3,id || yhd | single_table | idx_key3 | 2021-12-19 02:13:19 | n_leaf_pages | 827 | NULL | Number of leaf pages in the index || yhd | single_table | idx_key3 | 2021-12-19 02:13:19 | size | 993 | NULL | Number of pages in the index || yhd | single_table | idx_key_part | 2021-12-19 02:13:19 | n_diff_pfx01 | 8 | 10 | key_part1 || yhd | single_table | idx_key_part | 2021-12-19 02:13:19 | n_diff_pfx02 | 82 | 20 | key_part1,key_part2 || yhd | single_table | idx_key_part | 2021-12-19 02:13:19 | n_diff_pfx03 | 730 | 20 | key_part1,key_part2,key_part3 || yhd | single_table | idx_key_part | 2021-12-19 02:13:19 | n_diff_pfx04 | 1028534 | 20 | key_part1,key_part2,key_part3,id || yhd | single_table | idx_key_part | 2021-12-19 02:13:19 | n_leaf_pages | 2556 | NULL | Number of leaf pages in the index || yhd | single_table | idx_key_part | 2021-12-19 02:13:19 | size | 2985 | NULL | Number of pages in the index || yhd | single_table | uk_key2 | 2021-12-19 02:13:19 | n_diff_pfx01 | 913104 | 20 | key2 || yhd | single_table | uk_key2 | 2021-12-19 02:13:19 | n_leaf_pages | 816 | NULL | Number of leaf pages in the index || yhd | single_table | uk_key2 | 2021-12-19 02:13:19 | size | 865 | NULL | Number of pages in the index |+---------------+--------------+--------------+---------------------+--------------+------------+-------------+-----------------------------------+20 rows in set (0.01 sec) 这个结果有点儿多，正确查看这个结果的方式是这样的： 先查看index_name列，这个列说明该记录是哪个索引的统计信息，从结果中我们可以看出来，PRIMARY索引（也就是主键）占了3条记录，idx_key_part索引占了6条记录。 针对index_name列相同的记录，stat_name表示针对该索引的统计项名称，stat_value展示的是该索引在该统计项上的值，stat_description指的是来描述该统计项的含义的。我们来具体看一下一个索引都有哪些统计项： n_leaf_pages：表示该索引的叶子节点占用多少页面。 size：表示该索引共占用多少页面。 n_diff_pfx**NN**：表示对应的索引列不重复的值有多少。其实NN可以被替换为01、02、03… 这样的数字。比如对于idx_key_part来说： 1. n_diff_pfx01表示的是统计key_part1这单单一个列不重复的值有多少。 1. n_diff_pfx02表示的是统计key_part1、key_part2这两个列组合起来不重复的值有多少。 1. n_diff_pfx03表示的是统计key_part1、key_part2、key_part3这三个列组合起来不重复的值有多少。 1. n_diff_pfx04表示的是统计key_part1、key_part2、key_part3、id这四个列组合起来不重复的值有多少。 注意：对于普通的二级索引，并不能保证它的索引列值是唯一的，比如对于idx_key1来说，key1列就可能有很多值重复的记录。此时只有在索引列上加上主键值才可以区分两条索引列值都一样的二级索引记录。对于主键和唯一二级索引则没有这个问题，它们本身就可以保证索引列值的不重复，所以也不需要再统计一遍在索引列后加上主键值的不重复值有多少。比如上边的idx_key1有n_diff_pfx01、n_diff_pfx02两个统计项，而idx_key2却只有n_diff_pfx01一个统计项。 在计算某些索引列中包含多少不重复值时，需要对一些叶子节点页面进行采样，sample_size列就表明了采样的页面数量是多少。 注意：对于有多个列的联合索引来说，采样的页面数量是：innodb_stats_persistent_sample_pages × 索引列的个数。当需要采样的页面数量大于该索引的叶子节点数量的话，就直接采用全表扫描来统计索引列的不重复值数量了。所以在查询结果中看到不同索引对应的size列的值可能是不同的。 2.3定期更新统计数据随着我们不断的对表进行增删改操作，表中的数据也一直在变化，innodb_table_stats和innodb_index_stats表里的统计数据是要变的，不变的话MySQL查询优化器计算的成本就会有问题。MySQL提供了如下两种更新统计数据的方式： 开启innodb_stats_auto_recalc。系统变量innodb_stats_auto_recalc决定着服务器是否自动重新计算统计数据，它的默认值是ON，也就是该功能默认是开启的。每个表都维护了一个变量，该变量记录着对该表进行增删改的记录条数，如果发生变动的记录数量超过了表大小的10%，并且自动重新计算统计数据的功能是打开的，那么服务器会重新进行一次统计数据的计算，并且更新innodb_table_stats和innodb_index_stats表。不过自动重新计算统计数据的过程是异步发生的，也就是即使表中变动的记录数超过了10%，自动重新计算统计数据也不会立即发生，可能会延迟几秒才会进行计算。InnoDB默认是以表为单位来收集和存储统计数据的，我们也可以单独为某个表设置是否自动重新计算统计数的属性，设置方式就是在创建或修改表的时候通过指定STATS_AUTO_RECALC属性来指明该表的统计数据存储方式：当STATS_AUTO_RECALC=1时，表明我们想让该表自动重新计算统计数据，当STATS_AUTO_RECALC=0时，表明不想让该表自动重新计算统计数据。如果我们在创建表时未指定STATS_AUTO_RECALC属性，那默认采用系统变量innodb_stats_auto_recalc的值作为该属性的值。 123CREATE TABLE 表名 (...) Engine=InnoDB, STATS_AUTO_RECALC = (1|0);ALTER TABLE 表名 Engine=InnoDB, STATS_AUTO_RECALC = (1|0); 手动调用ANALYZE TABLE语句来更新统计信息如果innodb_stats_auto_recalc系统变量的值为OFF的话，我们也可以手动调用ANALYZE TABLE语句来重新计算统计数据，比如我们可以这样更新关于single_table表的统计数据：需要注意的是，ANALYZE TABLE语句会立即重新计算统计数据，也就是这个过程是同步的，在表中索引多或者采样页面特别多时这个过程可能会特别慢，请不要没事儿就运行一下ANALYZE TABLE语句，最好在业务不是很繁忙的时候再运行。 1234567mysql&gt; ANALYZE TABLE single_table;+------------------------+---------+----------+----------+| Table | Op | Msg_type | Msg_text |+------------------------+---------+----------+----------+| yhd.single_table | analyze | status | OK |+------------------------+---------+----------+----------+1 row in set (0.08 sec) 2.4手动更新统计数据其实innodb_table_stats和innodb_index_stats表就相当于一个普通的表一样，我们能对它们做增删改查操作。这也就意味着我们可以手动更新某个表或者索引的统计数据。比如说我们想把single_table表关于行数的统计数据更改一下可以这么做： 步骤一：更新innodb_table_stats表。 123UPDATE innodb_table_stats SET n_rows = 1 WHERE table_name = &#x27;single_table&#x27;; 步骤二：让MySQL查询优化器重新加载我们更改过的数据。更新完innodb_table_stats只是单纯的修改了一个表的数据，需要让MySQL查询优化器重新加载我们更改过的数据，运行下边的命令就可以了： 1FLUSH TABLE single_table; 之后我们使用SHOW TABLE STATUS语句查看表的统计数据时就看到Rows行变为了1。 3.非永久性统计数据当我们把系统变量innodb_stats_persistent的值设置为OFF时，之后创建的表的统计数据默认就都是非永久性的了，或者我们直接在创建表或修改表时设置STATS_PERSISTENT属性的值为0，那么该表的统计数据就是非永久性的了。 与永久性的统计数据不同，非永久性的统计数据采样的页面数量是由innodb_stats_transient_sample_pages控制的，这个系统变量的默认值是8。 另外，由于非永久性的统计数据经常更新，所以导致MySQL查询优化器计算查询成本的时候依赖的是经常变化的统计数据，也就会生成经常变化的执行计划。 4.innodb_stats_method索引列不重复的值的数量这个统计数据对于MySQL查询优化器十分重要，因为通过它可以计算出在索引列中平均一个值重复多少行，它的应用场景主要有两个： 单表查询中单点区间太多，比方说这样：当IN里的参数数量过多时，采用index dive的方式直接访问B+树索引去统计每个单点区间对应的记录的数量就太耗费性能了，所以直接依赖统计数据中的平均一个值重复多少行来计算单点区间对应的记录数量。 1SELECT * FROM tbl_name WHERE key IN (&#x27;xx1&#x27;, &#x27;xx2&#x27;, ..., &#x27;xxn&#x27;); 连接查询时，如果有涉及两个表的等值匹配连接条件，该连接条件对应的被驱动表中的列又拥有索引时，则可以使用ref访问方法来对被驱动表进行查询，比方说这样：在真正执行对t2表的查询前，t1.comumn的值是不确定的，所以我们也不能通过index dive的方式直接访问B+树索引去统计每个单点区间对应的记录的数量，所以也只能依赖统计数据中的平均一个值重复多少行来计算单点区间对应的记录数量。 1SELECT * FROM t1 JOIN t2 ON t1.column = t2.key WHERE ...; 在统计索引列不重复的值的数量时，有一个比较烦的问题就是索引列中出现NULL值怎么办，比方说某个索引列的内容是这样： 12345678+------+| col |+------+| 1 || 2 || NULL || NULL |+------+ 此时计算这个col列中不重复的值的数量就有下边的分歧： 有的人认为NULL值代表一个未确定的值，所以MySQL认为任何和NULL值做比较的表达式的值都为NULL，就是这样：所以每一个NULL值都是独一无二的，也就是说统计索引列不重复的值的数量时，应该把NULL值当作一个独立的值，所以col列的不重复的值的数量就是：4（分别是1、2、NULL、NULL这四个值）。 12345678910111213141516171819202122232425262728293031mysql&gt; SELECT 1 = NULL;+----------+| 1 = NULL |+----------+| NULL |+----------+1 row in set (0.00 sec)mysql&gt; SELECT 1 != NULL;+-----------+| 1 != NULL |+-----------+| NULL |+-----------+1 row in set (0.00 sec)mysql&gt; SELECT NULL = NULL;+-------------+| NULL = NULL |+-------------+| NULL |+-------------+1 row in set (0.00 sec)mysql&gt; SELECT NULL != NULL;+--------------+| NULL != NULL |+--------------+| NULL |+--------------+1 row in set (0.00 sec) 有的人认为其实NULL值在业务上就是代表没有，所有的NULL值代表的意义是一样的，所以col列不重复的值的数量就是：3（分别是1、2、NULL这三个值）。 有的人认为这NULL完全没有意义嘛，所以在统计索引列不重复的值的数量时压根儿不能把它们算进来，所以col列不重复的值的数量就是：2（分别是1、2这两个值）。 MySQL提供了一个名为innodb_stats_method的系统变量，我们可以自己来设置，这个系统变量有三个候选值： nulls_equal：认为所有NULL值都是相等的。这个值也是innodb_stats_method的默认值。如果某个索引列中NULL值特别多的话，这种统计方式会让优化器认为某个列中平均一个值重复次数特别多，所以倾向于不使用索引进行访问。 nulls_unequal：认为所有NULL值都是不相等的。如果某个索引列中NULL值特别多的话，这种统计方式会让优化器认为某个列中平均一个值重复次数特别少，所以倾向于使用索引进行访问。 nulls_ignored：直接把NULL值忽略掉。 5.总结 InnoDB以表为单位来收集统计数据，这些统计数据可以是基于磁盘的永久性统计数据，也可以是基于内存的非永久性统计数据。 innodb_stats_persistent控制着使用永久性统计数据还是非永久性统计数据；innodb_stats_persistent_sample_pages控制着永久性统计数据的采样页面数量；innodb_stats_transient_sample_pages控制着非永久性统计数据的采样页面数量；innodb_stats_auto_recalc控制着是否自动重新计算统计数据。 我们可以针对某个具体的表，在创建和修改表时通过指定STATS_PERSISTENT、STATS_AUTO_RECALC、STATS_SAMPLE_PAGES的值来控制相关统计数据属性。 innodb_stats_method决定着在统计某个索引列不重复值的数量时如何对待NULL值。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[七]基于成本的优化","slug":"MySQL/MySQL[七]基于成本的优化","date":"2022-01-11T03:16:05.985Z","updated":"2022-01-11T03:21:45.620Z","comments":true,"path":"2022/01/11/MySQL/MySQL[七]基于成本的优化/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E4%B8%83]%E5%9F%BA%E4%BA%8E%E6%88%90%E6%9C%AC%E7%9A%84%E4%BC%98%E5%8C%96/","excerpt":"","text":"1.什么是成本？在MySQL中一条查询语句的执行成本是由下边这两个方面组成的： I/O成本我们的表经常使用的MyISAM、InnoDB存储引擎都是将数据和索引都存储到磁盘上的，当我们想查询表中的记录时，需要先把数据或者索引加载到内存中然后再操作。这个从磁盘到内存这个加载的过程损耗的时间称之为I/O成本。 CPU成本读取以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称之为CPU成本。 对于InnoDB存储引擎来说，页是磁盘和内存之间交互的基本单位，MySQL规定读取一个页面花费的成本默认是1.0，读取以及检测一条记录是否符合搜索条件的成本默认是0.2。1.0、0.2这些数字称之为成本常数。 不管读取记录时需不需要检测是否满足搜索条件，其成本都算是0.2。 2.单表查询的成本2.1 准备工作把之前用到的single_table表搬来。 123456789101112131415CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3)) Engine=InnoDB CHARSET=utf8; 2.2 基于成本的优化步骤在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案，这个成本最低的方案就是所谓的执行计划，之后才会调用存储引擎提供的接口真正的执行查询，这个过程总结一下就是这样： 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种执行方案的代价，找出成本最低的那一个 下边我们就以一个实例来分析一下这些步骤，单表查询语句如下： 123456SELECT * FROM single_table WHERE key1 IN (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;) AND key2 &gt; 10 AND key2 &lt; 1000 AND key3 &gt; key2 AND key_part1 LIKE &#x27;%hello%&#x27; AND common_field = &#x27;123&#x27;; 2.2.1 根据搜索条件，找出所有可能使用的索引对于B+树索引来说，只要索引列和常数使用=、&lt;=&gt;、IN、NOT IN、IS NULL、IS NOT NULL、&gt;、&lt;、&gt;=、&lt;=、BETWEEN、!=（不等于也可以写成&lt;&gt;）或者LIKE操作符连接起来，就可以产生一个所谓的范围区间（LIKE匹配字符串前缀也行），也就是说这些搜索条件都可能使用到索引，MySQL把一个查询中可能使用到的索引称之为possible keys。 我们分析一下上边查询中涉及到的几个搜索条件： key1 IN (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)，这个搜索条件可以使用二级索引idx_key1。 key2 &gt; 10 AND key2 &lt; 1000，这个搜索条件可以使用二级索引idx_key2。 key3 &gt; key2，这个搜索条件的索引列由于没有和常数比较，所以并不能使用到索引。 key_part1 LIKE &#39;%hello%&#39;，key_part1通过LIKE操作符和以通配符开头的字符串做比较，不可以适用索引。 common_field = &#39;123&#39;，由于该列上压根儿没有索引，所以不会用到索引。 综上所述，上边的查询语句可能用到的索引，也就是possible keys只有idx_key1和idx_key2。 2.2.2 计算全表扫描的代价对于InnoDB存储引擎来说，全表扫描的意思就是把聚簇索引中的记录都依次和给定的搜索条件做一下比较，把符合搜索条件的记录加入到结果集，所以需要将聚簇索引对应的页面加载到内存中，然后再检测记录是否符合搜索条件。由于查询成本=I/O成本+CPU成本，所以计算全表扫描的代价需要两个信息： 聚簇索引占用的页面数 该表中的记录数 这两个信息从哪来呢？MySQL为每个表维护了一系列的统计信息，关于这些统计信息是如何收集起来的后面再谈，现在看看怎么查看这些统计信息。MySQL给我们提供了SHOW TABLE STATUS语句来查看表的统计信息，如果要看指定的某个表的统计信息，在该语句后加对应的LIKE语句就好了，比方说我们要查看single_table这个表的统计信息可以这么写： 1SHOW TABLE STATUS LIKE &#x27;single_table&#x27; 虽然出现了很多统计选项，但我们目前只关心两个： Rows本选项表示表中的记录条数。对于使用MyISAM存储引擎的表来说，该值是准确的，对于使用InnoDB存储引擎的表来说，该值是一个估计值。从查询结果我们也可以看出来，由于我们的single_table表是使用InnoDB存储引擎的，所以虽然实际上表中有10000条记录，但是SHOW TABLE STATUS显示的Rows值只有9693条记录。 Data_length本选项表示表占用的存储空间字节数。使用MyISAM存储引擎的表来说，该值就是数据文件的大小，对于使用InnoDB存储引擎的表来说，该值就相当于聚簇索引占用的存储空间大小，也就是说可以这样计算该值的大小：我们的single_table使用默认16KB的页面大小，而上边查询结果显示Data_length的值是1589248，所以我们可以反向来推导出聚簇索引的页面数量： 1Data_length = 聚簇索引的页面数量 x 每个页面的大小 1聚簇索引的页面数量 = 1589248 ÷ 16 ÷ 1024 = 97 我们现在已经得到了聚簇索引占用的页面数量以及该表记录数的估计值，所以就可以计算全表扫描成本了，但是MySQL在真实计算成本时会进行一些微调，这些微调的值是直接硬编码到代码里的，这些微调的值十分的小，并不影响我们分析。现在可以看一下全表扫描成本的计算过程： I/O成本97指的是聚簇索引占用的页面数，1.0指的是加载一个页面的成本常数，后边的1.1是一个微调值，我们不用在意。 197 x 1.0 + 1.1 = 98.1 CPU成本：9693指的是统计数据中表的记录数，对于InnoDB存储引擎来说是一个估计值，0.2指的是访问一条记录所需的成本常数，后边的1.0是一个微调值，我们不用在意。 19693 x 0.2 + 1.0 = 1939.6 总成本： 198.1 + 1939.6 = 2037.7 综上所述，对于single_table的全表扫描所需的总成本就是2037.7。 表中的记录其实都存储在聚簇索引对应B+树的叶子节点中，所以只要我们通过根节点获得了最左边的叶子节点，就可以沿着叶子节点组成的双向链表把所有记录都查看一遍。也就是说全表扫描这个过程其实有的B+树内节点是不需要访问的，但是MySQL在计算全表扫描成本时直接使用聚簇索引占用的页面数作为计算I/O成本的依据，是不区分内节点和叶子节点的。 2.2.3 计算使用不同索引执行查询的代价从第1步分析我们得到，上述查询可能使用到idx_key1和idx_key2这两个索引，我们需要分别分析单独使用这些索引执行查询的成本，最后还要分析是否可能使用到索引合并。这里需要提一点的是，MySQL查询优化器先分析使用唯一二级索引的成本，再分析使用普通索引的成本，所以我们也先分析idx_key2的成本，然后再看使用idx_key1的成本。 ①使用idx_key2执行查询的成本分析idx_key2对应的搜索条件是：key2 &gt; 10 AND key2 &lt; 1000，也就是说对应的范围区间就是：(10, 1000)，使用idx_key2搜索的示意图就是这样子： 对于使用二级索引 + 回表方式的查询，MySQL计算这种查询的成本依赖两个方面的数据： 范围区间数量不论某个范围区间的二级索引到底占用了多少页面，查询优化器粗暴的认为读取索引的一个范围区间的I/O成本和读取一个页面是相同的。本例中使用idx_key2的范围区间只有一个：(10, 1000)，所以相当于访问这个范围区间的二级索引付出的I/O成本就是： 11 x 1.0 = 1.0 需要回表的记录数优化器需要计算二级索引的某个范围区间到底包含多少条记录，对于本例来说就是要计算idx_key2在(10, 1000)这个范围区间中包含多少二级索引记录，计算过程是这样的： 步骤1：先根据key2 &gt; 10这个条件访问一下idx_key2对应的B+树索引，找到满足key2 &gt; 10这个条件的第一条记录，我们把这条记录称之为区间最左记录。在B+数树中定位一条记录的过程是贼快的，是常数级别的，所以这个过程的性能消耗是可以忽略不计的。 步骤2：然后再根据key2 &lt; 1000这个条件继续从idx_key2对应的B+树索引中找出最后一条满足这个条件的记录，我们把这条记录称之为区间最右记录，这个过程的性能消耗也可以忽略不计的。 步骤3：如果区间最左记录和区间最右记录相隔不太远（在MySQL 5.7.21这个版本里，只要相隔不大于10个页面即可），那就可以精确统计出满足key2 &gt; 10 AND key2 &lt; 1000条件的二级索引记录条数。否则只沿着区间最左记录向右读10个页面，计算平均每个页面中包含多少记录，然后用这个平均值乘以区间最左记录和区间最右记录之间的页面数量就可以了。那么问题又来了，怎么估计区间最左记录和区间最右记录之间有多少个页面呢？解决这个问题还得回到B+树索引的结构中来： 如图，我们假设区间最左记录在页b中，区间最右记录在页c中，那么我们想计算区间最左记录和区间最右记录之间的页面数量就相当于计算页b和页c之间有多少页面，而每一条目录项记录都对应一个数据页，所以计算页b和页c之间有多少页面就相当于计算它们父节点（也就是页a）中对应的目录项记录之间隔着几条记录。在一个页面中统计两条记录之间有几条记录的成本就贼小了。如果页b和页c之间的页面实在太多，以至于页b和页c对应的目录项记录都不在一个页面中，继续递归，也就是再统计页b和页c对应的目录项记录所在页之间有多少个页面。过一个B+树有4层高已经很了不得了，所以这个统计过程也不是很耗费性能。知道了如何统计二级索引某个范围区间的记录数之后，就需要回到现实问题中来，根据上述算法测得idx_key2在区间(10, 1000)之间大约有95条记录。读取这95条二级索引记录需要付出的CPU成本就是： 195 x 0.2 + 0.01 = 19.01 其中95是需要读取的二级索引记录条数，0.2是读取一条记录成本常数，0.01是微调。在通过二级索引获取到记录之后，还需要干两件事儿： 根据这些记录里的主键值到聚簇索引中做回表操作MySQL认为每次回表操作都相当于访问一个页面，也就是说二级索引范围区间有多少记录，就需要进行多少次回表操作，也就是需要进行多少次页面I/O。我们上边统计了使用idx_key2二级索引执行查询时，预计有95条二级索引记录需要进行回表操作，所以回表操作带来的I/O成本就是：其中95是预计的二级索引记录数，1.0是一个页面的I/O成本常数。 195 x 1.0 = 95.0 回表操作后得到的完整用户记录，然后再检测其他搜索条件是否成立回表操作的本质就是通过二级索引记录的主键值到聚簇索引中找到完整的用户记录，然后再检测除key2 &gt; 10 AND key2 &lt; 1000这个搜索条件以外的搜索条件是否成立。因为我们通过范围区间获取到二级索引记录共95条，也就对应着聚簇索引中95条完整的用户记录，读取并检测这些完整的用户记录是否符合其余的搜索条件的CPU成本如下：MySQL只计算这个查找过程所需的I/O成本，也就是我们上一步骤中得到的95.0，在内存中的定位完整用户记录的过程的成本是忽略不计的。在定位到这些完整的用户记录后，需要检测除key2 &gt; 10 AND key2 &lt; 1000这个搜索条件以外的搜索条件是否成立，这个比较过程花费的CPU成本就是：其中95是待检测记录的条数，0.2是检测一条记录是否符合给定的搜索条件的成本常数。 195 x 0.2 = 19.0 所以本例中使用idx_key2执行查询的成本就如下所示： I/O成本： 11.0 + 95 x 1.0 = 96.0 (范围区间的数量 + 预估的二级索引记录条数) CPU成本： 195 x 0.2 + 0.01 + 95 x 0.2 = 38.01 （读取二级索引记录的成本 + 读取并检测回表后聚簇索引记录的成本） 综上所述，使用idx_key2执行查询的总成本就是： 196.0 + 38.01 = 134.01 ②使用idx_key1执行查询的成本分析idx_key1对应的搜索条件是：key1 IN (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)，也就是说相当于3个单点区间： [&#39;a&#39;, &#39;a&#39;] [&#39;b&#39;, &#39;b&#39;] [&#39;c&#39;, &#39;c&#39;] 使用idx_key1搜索的示意图就是这样子： 与使用idx_key2的情况类似，我们也需要计算使用idx_key1时需要访问的范围区间数量以及需要回表的记录数： 范围区间数量使用idx_key1执行查询时很显然有3个单点区间，所以访问这3个范围区间的二级索引付出的I/O成本就是： 13 x 1.0 = 3.0 需要回表的记录数由于使用idx_key1时有3个单点区间，所以每个单点区间都需要查找一遍对应的二级索引记录数： 查找单点区间[&#39;a&#39;, &#39;a&#39;]对应的二级索引记录数计算单点区间对应的二级索引记录数和计算连续范围区间对应的二级索引记录数是一样的，都是先计算区间最左记录和区间最右记录，然后再计算它们之间的记录数，最后计算得到单点区间[&#39;a&#39;, &#39;a&#39;]对应的二级索引记录数是：35。 查找单点区间[&#39;b&#39;, &#39;b&#39;]对应的二级索引记录数与上同理，计算得到本单点区间对应的记录数是：44。 查找单点区间[&#39;c&#39;, &#39;c&#39;]对应的二级索引记录数与上同理，计算得到本单点区间对应的记录数是：39。 所以，这三个单点区间总共需要回表的记录数就是： 135 + 44 + 39 = 118 读取这些二级索引记录的CPU成本就是： 1118 x 0.2 + 0.01 = 23.61 得到总共需要回表的记录数之后，就要考虑： 根据这些记录里的主键值到聚簇索引中做回表操作所需的I/O成本就是： 1118 x 1.0 = 118.0 回表操作后得到的完整用户记录，然后再比较其他搜索条件是否成立此步骤对应的CPU成本就是： 1118 x 0.2 = 23.6 所以本例中使用idx_key1执行查询的成本就如下所示： I/O成本： 13.0 + 118 x 1.0 = 121.0 (范围区间的数量 + 预估的二级索引记录条数) CPU成本： 1118 x 0.2 + 0.01 + 118 x 0.2 = 47.21 （读取二级索引记录的成本 + 读取并检测回表后聚簇索引记录的成本） 综上所述，使用idx_key1执行查询的总成本就是： 1121.0 + 47.21 = 168.21 ③是否有可能使用索引合并（Index Merge）本例中有关key1和key2的搜索条件是使用AND连接起来的，而对于idx_key1和idx_key2都是范围查询，也就是说查找到的二级索引记录并不是按照主键值进行排序的，并不满足使用Intersection索引合并的条件，所以并不会使用索引合并。 2.2.4 对比各种执行方案的代价，找出成本最低的那一个下边把执行本例中的查询的各种可执行方案以及它们对应的成本列出来： 全表扫描的成本：2037.7 使用idx_key2的成本：134.01 使用idx_key1的成本：168.21 很显然，使用idx_key2的成本最低，所以选择idx_key2来执行查询。 2.3 基于索引统计数据的成本计算有时候使用索引执行查询时会有许多单点区间，比如使用IN语句就很容易产生非常多的单点区间，比如下边这个查询（下边查询语句中的...表示还有很多参数）： 1SELECT * FROM single_table WHERE key1 IN (&#x27;aa1&#x27;, &#x27;aa2&#x27;, &#x27;aa3&#x27;, ... , &#x27;zzz&#x27;); 很显然，这个查询可能使用到的索引就是idx_key1，由于这个索引并不是唯一二级索引，所以并不能确定一个单点区间对应的二级索引记录的条数有多少，需要我们去计算。计算方式就是先获取索引对应的B+树的区间最左记录和区间最右记录，然后再计算这两条记录之间有多少记录（记录条数少的时候可以做到精确计算，多的时候只能估算）。MySQL把这种通过直接访问索引对应的B+树来计算某个范围区间对应的索引记录条数的方式称之为index dive。 index dive就是直接利用索引对应的B+树来计算某个范围区间对应的记录条数。 有几个单点区间的话，使用index dive的方式去计算这些单点区间对应的记录数也不是什么问题，可是如果很多的话，这就意味着MySQL的查询优化器为了计算这些单点区间对应的索引记录条数，要进行20000次index dive操作，这性能损耗可就大了，搞不好计算这些单点区间对应的索引记录条数的成本比直接全表扫描的成本都大了。MySQL提供了一个系统变量eq_range_index_dive_limit，我们看一下在MySQL 5.7.21中这个系统变量的默认值： 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;%dive%&#x27;;+---------------------------+-------+| Variable_name | Value |+---------------------------+-------+| eq_range_index_dive_limit | 200 |+---------------------------+-------+1 row in set (0.08 sec) 也就是说如果我们的IN语句中的参数个数小于200个的话，将使用index dive的方式计算各个单点区间对应的记录条数，如果大于或等于200个的话，可就不能使用index dive了，要使用所谓的索引统计数据来进行估算。 像会为每个表维护一份统计数据一样，MySQL也会为表中的每一个索引维护一份统计数据，查看某个表中索引的统计数据可以使用SHOW INDEX FROM 表名的语法，比如我们查看一下single_table的各个索引的统计数据可以这么写： 12345678910111213mysql&gt; SHOW INDEX FROM single_table;+--------------+------------+--------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+--------------+------------+--------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| single_table | 0 | PRIMARY | 1 | id | A | 9693 | NULL | NULL | | BTREE | | || single_table | 0 | idx_key2 | 1 | key2 | A | 9693 | NULL | NULL | YES | BTREE | | || single_table | 1 | idx_key1 | 1 | key1 | A | 968 | NULL | NULL | YES | BTREE | | || single_table | 1 | idx_key3 | 1 | key3 | A | 799 | NULL | NULL | YES | BTREE | | || single_table | 1 | idx_key_part | 1 | key_part1 | A | 9673 | NULL | NULL | YES | BTREE | | || single_table | 1 | idx_key_part | 2 | key_part2 | A | 9999 | NULL | NULL | YES | BTREE | | || single_table | 1 | idx_key_part | 3 | key_part3 | A | 10000 | NULL | NULL | YES | BTREE | | |+--------------+------------+--------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+7 rows in set (0.01 sec) 属性名 描述 Table 索引所属表的名称。 Non_unique 索引列的值是否是唯一的，聚簇索引和唯一二级索引的该列值为0 ，普通二级索引该列值为1 。 Key_name 索引的名称。 Seq_in_index 索引列在索引中的位置，从1开始计数。比如对于联合索引idx_key_part ，来说，key_part1 、key_part2 和key_part3 对应的位置分别是1、2、3。 Column_name 索引列的名称。 Collation 索引列中的值是按照何种排序方式存放的，值为A 时代表升序存放，为NULL 时代表降序存放。 Cardinality 索引列中不重复值的数量。后边我们会重点看这个属性的。 Sub_part 对于存储字符串或者字节串的列来说，有时候我们只想对这些串的前n 个字符或字节建立索引，这个属性表示的就是那个n 值。如果对完整的列建立索引的话，该属性的值就是NULL 。 Packed 索引列如何被压缩，NULL 值表示未被压缩。这个属性我们暂时不了解，可以先忽略掉。 Null 该索引列是否允许存储NULL 值。 Index_type 使用索引的类型，我们最常见的就是BTREE ，其实也就是B+ 树索引。 Comment 索引列注释信息。 Index_comment 索引注释信息。 上述属性其实我们现在最在意的是Cardinality属性，Cardinality直译过来就是基数的意思，表示索引列中不重复值的个数。比如对于一个一万行记录的表来说，某个索引列的Cardinality属性是10000，那意味着该列中没有重复的值，如果Cardinality属性是1的话，就意味着该列的值全部是重复的。不过需要注意的是，对于InnoDB存储引擎来说，使用SHOW INDEX语句展示出来的某个索引列的Cardinality属性是一个估计值，并不是精确的。 前边说道，当IN语句中的参数个数大于或等于系统变量eq_range_index_dive_limit的值的话，就不会使用index dive的方式计算各个单点区间对应的索引记录条数，而是使用索引统计数据，这里所指的索引统计数据指的是这两个值： 使用SHOW TABLE STATUS展示出的Rows值，也就是一个表中有多少条记录。 使用SHOW INDEX语句展示出的Cardinality属性。结合上一个Rows统计数据，我们可以针对索引列，计算出平均一个值重复多少次。 1一个值的重复次数 ≈ Rows ÷ Cardinality 以single_table表的idx_key1索引为例，它的Rows值是9693，它对应索引列key1的Cardinality值是968，所以我们可以计算key1列平均单个值的重复次数就是： 19693 ÷ 968 ≈ 10（条） 此时再看上边那条查询语句： 1SELECT * FROM single_table WHERE key1 IN (&#x27;aa1&#x27;, &#x27;aa2&#x27;, &#x27;aa3&#x27;, ... , &#x27;zzz&#x27;); 假设IN语句中有20000个参数的话，就直接使用统计数据来估算这些参数需要单点区间对应的记录条数了，每个参数大约对应10条记录，所以总共需要回表的记录数就是： 120000 x 10 = 200000 使用统计数据来计算单点区间对应的索引记录条数可比index dive的方式简单多了，但是不精确！。使用统计数据算出来的查询成本与实际所需的成本可能相差非常大。 在MySQL 5.7.3以及之前的版本中，eq_range_index_dive_limit的默认值为10，之后的版本默认值为200。所以如果采用的是5.7.3以及之前的版本的话，很容易采用索引统计数据而不是index dive的方式来计算查询成本。当查询中使用到了IN查询，但是却实际没有用到索引，就应该考虑一下是不是由于 eq_range_index_dive_limit 值太小导致的。 3. 连接查询的成本我们直接构造一个和single_table表一模一样的single_table2表。为了简便起见，我们把single_table表称为s1表，把single_table2表称为s2表。 3.1 条件过滤我们前边说过，MySQL中连接查询采用的是嵌套循环连接算法，驱动表会被访问一次，被驱动表可能会被访问多次，所以对于两表连接查询来说，它的查询成本由下边两个部分构成： 单次查询驱动表的成本 多次查询被驱动表的成本（具体查询多少次取决于对驱动表查询的结果集中有多少条记录） 我们把对驱动表进行查询后得到的记录条数称之为驱动表的扇出（英文名：fanout）。很显然驱动表的扇出值越小，对被驱动表的查询次数也就越少，连接查询的总成本也就越低。当查询优化器想计算整个连接查询所使用的成本时，就需要计算出驱动表的扇出值，有的时候扇出值的计算是很容易的，比如下边这两个查询： 查询一：假设使用s1表作为驱动表，很显然对驱动表的单表查询只能使用全表扫描的方式执行，驱动表的扇出值也很明确，那就是驱动表中有多少记录，扇出值就是多少。我们前边说过，统计数据中s1表的记录行数是9693，也就是说优化器就直接会把9693当作在s1表的扇出值。 1SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2; 查询二：仍然假设s1表是驱动表的话，很显然对驱动表的单表查询可以使用idx_key2索引执行查询。此时idx_key2的范围区间(10, 1000)中有多少条记录，那么扇出值就是多少。我们前边计算过，满足idx_key2的范围区间(10, 1000)的记录数是95条，也就是说本查询中优化器会把95当作驱动表s1的扇出值。 12SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2 WHERE s1.key2 &gt;10 AND s1.key2 &lt; 1000; 有的时候扇出值的计算就变得很棘手，比方说下边几个查询： 查询三：本查询和查询一类似，只不过对于驱动表s1多了一个common_field &gt; &#39;xyz&#39;的搜索条件。查询优化器又不会真正的去执行查询，所以它只能猜这9693记录里有多少条记录满足common_field &gt; &#39;xyz&#39;条件。 12SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2 WHERE s1.common_field &gt; &#x27;xyz&#x27;; 查询四：本查询和查询二类似，只不过对于驱动表s1也多了一个common_field &gt; &#39;xyz&#39;的搜索条件。不过因为本查询可以使用idx_key2索引，所以只需要从符合二级索引范围区间的记录中猜有多少条记录符合common_field &gt; &#39;xyz&#39;条件，也就是只需要猜在95条记录中有多少符合common_field &gt; &#39;xyz&#39;条件。 123SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2 WHERE s1.key2 &gt; 10 AND s1.key2 &lt; 1000 AND s1.common_field &gt; &#x27;xyz&#x27;; 查询五：本查询和查询二类似，不过在驱动表s1选取idx_key2索引执行查询后，优化器需要从符合二级索引范围区间的记录中猜有多少条记录符合下边两个条件： 1234SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2 WHERE s1.key2 &gt; 10 AND s1.key2 &lt; 1000 AND s1.key1 IN (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;) AND s1.common_field &gt; &#x27;xyz&#x27;; key1 IN (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) common_field &gt; &#39;xyz&#39; 也就是优化器需要猜在95条记录中有多少符合上述两个条件的。 说了这么多，其实就是想表达在这两种情况下计算驱动表扇出值时需要靠猜： 如果使用的是全表扫描的方式执行的单表查询，那么计算驱动表扇出时需要猜满足搜索条件的记录到底有多少条。 如果使用的是索引执行的单表扫描，那么计算驱动表扇出的时候需要猜满足除使用到对应索引的搜索条件外的其他搜索条件的记录有多少条。 MySQL把这个猜的过程称之为condition filtering。当然，这个过程可能会使用到索引，也可能使用到统计数据，也可能就是MySQL单纯的瞎猜。 在MySQL 5.7之前的版本中，查询优化器在计算驱动表扇出时，如果是使用全表扫描的话，就直接使用表中记录的数量作为扇出值，如果使用索引的话，就直接使用满足范围条件的索引记录条数作为扇出值。在MySQL 5.7中，MySQL引入了这个condition filtering的功能，就是还要猜一猜剩余的那些搜索条件能把驱动表中的记录再过滤多少条，其实本质上就是为了让成本估算更精确。 MySQL称之为启发式规则（heuristic）。 3.2 两表连接成本分析连接查询的成本计算公式是这样的： 1连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本 对于左（外）连接和右（外）连接查询来说，它们的驱动表是固定的，所以想要得到最优的查询方案只需要： 分别为驱动表和被驱动表选择成本最低的访问方法。 可是对于内连接来说，驱动表和被驱动表的位置是可以互换的，所以需要考虑两个方面的问题： 不同的表作为驱动表最终的查询成本可能是不同的，也就是需要考虑最优的表连接顺序。 然后分别为驱动表和被驱动表选择成本最低的访问方法。 很显然，计算内连接查询成本的方式更麻烦一些，下边我们就以内连接为例来看看如何计算出最优的连接查询方案。 左（外）连接和右（外）连接查询在某些特殊情况下可以被优化为内连接查询。 比如对于下边这个查询来说： 1234SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2 ON s1.key1 = s2.common_field WHERE s1.key2 &gt; 10 AND s1.key2 &lt; 1000 AND s2.key2 &gt; 1000 AND s2.key2 &lt; 2000; 可以选择的连接顺序有两种： s1连接s2，也就是s1作为驱动表，s2作为被驱动表。 s2连接s1，也就是s2作为驱动表，s1作为被驱动表。 查询优化器需要分别考虑这两种情况下的最优查询成本，然后选取那个成本更低的连接顺序以及该连接顺序下各个表的最优访问方法作为最终的查询计划。我们分别来看一下（定性的分析一下，不像分析单表查询那样定量的分析了）： 使用s1作为驱动表的情况 分析对于驱动表的成本最低的执行方案首先看一下涉及s1表单表的搜索条件有哪些： s1.key2 &gt; 10 AND s1.key2 &lt; 1000 所以这个查询可能使用到idx_key2索引，从全表扫描和使用idx_key2这两个方案中选出成本最低的那个，很显然使用idx_key2执行查询的成本更低些。 然后分析对于被驱动表的成本最低的执行方案此时涉及被驱动表s2的搜索条件就是： s2.common_field = 常数（这是因为对驱动表s1结果集中的每一条记录，都需要进行一次被驱动表s2的访问，此时那些涉及两表的条件现在相当于只涉及被驱动表s2了。） s2.key2 &gt; 1000 AND s2.key2 &lt; 2000 很显然，第一个条件由于common_field没有用到索引，此时访问s2表时可用的方案也是全表扫描和使用idx_key2两种，假设使用idx_key2的成本更小。所以此时使用s1作为驱动表时的总成本就是（暂时不考虑使用join buffer对成本的影响）： 1使用idx_key2访问s1的成本 + s1的扇出 × 使用idx_key2访问s2的成本 使用s2作为驱动表的情况 分析对于驱动表的成本最低的执行方案首先看一下涉及s2表单表的搜索条件有哪些： s2.key2 &gt; 1000 AND s2.key2 &lt; 2000 所以这个查询可能使用到idx_key2索引，从全表扫描和使用idx_key2这两个方案中选出成本最低的那个，假设使用idx_key2执行查询的成本更低些。 然后分析对于被驱动表的成本最低的执行方案此时涉及被驱动表s1的搜索条件就是： s1.key1 = 常数 s1.key2 &gt; 10 AND s1.key2 &lt; 2000 这时就很有趣了，使用idx_key1可以进行ref方式的访问，使用idx_key2可以使用range方式的访问。这时优化器需要从全表扫描、使用idx_key1、使用idx_key2这几个方案里选出一个成本最低的方案。这里有个问题，因为idx_key2的范围区间是确定的：(10, 1000)，怎么计算使用idx_key2的成本我们上边已经说过了，可是在没有真正执行查询前，s1.key1 = 常数中的常数值我们并不知道，怎么衡量使用idx_key1执行查询的成本呢？其实很简单，直接使用索引统计数据就好了（就是索引列平均一个值重复多少次）。一般情况下，ref的访问方式要比range成本更低，这里假设使用idx_key1进行对s1的访问。所以此时使用s2作为驱动表时的总成本就是： 1使用idx_key2访问s2的成本 + s2的扇出 × 使用idx_key1访问s1的成本 最后优化器会比较这两种方式的最优访问成本，选取那个成本更低的连接顺序去真正的执行查询。从上边的计算过程也可以看出来，连接查询成本占大头的其实是驱动表扇出数 x 单次访问被驱动表的成本，所以我们的优化重点其实是下边这两个部分： 尽量减少驱动表的扇出 对被驱动表的访问成本尽量低这一点对于我们实际书写连接查询语句时十分有用，我们需要尽量在被驱动表的连接列上建立索引，这样就可以使用ref访问方法来降低访问被驱动表的成本了。如果可以，被驱动表的连接列最好是该表的主键或者唯一二级索引列，这样就可以把访问被驱动表的成本降到更低了。 3.3 多表连接的成本分析首先要考虑一下多表连接时可能产生出多少种连接顺序： 对于两表连接，比如表A和表B连接只有 AB、BA这两种连接顺序。其实相当于2 × 1 = 2种连接顺序。 对于三表连接，比如表A、表B、表C进行连接有ABC、ACB、BAC、BCA、CAB、CBA这么6种连接顺序。其实相当于3 × 2 × 1 = 6种连接顺序。 对于四表连接的话，则会有4 × 3 × 2 × 1 = 24种连接顺序。 对于n表连接的话，则有 n × (n-1) × (n-2) × ··· × 1种连接顺序，就是n的阶乘种连接顺序，也就是n!。 有n个表进行连接，MySQL查询优化器要每一种连接顺序的成本都计算一遍，不过MySQL想了很多办法减少计算非常多种连接顺序的成本的方法： 提前结束某种顺序的成本评估MySQL在计算各种链接顺序的成本之前，会维护一个全局的变量，这个变量表示当前最小的连接查询成本。如果在分析某个连接顺序的成本时，该成本已经超过当前最小的连接查询成本，那就不对该连接顺序继续往下分析了。比方说A、B、C三个表进行连接，已经得到连接顺序ABC是当前的最小连接成本，比方说10.0，在计算连接顺序BCA时，发现B和C的连接成本就已经大于10.0时，就不再继续往后分析BCA这个连接顺序的成本了。 系统变量optimizer_search_depth为了防止无穷无尽的分析各种连接顺序的成本，MySQL提出了optimizer_search_depth系统变量，如果连接表的个数小于该值，那么就继续穷举分析每一种连接顺序的成本，否则只对与optimizer_search_depth值相同数量的表进行穷举分析。很显然，该值越大，成本分析的越精确，越容易得到好的执行计划，但是消耗的时间也就越长，否则得到不是很好的执行计划，但可以省掉很多分析连接成本的时间。 根据某些规则压根儿就不考虑某些连接顺序即使是有上边两条规则的限制，但是分析多个表不同连接顺序成本花费的时间还是会很长，所以MySQL干脆提出了一些所谓的启发式规则（就是根据以往经验指定的一些规则），凡是不满足这些规则的连接顺序压根儿就不分析，这样可以极大的减少需要分析的连接顺序的数量，但是也可能造成错失最优的执行计划。他们提供了一个系统变量optimizer_prune_level来控制到底是不是用这些启发式规则。 4. 调节成本常数我们前边已经介绍了两个成本常数： 读取一个页面花费的成本默认是1.0 检测一条记录是否符合搜索条件的成本默认是0.2 其实除了这两个成本常数，MySQL还支持好多，它们被存储到了mysql数据库（这是一个系统数据库）的两个表中： 12345678mysql&gt; SHOW TABLES FROM mysql LIKE &#x27;%cost%&#x27;;+--------------------------+| Tables_in_mysql (%cost%) |+--------------------------+| engine_cost || server_cost |+--------------------------+2 rows in set (0.00 sec) 一条语句的执行其实是分为两层的： server层 存储引擎层 在server层进行连接管理、查询缓存、语法解析、查询优化等操作，在存储引擎层执行具体的数据存取操作。也就是说一条语句在server层中执行的成本是和它操作的表使用的存储引擎是没关系的，所以关于这些操作对应的成本常数就存储在了server_cost表中，而依赖于存储引擎的一些操作对应的成本常数就存储在了engine_cost表中。 4.1mysql.server_cost表server_cost表中在server层进行的一些操作对应的成本常数，具体内容如下： 123456789101112mysql&gt; SELECT * FROM mysql.server_cost;+------------------------------+------------+---------------------+---------+| cost_name | cost_value | last_update | comment |+------------------------------+------------+---------------------+---------+| disk_temptable_create_cost | NULL | 2018-01-20 12:03:21 | NULL || disk_temptable_row_cost | NULL | 2018-01-20 12:03:21 | NULL || key_compare_cost | NULL | 2018-01-20 12:03:21 | NULL || memory_temptable_create_cost | NULL | 2018-01-20 12:03:21 | NULL || memory_temptable_row_cost | NULL | 2018-01-20 12:03:21 | NULL || row_evaluate_cost | NULL | 2018-01-20 12:03:21 | NULL |+------------------------------+------------+---------------------+---------+6 rows in set (0.05 sec) 我们先看一下server_cost各个列都分别是什么意思： cost_name表示成本常数的名称。 cost_value表示成本常数对应的值。如果该列的值为NULL的话，意味着对应的成本常数会采用默认值。 last_update表示最后更新记录的时间。 comment注释。 从server_cost中的内容可以看出来，目前在server层的一些操作对应的成本常数有以下几种： 成本常数名称 默认值 描述 disk_temptable_create_cost 40.0 创建基于磁盘的临时表的成本，如果增大这个值的话会让优化器尽量少的创建基于磁盘的临时表。 disk_temptable_row_cost 1.0 向基于磁盘的临时表写入或读取一条记录的成本，如果增大这个值的话会让优化器尽量少的创建基于磁盘的临时表。 key_compare_cost 0.1 两条记录做比较操作的成本，多用在排序操作上，如果增大这个值的话会提升filesort 的成本，让优化器可能更倾向于使用索引完成排序而不是filesort 。 memory_temptable_create_cost 2.0 创建基于内存的临时表的成本，如果增大这个值的话会让优化器尽量少的创建基于内存的临时表。 memory_temptable_row_cost 0.2 向基于内存的临时表写入或读取一条记录的成本，如果增大这个值的话会让优化器尽量少的创建基于内存的临时表。 row_evaluate_cost 0.2 这个就是我们之前一直使用的检测一条记录是否符合搜索条件的成本，增大这个值可能让优化器更倾向于使用索引而不是直接全表扫描。 MySQL在执行诸如DISTINCT查询、分组查询、Union查询以及某些特殊条件下的排序查询都可能在内部先创建一个临时表，使用这个临时表来辅助完成查询（比如对于DISTINCT查询可以建一个带有UNIQUE索引的临时表，直接把需要去重的记录插入到这个临时表中，插入完成之后的记录就是结果集了）。在数据量大的情况下可能创建基于磁盘的临时表，也就是为该临时表使用MyISAM、InnoDB等存储引擎，在数据量不大时可能创建基于内存的临时表，也就是使用Memory存储引擎。创建临时表和对这个临时表进行写入和读取的操作代价还是很高的。 这些成本常数在server_cost中的初始值都是NULL，意味着优化器会使用它们的默认值来计算某个操作的成本，如果我们想修改某个成本常数的值的话，需要做两个步骤： 对我们感兴趣的成本常数做更新操作比方说我们想把检测一条记录是否符合搜索条件的成本增大到0.4，那么就可以这样写更新语句： 123UPDATE mysql.server_cost SET cost_value = 0.4 WHERE cost_name = &#x27;row_evaluate_cost&#x27;; 让系统重新加载这个表的值。使用下边语句即可： 1FLUSH OPTIMIZER_COSTS; 当然，在你修改完某个成本常数后想把它们再改回默认值的话，可以直接把cost_value的值设置为NULL，再使用FLUSH OPTIMIZER_COSTS语句让系统重新加载它就好了。 4.2mysql.engine_cost表engine_cost表表中在存储引擎层进行的一些操作对应的成本常数，具体内容如下： 12345678mysql&gt; SELECT * FROM mysql.engine_cost;+-------------+-------------+------------------------+------------+---------------------+---------+| engine_name | device_type | cost_name | cost_value | last_update | comment |+-------------+-------------+------------------------+------------+---------------------+---------+| default | 0 | io_block_read_cost | NULL | 2018-01-20 12:03:21 | NULL || default | 0 | memory_block_read_cost | NULL | 2018-01-20 12:03:21 | NULL |+-------------+-------------+------------------------+------------+---------------------+---------+2 rows in set (0.05 sec) 与server_cost相比，engine_cost多了两个列： engine_name列指成本常数适用的存储引擎名称。如果该值为default，意味着对应的成本常数适用于所有的存储引擎。 device_type列指存储引擎使用的设备类型，这主要是为了区分常规的机械硬盘和固态硬盘，不过在MySQL 5.7.21这个版本中并没有对机械硬盘的成本和固态硬盘的成本作区分，所以该值默认是0。 我们从engine_cost表中的内容可以看出来，目前支持的存储引擎成本常数只有两个： 成本常数名称 默认值 描述 io_block_read_cost 1.0 从磁盘上读取一个块对应的成本。请注意我使用的是块 ，而不是页 这个词儿。对于InnoDB 存储引擎来说，一个页 就是一个块，不过对于MyISAM 存储引擎来说，默认是以4096 字节作为一个块的。增大这个值会加重I/O 成本，可能让优化器更倾向于选择使用索引执行查询而不是执行全表扫描。 memory_block_read_cost 1.0 与上一个参数类似，只不过衡量的是从内存中读取一个块对应的成本。 怎么从内存中和从磁盘上读取一个块的默认成本是一样的？这主要是因为在MySQL目前的实现中，并不能准确预测某个查询需要访问的块中有哪些块已经加载到内存中，有哪些块还停留在磁盘上，所以MySQL认为不管这个块有没有加载到内存中，使用的成本都是1.0，不过随着MySQL的发展，等到可以准确预测哪些块在磁盘上，那些块在内存中的那一天，这两个成本常数的默认值可能会改。 与更新server_cost表中的记录一样，我们也可以通过更新engine_cost表中的记录来更改关于存储引擎的成本常数，我们也可以通过为engine_cost表插入新记录的方式来添加只针对某种存储引擎的成本常数： 插入针对某个存储引擎的成本常数比如我们想增大InnoDB存储引擎页面I/O的成本，书写正常的插入语句即可： 123INSERT INTO mysql.engine_cost VALUES (&#x27;InnoDB&#x27;, 0, &#x27;io_block_read_cost&#x27;, 2.0, CURRENT_TIMESTAMP, &#x27;increase Innodb I/O cost&#x27;); 让系统重新加载这个表的值。使用下边语句即可： 1FLUSH OPTIMIZER_COSTS; 5. 总结在MySQL中，一个查询的执行成本是由IO成本和CPU成本组成的。对于InnoDB存储引擎来说，读取一个页面的默认IO成本是1.0，读取以及检测一条记录是否符合搜索条件的成本默认是0.2。 在单表查询中，优化器生成执行计划的步骤如下： 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种执行方案的代价，找出成本最低的那个方案 在优化器生成执行计划过程中，需要依赖一些数据。这些数据可能是使用下面两种方式得到的： index dive：通过直接访问索引对应的B+树来获取数据 索引统计数据：直接依赖对表或者索引的统计数据 为了更准确的计算连接查询的成本，MySQL提出了条件过滤的概念，也就是采用了某些规则来预测驱动表的扇出值。 对于内连接来说，为了生成成本最低的执行计划，需要考虑两方面的事情： 选择最优的表连接顺序 为驱动表和被驱动表选择成本最低的访问方法 我们可以通过手动修改MySQL数据库下engine_cost &amp; server_cost表中的某些成本常数，更精确的控制在生成执行计划时的成本计算过程。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[六]单表查询&连接查询原理","slug":"MySQL/MySQL[六]单表查询&连接查询原理","date":"2022-01-11T03:15:54.543Z","updated":"2022-01-11T03:21:05.026Z","comments":true,"path":"2022/01/11/MySQL/MySQL[六]单表查询&连接查询原理/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E5%85%AD]%E5%8D%95%E8%A1%A8%E6%9F%A5%E8%AF%A2&%E8%BF%9E%E6%8E%A5%E6%9F%A5%E8%AF%A2%E5%8E%9F%E7%90%86/","excerpt":"","text":"一，单表查询不会走之前不要跑，在学SQL优化之前，我们先来分析下SQL是怎么执行的。 前面说过，MySQL Server有一个称为查询优化器的模块，一条查询语句进行语法解析之后就会被交给查询优化器来进行优化，优化的结果就是生成一个所谓的执行计划，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是啥样的，最后会按照执行计划中的步骤调用存储引擎提供的方法来真正的执行查询，并将查询结果返回给用户。 如果觉得我这篇博客讲的看不懂，回头看看我前面的几篇，MySQL是一个很复杂的东西，尽量不要跳着学，要静下心系统的来学习，之前我都是四处看帖子看博客，一直觉得自己MySQL迷迷糊糊，甚至成了痛点，所以决心写个MySQL专栏，系统的学习下。 我们前面创建过一张表，现在拿来复用下。 123456789101112131415CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3)) Engine=InnoDB CHARSET=utf8; 我们为这个single_table表建立了1个聚簇索引和4个二级索引，分别是： 为id列建立的聚簇索引。 为key1列建立的idx_key1二级索引。 为key2列建立的idx_key2二级索引，而且该索引是唯一二级索引。 为key3列建立的idx_key3二级索引。 为key_part1、key_part2、key_part3列建立的idx_key_part二级索引，这也是一个联合索引。 这张表我插入了一百万数据，用来做实验。 1.访问方法对于单个表的查询来说，MySQL把查询的执行方式大致分为下边两种： 使用全表扫描进行查询这种执行方式很好理解，就是把表的每一行记录都扫一遍嘛，把符合搜索条件的记录加入到结果集就完了。不管是啥查询都可以使用这种方式执行，当然，这种也是最笨的执行方式。 使用索引进行查询因为直接使用全表扫描的方式执行查询要遍历好多记录，所以代价可能太大了。如果查询语句中的搜索条件可以使用到某个索引，那直接使用索引来执行查询可能会加快查询执行的时间。使用索引来执行查询的方式五花八门，又可以细分为许多种类： 针对主键或唯一二级索引的等值查询 针对普通二级索引的等值查询 针对索引列的范围查询 直接扫描整个索引 MySQL把MySQL执行查询语句的方式称之为访问方法或者访问类型。同一个查询语句可能可以使用多种不同的访问方法来执行，虽然最后的查询结果都是一样的，但是执行的时间可能相差很多。 2.const1SELECT * FROM single_table WHERE id = 1438; MySQL会直接利用主键值在聚簇索引中定位对应的用户记录。 **B+**树叶子节点中的记录是按照索引列排序的，对于的聚簇索引来说，它对应的**B+**树叶子节点中的记录就是按照**id**列排序的。所以这样根据主键值定位一条记录的速度贼快。类似的，我们根据唯一二级索引列来定位一条记录的速度也是贼快的，比如下边这个查询： 1SELECT * FROM single_table WHERE key2 = 3841; 这个查询的执行过程的示意图就是这样： 这个查询的执行分两步： 先从idx_key2对应的B+树索引中根据key2列与常数的等值比较条件定位到一条二级索引记录 再根据该记录的id值到聚簇索引中获取到完整的用户记录 MySQL认为通过主键或者唯一二级索引列与常数的等值比较来定位一条记录非常快，所以他们把这种通过主键或者唯一二级索引列来定位一条记录的访问方法定义为：const，意思是常数级别的，代价是可以忽略不计的。不过这种const访问方法只能在主键列或者唯一二级索引列和一个常数进行等值比较时才有效，如果主键或者唯一二级索引是由多个列构成的话，索引中的每一个列都需要与常数进行等值比较，这个const访问方法才有效（这是因为只有该索引中全部列都采用等值比较才可以定位唯一的一条记录）。 对于唯一二级索引来说，查询该列为NULL值的情况比较特殊，比如这样： 1SELECT * FROM single_table WHERE key2 IS NULL; 因为唯一二级索引列并不限制 NULL 值的数量，所以上述语句可能访问到多条记录，也就是说 上边这个语句不可以使用const访问方法来执行。 3.ref有时候我们对某个普通的二级索引列与常数进行等值比较，比如这样： 1SELECT * FROM single_table WHERE key1 = &#x27;abc&#x27;; 对于这个查询，我们当然可以选择全表扫描来逐一对比搜索条件是否满足要求，我们也可以先使用二级索引找到对应记录的id值，然后再回表到聚簇索引中查找完整的用户记录。由于普通二级索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，也就是说使用二级索引来执行查询的代价取决于等值匹配到的二级索引记录条数。如果匹配的记录较少，则回表的代价还是比较低的，所以MySQL可能选择使用索引而不是全表扫描的方式来执行查询。MySQL把这种搜索条件为二级索引列与常数等值比较，采用二级索引来执行查询的访问方法称为：ref。我们看一下采用ref访问方法执行查询的图示： 对于普通的二级索引来说，通过索引列进行等值比较后可能匹配到多条连续的记录，而不是像主键或者唯一二级索引那样最多只能匹配1条记录，所以这种ref访问方法比const差了那么一点，但是在二级索引等值比较时匹配的记录数较少时的效率还是很高的（如果匹配的二级索引记录太多那么回表的成本就太大了）。 有两种特殊情况： 二级索引列值为NULL的情况不论是普通的二级索引，还是唯一二级索引，它们的索引列对包含NULL值的数量并不限制，所以我们采用key IS NULL这种形式的搜索条件最多只能使用ref的访问方法，而不是const的访问方法。 对于某个包含多个索引列的二级索引来说，只要是最左边的连续索引列是与常数的等值比较就可能采用ref的访问方法，比方说下边这几个查询： 12345SELECT * FROM single_table WHERE key_part1 = &#x27;god like&#x27;;SELECT * FROM single_table WHERE key_part1 = &#x27;god like&#x27; AND key_part2 = &#x27;legendary&#x27;;SELECT * FROM single_table WHERE key_part1 = &#x27;god like&#x27; AND key_part2 = &#x27;legendary&#x27; AND key_part3 = &#x27;penta kill&#x27;; 但是如果最左边的连续索引列并不全部是等值比较的话，它的访问方法就不能称为ref了，比方说这样： 1SELECT * FROM single_table WHERE key_part1 = &#x27;god like&#x27; AND key_part2 &gt; &#x27;legendary&#x27;; 4.ref_or_null有时候我们不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为NULL的记录也找出来，就像下边这个查询： 1SELECT * FROM single_table WHERE key1 = &#x27;abc&#x27; OR key1 IS NULL; 当使用二级索引而不是全表扫描的方式执行该查询时，这种类型的查询使用的访问方法就称为ref_or_null，这个ref_or_null访问方法的执行过程如下： 上边的查询相当于先分别从idx_key1索引对应的B+树中找出key1 IS NULL和key1 = &#39;abc&#39;的两个连续的记录范围，然后根据这些二级索引记录中的id值再回表查找完整的用户记录。 5.range1SELECT * FROM single_table WHERE key2 IN (1438, 6328) OR (key2 &gt;= 38 AND key2 &lt;= 79); 如果采用二级索引 + 回表的方式来执行的话，那么此时的搜索条件就不只是要求索引列与常数的等值匹配了，而是索引列需要匹配某个或某些范围的值，在本查询中key2列的值只要匹配下列3个范围中的任何一个就算是匹配成功了： key2的值是1438 key2的值是6328 key2的值在38和79之间。 MySQL把这种利用索引进行范围匹配的访问方法称之为：range。 此处所说的使用索引进行范围匹配中的 索引 可以是聚簇索引，也可以是二级索引。 我们可以把那种索引列等值匹配的情况称之为单点区间，上边所说的范围1和范围2都可以被称为单点区间，像范围3这种的我们可以称为连续范围区间。 6.index1SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = &#x27;abc&#x27;; 由于key_part2并不是联合索引idx_key_part最左索引列，所以我们无法使用ref或者range访问方法来执行这个语句。但是这个查询符合下边这两个条件： 它的查询列表只有3个列：key_part1, key_part2, key_part3，而索引idx_key_part又包含这三个列。 搜索条件中只有key_part2列。这个列也包含在索引idx_key_part中。 也就是说我们可以直接通过遍历idx_key_part索引的叶子节点的记录来比较key_part2 = &#39;abc&#39;这个条件是否成立，把匹配成功的二级索引记录的key_part1, key_part2, key_part3列的值直接加到结果集中就行了。由于二级索引记录比聚簇索记录小的多（聚簇索引记录要存储所有用户定义的列以及所谓的隐藏列，而二级索引记录只需要存放索引列和主键），而且这个过程也不用进行回表操作，所以直接遍历二级索引比直接遍历聚簇索引的成本要小很多，MySQL就把这种采用遍历二级索引记录的执行方式称之为：index。 7.all全表扫描 8.注意8.1 二级索引 + 回表一般情况下只能利用单个二级索引执行查询，比方说下边的这个查询： 1SELECT * FROM single_table WHERE key1 = &#x27;abc&#x27; AND key2 &gt; 1000; 查询优化器会识别到这个查询中的两个搜索条件： key1 = &#39;abc&#39; key2 &gt; 1000 优化器一般会根据single_table表的统计数据来判断到底使用哪个条件到对应的二级索引中查询扫描的行数会更少，选择那个扫描行数较少的条件到对应的二级索引中查询。然后将从该二级索引中查询到的结果经过回表得到完整的用户记录后再根据其余的WHERE条件过滤记录。一般来说，等值查找比范围查找需要扫描的行数更少（也就是ref的访问方法一般比range好，但这也不总是一定的，也可能采用ref访问方法的那个索引列的值为特定值的行数特别多），所以这里假设优化器决定使用idx_key1索引进行查询，那么整个查询过程可以分为两个步骤： 使用二级索引定位记录的阶段，也就是根据条件key1 = &#39;abc&#39;从idx_key1索引代表的B+树中找到对应的二级索引记录。 回表阶段，也就是根据上一步骤中找到的记录的主键值进行回表操作，也就是到聚簇索引中找到对应的完整的用户记录，再根据条件key2 &gt; 1000到完整的用户记录继续过滤。将最终符合过滤条件的记录返回给用户。 注意，因为二级索引的节点中的记录只包含索引列和主键，所以在步骤1中使用idx_key1索引进行查询时只会用到与key1列有关的搜索条件，其余条件，比如key2 &gt; 1000这个条件在步骤1中是用不到的，只有在步骤2完成回表操作后才能继续针对完整的用户记录中继续过滤。 一般情况下执行一个查询只会用到单个二级索引，不过还是有特殊情况的。 从上文可以看出，每次从二级索引中读取到一条记录后，就会根据该记录的主键值执行回表操作。而在某个扫描区间中的二级索引记录的主键值是无序的，也就是说这些二级索引记录对应的聚簇索引记录所在的页面的页号是无序的。每次执行回表操作时都相当于要随机读取一个聚簇索引页面，而这些随机I/O带来的性能开销比较大。于是MySQL提出了一个名为Disk-S weep Multi-Range Read(MRR，多范围读取)的优化措施，即先读取一部分二级索引记录，将它们的主键值排好序之后再统一执行回表操作。相对于每读取一条二级索引记录 就立即执行回表操作，这样会节省一些I/0开销。当然使用这个MRR优化措施的条件比较苛刻，我们之前的讨论中没有涉及MRR 之后的讨论中也将忽略这项优化措施，直接认为每读取一条二级索引记录就立即执行回表操作。 8.2 range访问方法使用的范围区间其实对于B+树索引来说，只要索引列和常数使用=、&lt;=&gt;、IN、NOT IN、IS NULL、IS NOT NULL、&gt;、&lt;、&gt;=、&lt;=、BETWEEN、!=（不等于也可以写成&lt;&gt;）或者LIKE操作符连接起来，就可以产生一个所谓的区间。 LIKE操作符比较特殊，只有在匹配完整字符串或者匹配字符串前缀时才可以利用索引。 IN操作符的效果和若干个等值匹配操作符=之间用OR连接起来是一样的，也就是说会产生多个单点区间，比如下边这两个语句的效果是一样的： 123SELECT * FROM single_table WHERE key2 IN (1438, 6328); SELECT * FROM single_table WHERE key2 = 1438 OR key2 = 6328; 在日常的工作中，一个查询的WHERE子句可能有很多个小的搜索条件，这些搜索条件需要使用AND或者OR操作符连接起来。当我们想使用range访问方法来执行一个查询语句时，重点就是找出该查询可用的索引以及这些索引对应的范围区间。 9.索引合并MySQL在一般情况下执行一个查询时最多只会用到单个二级索引，但是还有特殊情况，在这些特殊情况下也可能在一个查询中使用到多个二级索引，MySQL把这种使用到多个索引来完成一次查询的执行方法称之为：index merge，具体的索引合并算法有下边三种。 9.1 Intersection合并Intersection翻译过来的意思是交集。这里是说某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集，比方说下边这个查询： 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;; 假设这个查询使用Intersection合并的方式执行的话，那这个过程就是这样的： 从idx_key1二级索引对应的B+树中取出key1 = &#39;a&#39;的相关记录。 从idx_key3二级索引对应的B+树中取出key3 = &#39;b&#39;的相关记录。 二级索引的记录都是由索引列 + 主键构成的，所以我们可以计算出这两个结果集中id值的交集。 按照上一步生成的id值列表进行回表操作，也就是从聚簇索引中把指定id值的完整用户记录取出来，返回给用户。 为啥不直接使用idx_key1或者idx_key3只根据某个搜索条件去读取一个二级索引，然后回表后再过滤另外一个搜索条件呢？这里要分析一下两种查询执行方式之间需要的成本代价。 只读取一个二级索引的成本： 按照某个搜索条件读取一个二级索引 根据从该二级索引得到的主键值进行回表操作，然后再过滤其他的搜索条件 读取多个二级索引之后取交集成本： 按照不同的搜索条件分别读取不同的二级索引 将从多个二级索引得到的主键值取交集，然后进行回表操作 虽然读取多个二级索引比读取一个二级索引消耗性能，但是读取二级索引的操作是顺序I/O，而回表操作是随机I/O，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数非常少，当节省的因为回表而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读取一个二级索引的成本更低。 MySQL在某些特定的情况下才可能会使用到Intersection索引合并： 情况一：二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况。比方说下边这个查询可能用到idx_key1和idx_key_part这两个二级索引进行Intersection索引合并的操作： 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27;; 而下边这两个查询就不能进行Intersection索引合并： 123SELECT * FROM single_table WHERE key1 &gt; &#x27;a&#x27; AND key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27;;SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND key_part1 = &#x27;a&#x27;; 第一个查询是因为对key1进行了范围匹配，第二个查询是因为联合索引idx_key_part中的key_part2和key_part3列并没有出现在搜索条件中，所以这两个查询不能进行Intersection索引合并。 情况二：主键列可以是范围匹配比方说下边这个查询可能用到主键和idx_key1进行Intersection索引合并的操作： 1SELECT * FROM single_table WHERE id &gt; 100 AND key1 = &#x27;a&#x27;; 对于InnoDB的二级索引来说，记录先是按照索引列进行排序，如果该二级索引是一个联合索引，那么会按照联合索引中的各个列依次排序。而二级索引的用户记录是由索引列 + 主键构成的，二级索引列的值相同的记录可能会有好多条，这些索引列的值相同的记录又是按照主键的值进行排序的。所以在二级索引列都是等值匹配的情况下才可能使用Intersection索引合并，是因为只有在这种情况下根据二级索引查询出的结果集是按照主键值排序的。 根据二级索引查询出的结果集是按照主键值排序的对使用**Intersection**索引合并的好处？Intersection索引合并会把从多个二级索引中查询出的主键值求交集，如果从各个二级索引中查询的到的结果集本身就是已经按照主键排好序的，那么求交集的过程就很简单。假设某个查询使用Intersection索引合并的方式从idx_key1和idx_key2这两个二级索引中获取到的主键值分别是： 从idx_key1中获取到已经排好序的主键值：1、3、5 从idx_key2中获取到已经排好序的主键值：2、3、4 那么求交集的过程就是这样：逐个取出这两个结果集中最小的主键值，如果两个值相等，则加入最后的交集结果中，否则丢弃当前较小的主键值，再取该丢弃的主键值所在结果集的后一个主键值来比较，直到某个结果集中的主键值用完了： 先取出这两个结果集中较小的主键值做比较，因为1 &lt; 2，所以把idx_key1的结果集的主键值1丢弃，取出后边的3来比较。 因为3 &gt; 2，所以把idx_key2的结果集的主键值2丢弃，取出后边的3来比较。 因为3 = 3，所以把3加入到最后的交集结果中，继续两个结果集后边的主键值来比较。 后边的主键值也不相等，所以最后的交集结果中只包含主键值3。 这个过程其实很快，时间复杂度是O(n)，但是如果从各个二级索引中查询出的结果集并不是按照主键排序的话，那就要先把结果集中的主键值排序完再来做上边的那个过程，就比较耗时了。 按照有序的主键值去回表取记录有个专有名词儿，叫：Rowid Ordered Retrieval，简称ROR。 另外，不仅是多个二级索引之间可以采用Intersection索引合并，索引合并也可以有聚簇索引参加，也就是我们上边写的情况二：在搜索条件中有主键的范围匹配的情况下也可以使用Intersection索引合并索引合并。 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND id &gt; 100; 假设这个查询可以采用Intersection索引合并，我们理所当然的以为这个查询会分别按照id &gt; 100这个条件从聚簇索引中获取一些记录，在通过key1 = &#39;a&#39;这个条件从idx_key1二级索引中获取一些记录，然后再求交集，其实这样就把问题复杂化了，没必要从聚簇索引中获取一次记录。二级索引的记录中都带有主键值的，所以可以在从idx_key1中获取到的主键值上直接运用条件id &gt; 100过滤就行了。所以涉及主键的搜索条件只不过是为了从别的二级索引得到的结果集中过滤记录罢了，是不是等值匹配不重要。 当然，上边说的情况一和情况二只是发生Intersection索引合并的必要条件，不是充分条件。也就是说即使情况一、情况二成立，也不一定发生Intersection索引合并，这得看优化器的心情。优化器只有在单独根据搜索条件从某个二级索引中获取的记录数太多，导致回表开销太大，而通过Intersection索引合并后需要回表的记录数大大减少时才会使用Intersection索引合并。 9.2 Union合并有时候OR关系的不同搜索条件会使用到不同的索引。 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR key3 = &#x27;b&#x27; Intersection是交集的意思，这适用于使用不同索引的搜索条件之间使用AND连接起来的情况；Union是并集的意思，适用于使用不同索引的搜索条件之间使用OR连接起来的情况。与Intersection索引合并类似，MySQL在某些特定的情况下才可能会使用到Union索引合并： 情况一：二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只出现匹配部分列的情况。比方说下边这个查询可能用到idx_key1和idx_key_part这两个二级索引进行Union索引合并的操作： 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR ( key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27;); 而下边这两个查询就不能进行Union索引合并： 123SELECT * FROM single_table WHERE key1 &gt; &#x27;a&#x27; OR (key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27;);SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR key_part1 = &#x27;a&#x27;; 第一个查询是因为对key1进行了范围匹配，第二个查询是因为联合索引idx_key_part中的key_part2和key_part3列并没有出现在搜索条件中，所以这两个查询不能进行Union索引合并。 情况二：主键列可以是范围匹配 情况三：使用Intersection索引合并的搜索条件 这种情况其实就是搜索条件的某些部分使用Intersection索引合并的方式得到的主键集合和其他方式得到的主键集合取交集，比方说这个查询： 1SELECT * FROM single_table WHERE key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27; OR (key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;); 优化器可能采用这样的方式来执行这个查询： 先按照搜索条件key1 = &#39;a&#39; AND key3 = &#39;b&#39;从索引idx_key1和idx_key3中使用Intersection索引合并的方式得到一个主键集合。 再按照搜索条件key_part1 = &#39;a&#39; AND key_part2 = &#39;b&#39; AND key_part3 = &#39;c&#39;从联合索引idx_key_part中得到另一个主键集合。 采用Union索引合并的方式把上述两个主键集合取并集，然后进行回表操作，将结果返回给用户。 当然，查询条件符合了这些情况也不一定就会采用Union索引合并，也得看优化器的心情。优化器只有在单独根据搜索条件从某个二级索引中获取的记录数比较少，通过Union索引合并后进行访问的代价比全表扫描更小时才会使用Union索引合并。 9.3 Sort-Union合并Union索引合并的使用条件太苛刻，必须保证各个二级索引列在进行等值匹配的条件下才可能被用到，比方说下边这个查询就无法使用到Union索引合并： 1SELECT * FROM single_table WHERE key1 &lt; &#x27;a&#x27; OR key3 &gt; &#x27;z&#x27; 这是因为根据key1 &lt; &#39;a&#39;从idx_key1索引中获取的二级索引记录的主键值不是排好序的，根据key3 &gt; &#39;z&#39;从idx_key3索引中获取的二级索引记录的主键值也不是排好序的，但是key1 &lt; &#39;a&#39;和key3 &gt; &#39;z&#39;这两个条件又特别让我们动心，所以我们可以这样： 先根据key1 &lt; &#39;a&#39;条件从idx_key1二级索引中获取记录，并按照记录的主键值进行排序 再根据key3 &gt; &#39;z&#39;条件从idx_key3二级索引中获取记录，并按照记录的主键值进行排序 因为上述的两个二级索引主键值都是排好序的，剩下的操作和Union索引合并方式就一样了。 我们把上述这种先按照二级索引记录的主键值进行排序，之后按照Union索引合并方式执行的方式称之为Sort-Union索引合并，很显然，这种Sort-Union索引合并比单纯的Union索引合并多了一步对二级索引记录的主键值排序的过程。 为啥有Sort-Union索引合并，就没有Sort-Intersection索引合并么？是的，的确没有Sort-Intersection索引合并这么一说， Sort-Union的适用场景是单独根据搜索条件从某个二级索引中获取的记录数比较少，这样即使对这些二级索引记录按照主键值进行排序的成本也不会太高 而Intersection索引合并的适用场景是单独根据搜索条件从某个二级索引中获取的记录数太多，导致回表开销太大，合并后可以明显降低回表开销，但是如果加入Sort-Intersection后，就需要为大量的二级索引记录按照主键值进行排序，这个成本可能比回表查询都高了，所以也就没有引入Sort-Intersection。 9.4 索引合并注意事项联合索引替代Intersection索引合并1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;; 这个查询之所以可能使用Intersection索引合并的方式执行，还不是因为idx_key1和idx_key3是两个单独的B+树索引，要是把这两个列搞一个联合索引，那直接使用这个联合索引就可以了： 1ALTER TABLE single_table drop index idx_key1, idx_key3, add index idx_key1_key3(key1, key3); 这样我们把没用的idx_key1、idx_key3都干掉，再添加一个联合索引idx_key1_key3，使用这个联合索引进行查询效果更好，既不用多读一棵B+树，也不用合并结果。 不过如果有单独对key3列进行查询的业务场景，这样子不得不再把key3列的单独索引给加上。具体还得以业务为准。 二，连接查询原理1. 连接简介1.1 连接的本质我们先建立两个简单的表并给它们填充一点数据： 1234567CREATE TABLE t1 (m1 int, n1 char(1));CREATE TABLE t2 (m2 int, n2 char(1));INSERT INTO t1 VALUES(1, &#x27;a&#x27;), (2, &#x27;b&#x27;), (3, &#x27;c&#x27;);INSERT INTO t2 VALUES(2, &#x27;b&#x27;), (3, &#x27;c&#x27;), (4, &#x27;d&#x27;); 我们成功建立了t1、t2两个表，这两个表都有两个列，一个是INT类型的，一个是CHAR(1)类型的。 12345678910111213141516171819mysql&gt; SELECT * FROM t1;+------+------+| m1 | n1 |+------+------+| 1 | a || 2 | b || 3 | c |+------+------+3 rows in set (0.00 sec)mysql&gt; SELECT * FROM t2;+------+------+| m2 | n2 |+------+------+| 2 | b || 3 | c || 4 | d |+------+------+3 rows in set (0.00 sec) 连接的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户。所以我们把t1和t2两个表连接起来的过程如下图所示： 这个过程看起来就是把t1表的记录和t2的记录连起来组成新的更大的记录，所以这个查询过程称之为连接查询。连接查询的结果集中包含一个表中的每一条记录与另一个表中的每一条记录相互匹配的组合，像这样的结果集就可以称之为笛卡尔积。因为表t1中有3条记录，表t2中也有3条记录，所以这两个表连接之后的笛卡尔积就有3×3=9行记录。在MySQL中，连接查询的语法很简单，只要在FROM语句后边跟多个表名就好了，比如我们把t1表和t2表连接起来的查询语句可以写成这样： 1SELECT * FROM t1, t2; 1.2 连接过程简介在连接查询中的过滤条件可以分成两种： 涉及单表的条件这种只涉及单表的过滤条件我们之前都提到过一万遍了，我们之前也一直称为搜索条件，比如t1.m1 &gt; 1是只针对t1表的过滤条件，t2.n2 &lt; &#39;d&#39;是只针对t2表的过滤条件。 涉及两表的条件这种过滤条件我们之前没见过，比如t1.m1 = t2.m2、t1.n1 &gt; t2.n2等，这些条件中涉及到了两个表。 我们看一下携带过滤条件的连接查询的大致执行过程： 1SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; &#x27;d&#x27;; 在这个查询中我们指明了这三个过滤条件： t1.m1 &gt; 1 t1.m1 = t2.m2 t2.n2 &lt; &#39;d&#39; 这个连接查询的大致执行过程如下： 首先确定第一个需要查询的表，这个表称之为驱动表。此处假设使用t1作为驱动表，那么就需要到t1表中找满足t1.m1 &gt; 1的记录，因为表中的数据太少，我们也没在表上建立二级索引，所以此处查询t1表的访问方法就设定为all吧，也就是采用全表扫描的方式执行单表查询，所以查询过程就如下图所示：我们可以看到，t1表中符合t1.m1 &gt; 1的记录有两条。 针对上一步骤中从驱动表产生的结果集中的每一条记录，分别需要到t2表中查找匹配的记录，所谓匹配的记录，指的是符合过滤条件的记录。因为是根据t1表中的记录去找t2表中的记录，所以t2表也可以被称之为被驱动表。上一步骤从驱动表中得到了2条记录，所以需要查询2次t2表。此时涉及两个表的列的过滤条件t1.m1 = t2.m2就派上用场了： 当t1.m1 = 2时，过滤条件t1.m1 = t2.m2就相当于t2.m2 = 2，所以此时t2表相当于有了t2.m2 = 2、t2.n2 &lt; &#39;d&#39;这两个过滤条件，然后到t2表中执行单表查询。 当t1.m1 = 3时，过滤条件t1.m1 = t2.m2就相当于t2.m2 = 3，所以此时t2表相当于有了t2.m2 = 3、t2.n2 &lt; &#39;d&#39;这两个过滤条件，然后到t2表中执行单表查询。 所以整个连接查询的执行过程就如下图所示： 也就是说整个连接查询最后的结果只有两条符合过滤条件的记录： 123456+------+------+------+------+| m1 | n1 | m2 | n2 |+------+------+------+------+| 2 | b | 2 | b || 3 | c | 3 | c |+------+------+------+------+ 这个两表连接查询共需要查询1次t1表，2次t2表。当然这是在特定的过滤条件下的结果，如果我们把t1.m1 &gt; 1这个条件去掉，那么从t1表中查出的记录就有3条，就需要查询3次t2表了。也就是说在两表连接查询中，驱动表只需要访问一次，被驱动表可能被访问多次。 1.3 内连接和外连接我们先创建两个有现实意义的表。 12345678910111213CREATE TABLE student ( number INT NOT NULL AUTO_INCREMENT COMMENT &#x27;学号&#x27;, name VARCHAR(5) COMMENT &#x27;姓名&#x27;, major VARCHAR(30) COMMENT &#x27;专业&#x27;, PRIMARY KEY (number)) Engine=InnoDB CHARSET=utf8 COMMENT &#x27;学生信息表&#x27;;CREATE TABLE score ( number INT COMMENT &#x27;学号&#x27;, subject VARCHAR(30) COMMENT &#x27;科目&#x27;, score TINYINT COMMENT &#x27;成绩&#x27;, PRIMARY KEY (number, subject)) Engine=InnoDB CHARSET=utf8 COMMENT &#x27;学生成绩表&#x27;; 我们新建了一个学生信息表，一个学生成绩表，然后我们向上述两个表中插入一些数据： 1234567891011121314151617181920mysql&gt; SELECT * FROM student;+----------+-----------+--------------------------+| number | name | major |+----------+-----------+--------------------------+| 20180101 | 杜子腾 | 软件学院 || 20180102 | 范统 | 计算机科学与工程 || 20180103 | 史珍香 | 计算机科学与工程 |+----------+-----------+--------------------------+3 rows in set (0.00 sec)mysql&gt; SELECT * FROM score;+----------+-----------------------------+-------+| number | subject | score |+----------+-----------------------------+-------+| 20180101 | 母猪的产后护理 | 78 || 20180101 | 论萨达姆的战争准备 | 88 || 20180102 | 论萨达姆的战争准备 | 98 || 20180102 | 母猪的产后护理 | 100 |+----------+-----------------------------+-------+4 rows in set (0.00 sec) 现在我们想把每个学生的考试成绩都查询出来就需要进行两表连接了（因为score中没有姓名信息，所以不能单纯只查询score表）。连接过程就是从student表中取出记录，在score表中查找number相同的成绩记录，所以过滤条件就是student.number = socre.number，整个查询语句就是这样： 1SELECT * FROM student, score WHERE student.number = score.number; 从上述查询结果中我们可以看到，各个同学对应的各科成绩就都被查出来了，可是有个问题，史珍香同学，也就是学号为20180103的同学因为某些原因没有参加考试，所以在score表中没有对应的成绩记录。那如果老师想查看所有同学的考试成绩，即使是缺考的同学也应该展示出来，但是到目前为止我们介绍的连接查询是无法完成这样的需求的。 这个需求的本质是：驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集。为了解决这个问题，就有了内连接和外连接的概念。 对于内连接的两个表，驱动表中的记录在被驱动表中找不到匹配的记录，该记录不会加入到最后的结果集，我们上边提到的连接都是所谓的内连接。 对于外连接的两个表，驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集。在MySQL中，根据选取驱动表的不同，外连接仍然可以细分为2种： 左外连接：选取左侧的表为驱动表。 右外连接：选取右侧的表为驱动表。 对于外连接来说，有时候我们也并不想把驱动表的全部记录都加入到最后的结果集。把过滤条件分为两种就可以了，所以放在不同地方的过滤条件是有不同语义的： WHERE子句中的过滤条件WHERE子句中的过滤条件就是我们平时见的那种，不论是内连接还是外连接，凡是不符合WHERE子句中的过滤条件的记录都不会被加入最后的结果集。 ON子句中的过滤条件对于外连接的驱动表的记录来说，如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用NULL值填充。 需要注意的是，这个ON子句是专门为外连接驱动表中的记录在被驱动表找不到匹配记录时应不应该把该记录加入结果集这个场景下提出的，所以如果把ON子句放到内连接中，MySQL会把它和WHERE子句一样对待，也就是说：内连接中的WHERE子句和ON子句是等价的。 一般情况下，我们都把只涉及单表的过滤条件放到WHERE子句中，把涉及两表的过滤条件都放到ON子句中，我们也一般把放到ON子句中的过滤条件也称之为连接条件。 1.3.1 左（外）连接的语法比如我们要把t1表和t2表进行左外连接查询可以这么写： 1SELECT * FROM t1 LEFT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件]; 其中中括号里的OUTER单词是可以省略的。对于LEFT JOIN类型的连接来说，我们把放在左边的表称之为外表或者驱动表，右边的表称之为内表或者被驱动表。所以上述例子中t1就是外表或者驱动表，t2就是内表或者被驱动表。需要注意的是，对于左（外）连接和右（外）连接来说，必须使用ON子句来指出连接条件。 回到我们上边那个现实问题中来，看看怎样写查询语句才能把所有的学生的成绩信息都查询出来，即使是缺考的考生也应该被放到结果集中： 1SELECT s1.number, s1.name, s2.subject, s2.score FROM student AS s1 LEFT JOIN score AS s2 ON s1.number = s2.number; 从结果集中可以看出来，虽然史珍香并没有对应的成绩记录，但是由于采用的是连接类型为左（外）连接，所以仍然把她放到了结果集中，只不过在对应的成绩记录的各列使用NULL值填充而已。 1.3.2 右（外）连接的语法右（外）连接和左（外）连接的原理是一样一样的，语法也只是把LEFT换成RIGHT而已： 1SELECT * FROM t1 RIGHT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件]; 只不过驱动表是右边的表，被驱动表是左边的表。 1.3.3 内连接的语法内连接和外连接的根本区别就是在驱动表中的记录不符合ON子句中的连接条件时不会把该记录加入到最后的结果集。 一种最简单的内连接语法，就是直接把需要连接的多个表都放到FROM子句后边。其实针对内连接，MySQL提供了好多不同的语法，我们以t1和t2表为例： 1SELECT * FROM t1 [INNER | CROSS] JOIN t2 [ON 连接条件] [WHERE 普通过滤条件]; 也就是说在MySQL中，下边这几种内连接的写法都是等价的： SELECT * FROM t1 JOIN t2; SELECT * FROM t1 INNER JOIN t2; SELECT * FROM t1 CROSS JOIN t2; 上边的这些写法和直接把需要连接的表名放到FROM语句之后，用逗号,分隔开的写法是等价的： 1SELECT * FROM t1, t2; 在内连接中ON子句和WHERE子句是等价的，所以内连接中不要求强制写明ON子句。 前边说过，连接的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户。不论哪个表作为驱动表，两表连接产生的笛卡尔积肯定是一样的。而对于内连接来说，由于凡是不符合ON子句或WHERE子句中的条件的记录都会被过滤掉，其实也就相当于从两表连接的笛卡尔积中把不符合过滤条件的记录给踢出去，所以对于内连接来说，驱动表和被驱动表是可以互换的，并不会影响最后的查询结果。但是对于外连接来说，由于驱动表中的记录即使在被驱动表中找不到符合ON子句条件的记录时也要将其加入到结果集，所以此时驱动表和被驱动表的关系就很重要了，也就是说左外连接和右外连接的驱动表和被驱动表不能轻易互换。 2.连接的原理接下来看一下MySQL采用了什么样的算法来进行表与表之间的连接。 2.1 嵌套循环连接对于两表连接来说，驱动表只会被访问一遍，但被驱动表却要被访问到好多遍，具体访问几遍取决于对驱动表执行单表查询后的结果集中的记录条数。对于内连接来说，选取哪个表为驱动表都没关系，而外连接的驱动表是固定的，也就是说左（外）连接的驱动表就是左边的那个表，右（外）连接的驱动表就是右边的那个表。 再来看一下t1表和t2表执行内连接查询的大致过程： 步骤1：选取驱动表，使用与驱动表相关的过滤条件，选取代价最低的单表访问方法来执行对驱动表的单表查询。 步骤2：对上一步骤中查询驱动表得到的结果集中每一条记录，都分别到被驱动表中查找匹配的记录。 通用的两表连接过程如下图所示： 如果有3个表进行连接的话，那么步骤2中得到的结果集就像是新的驱动表，然后第三个表就成为了被驱动表，重复上边过程，也就是步骤2中得到的结果集中的每一条记录都需要到t3表中找一找有没有匹配的记录，用伪代码表示一下这个过程就是这样： 123456789for each row in t1 &#123; #此处表示遍历满足对t1单表查询结果集中的每一条记录 for each row in t2 &#123; #此处表示对于某条t1表的记录来说，遍历满足对t2单表查询结果集中的每一条记录 for each row in t3 &#123; #此处表示对于某条t1和t2表的记录组合来说，对t3表进行单表查询 if row satisfies join conditions, send to client &#125; &#125;&#125; 这个过程就像是一个嵌套的循环，所以这种驱动表只访问一次，但被驱动表却可能被多次访问，访问次数取决于对驱动表执行单表查询后的结果集中的记录条数的连接执行方式称之为嵌套循环连接（Nested-Loop Join），这是最简单，也是最笨拙的一种连接查询算法。 2.2 使用索引加快连接速度在嵌套循环连接的步骤2中可能需要访问多次被驱动表，如果访问被驱动表的方式都是全表扫描的话，要查很多次。但是查询t2表其实就相当于一次单表扫描，我们可以利用索引来加快查询速度。回到最开始的t1表和t2表进行内连接的例子： 1SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; &#x27;d&#x27;; 查询驱动表t1后的结果集中有两条记录，嵌套循环连接算法需要对被驱动表查询2次： 当t1.m1 = 2时，去查询一遍t2表，对t2表的查询语句相当于： 1SELECT * FROM t2 WHERE t2.m2 = 2 AND t2.n2 &lt; &#x27;d&#x27;; 当t1.m1 = 3时，再去查询一遍t2表，此时对t2表的查询语句相当于： 1SELECT * FROM t2 WHERE t2.m2 = 3 AND t2.n2 &lt; &#x27;d&#x27;; 可以看到，原来的t1.m1 = t2.m2这个涉及两个表的过滤条件在针对t2表做查询时关于t1表的条件就已经确定了，所以我们只需要单单优化对t2表的查询了，上述两个对t2表的查询语句中利用到的列是m2和n2列，我们可以： 在m2列上建立索引，因为对m2列的条件是等值查找，比如t2.m2 = 2、t2.m2 = 3等，所以可能使用到ref的访问方法，假设使用ref的访问方法去执行对t2表的查询的话，需要回表之后再判断t2.n2 &lt; d这个条件是否成立。这里有一个比较特殊的情况，就是假设m2列是t2表的主键或者唯一二级索引列，那么使用t2.m2 = 常数值这样的条件从t2表中查找记录的过程的代价就是常数级别的。我们知道在单表中使用主键值或者唯一二级索引列的值进行等值查找的方式称之为const，而MySQL把在连接查询中对被驱动表使用主键值或者唯一二级索引列的值进行等值查找的查询执行方式称之为：eq_ref。 在n2列上建立索引，涉及到的条件是t2.n2 &lt; &#39;d&#39;，可能用到range的访问方法，假设使用range的访问方法对t2表的查询的话，需要回表之后再判断在m2列上的条件是否成立。 假设m2和n2列上都存在索引的话，那么就需要从这两个里边儿挑一个代价更低的去执行对t2表的查询。当然，建立了索引不一定使用索引，只有在二级索引 + 回表的代价比全表扫描的代价更低时才会使用索引。 另外，有时候连接查询的查询列表和过滤条件中可能只涉及被驱动表的部分列，而这些列都是某个索引的一部分，这种情况下即使不能使用eq_ref、ref、ref_or_null或者range这些访问方法执行对被驱动表的查询的话，也可以使用索引扫描，也就是index的访问方法来查询被驱动表。所以我们建议在真实工作中最好不要使用*作为查询列表，最好把真实用到的列作为查询列表。 2.3 基于块的嵌套循环连接扫描一个表的过程其实是先把这个表从磁盘上加载到内存中，然后从内存中比较匹配条件是否满足。现实生活中的表可不像t1、t2这种只有3条记录，成千上万条记录都是少的，几百万、几千万甚至几亿条记录的表到处都是。内存里可能并不能完全存放的下表中所有的记录，所以在扫描表前边记录的时候后边的记录可能还在磁盘上，等扫描到后边记录的时候可能内存不足，所以需要把前边的记录从内存中释放掉。我们前边又说过，采用嵌套循环连接算法的两表连接过程中，被驱动表可是要被访问好多次的，如果这个被驱动表中的数据特别多而且不能使用索引进行访问，那就相当于要从磁盘上读好几次这个表，这个I/O代价就非常大了，所以我们得想办法：尽量减少访问被驱动表的次数。 当被驱动表中的数据非常多时，每次访问被驱动表，被驱动表的记录会被加载到内存中，在内存中的每一条记录只会和驱动表结果集的一条记录做匹配，之后就会被从内存中清除掉。然后再从驱动表结果集中拿出另一条记录，再一次把被驱动表的记录加载到内存中一遍，周而复始，驱动表结果集中有多少条记录，就得把被驱动表从磁盘上加载到内存中多少次。 如果在把被驱动表的记录加载到内存的时候，一次性和多条驱动表中的记录做匹配，这样就可以大大减少重复从磁盘上加载被驱动表的代价。 MySQL提出了一个join buffer的概念，join buffer就是执行连接查询前申请的一块固定大小的内存，先把若干条驱动表结果集中的记录装在这个join buffer中，然后开始扫描被驱动表，每一条被驱动表的记录一次性和join buffer中的多条驱动表记录做匹配，因为匹配的过程都是在内存中完成的，所以这样可以显著减少被驱动表的I/O代价。使用join buffer的过程如下图所示： 最好的情况是join buffer足够大，能容纳驱动表结果集中的所有记录，这样只需要访问一次被驱动表就可以完成连接操作了。MySQL把这种加入了join buffer的嵌套循环连接算法称之为基于块的嵌套连接（Block Nested-Loop Join）算法。 这个join buffer的大小是可以通过启动参数或者系统变量join_buffer_size进行配置，默认大小为262144字节（也就是256KB），最小可以设置为128字节。当然，对于优化被驱动表的查询来说，最好是为被驱动表加上效率高的索引，如果实在不能使用索引，并且自己的机器的内存也比较大可以尝试调大join_buffer_size的值来对连接查询进行优化。 另外需要注意的是，驱动表的记录并不是所有列都会被放到join buffer中，只有查询列表中的列和过滤条件中的列才会被放到join buffer中，所以再次提醒我们，最好不要把*作为查询列表，只需要把我们关心的列放到查询列表就好了，这样还可以在join buffer中放置更多的记录。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[五]InnoDb表空间","slug":"MySQL/MySQL[五]InnoDb表空间","date":"2022-01-11T03:15:42.796Z","updated":"2022-01-11T03:20:19.117Z","comments":true,"path":"2022/01/11/MySQL/MySQL[五]InnoDb表空间/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E4%BA%94]InnoDb%E8%A1%A8%E7%A9%BA%E9%97%B4/","excerpt":"","text":"在前面的两篇文章已经对InnoDB索引的结构，页存储结构，行格式做了十分细致的分析，也详细阐述了为什么你的SQL会慢，索引命中的原理，接下来我要继续深入学习MySQL。在此之前还要先来补充一下MySQL的一些基础知识。 一，MySQL的数据目录1. 数据库和文件系统的关系InnoDB,MyISAM这样的存储引擎都是把表存储在磁盘上，而操作系统是使用文件系统来管理磁盘的。【像InnoDB,MyISAM这样的存储引擎都是把数据存储在文件系统上的。】当我们想读取数据的时候，这些存储引擎会从文件系统中把数据读出来返回给我们，当我们想写入数据的时候，这些存储引擎又会把数据写回到文件系统。 本小节主要就是分析下InnoDB,MyISAM两个存储引擎的数据是如何在文件系统中存储的。 我的MySQL版本是5.7.28，所以接下来的操作和分析都是基于这个小版本的。其他版本可能会有细微的差异。 2.MySQL数据目录MySQL服务器程序在启动时，会到文件系统的某个目录下加载一些数据，之后再运行过程中产生的数据也会存储到这个目录下的某些文件中。这个目录就是数据目录。 2.1 数据目录和安装目录的区别MySQL的安装目录是在安装MySQL的时候指定的安装位置，下面有个很重要的bin目录，里面存储着控制客户端程序与服务器程序的命令。 MySQL的数据目录是用来存储MySQL在运行过程中产生的数据。 2.2 MySQL的数据目录在哪里数据目录对应着一个系统变量datadir，在使用客户端与服务器建立连接以后，查看这个系统变量的值就知道了： 1show variables like &#x27;datadir&#x27;; 结果如下： 1234567mysql&gt; show variables like &#x27;datadir&#x27;;+---------------+--------------------+| Variable_name | Value |+---------------+--------------------+| datadir | C:\\yhd\\mysql\\Data\\ |+---------------+--------------------+1 row in set, 1 warning (0.00 sec) 3.数据目录的结构3.1 数据库在文件系统中的表示每个数据库都对应着数据目录下的一个子目录，或者说对应着一个文件夹。当我们创建一个新的数据库的时候，MySQL会帮助我们做两件事： 在数据目录下创建一个与数据库同名的文件目录 在该子目录下创建一个db.opt文件。这个文件中包含了数据库的一些属性，比如该数据库的字符集和比较规则。 下面来看一下我的MySQL中的数据库： 1234567891011mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || yhd |+--------------------+5 rows in set (0.00 sec) 再从数据目录里看一下： 123456789101112131415161718192021222324252627282930313233C:\\yhd\\mysql\\Data&gt;dir 驱动器 C 中的卷没有标签。 卷的序列号是 CA5F-90F5 C:\\yhd\\mysql\\Data 的目录2021/12/19 00:27 &lt;DIR&gt; .2021/12/19 00:27 &lt;DIR&gt; ..2021/12/14 00:00 56 auto.cnf2021/12/14 00:00 1,703 ca-key.pem2021/12/14 00:00 1,131 ca.pem2021/12/14 00:00 1,131 client-cert.pem2021/12/14 00:00 1,707 client-key.pem2021/12/14 00:12 696 DESKTOP-NJIMTJP-slow.log2021/12/18 01:15 25,345 DESKTOP-NJIMTJP.err2021/12/18 01:15 5 DESKTOP-NJIMTJP.pid2021/12/19 02:18 79,691,776 ibdata12021/12/18 01:15 12,582,912 ibtmp12021/12/18 01:15 356 ib_buffer_pool2021/12/19 02:18 50,331,648 ib_logfile02021/12/19 02:18 50,331,648 ib_logfile12021/12/14 00:00 &lt;DIR&gt; mysql2021/12/14 00:00 &lt;DIR&gt; performance_schema2021/12/14 00:00 1,707 private_key.pem2021/12/14 00:00 461 public_key.pem2021/12/14 00:00 1,131 server-cert.pem2021/12/14 00:00 1,707 server-key.pem2021/12/14 00:00 &lt;DIR&gt; sys2021/12/19 00:56 &lt;DIR&gt; yhd 17 个文件 192,975,120 字节 6 个目录 189,156,126,720 可用字节C:\\yhd\\mysql\\Data&gt; 仔细看会发现，除了information_schema这个数据库以外，其他的数据库都对应一个文件目录，这个数据库有点特殊，后面在具体分析。 3.2 表在文件系统中的表示我们的数据其实是以记录的形式插入到表中的。每个表的信息其实可以分为两种。 表结构信息 表数据信息 为了保存表结构信息，InnoDB,MyISAM这两种存储引擎都会在数据目录下对应的数据库子目录中创建一个专门用于描述表结构的文件，文件名是表名.frm。这个文件是二进制格式的，直接打开会乱码。 我们知道不同的存储引擎对于表中的数据存储是不一样的，接下来我们分别来看一下InnoDB,MyISAM是如何存储表中的数据的。 InnoDb是如何存储数据的我们再来回顾下上一篇的知识： innoDB其实是使用页来作为基本单位管理存储空间的，默认大小16KB。 对于InnoDB存储引擎来说，每个索引都对应一颗B+树，该B+树的每个结点都是一个数据页。数据页之间没有必要是物理连续的，因为数据页之间有双向链表来维护这些页的顺序。 InnoDB的聚簇索引的叶子结点存储了完整的用户记录，也就是所谓的索引即数据，数据即索引。 为了更好的管理这些页，InnoDB提出了表空间或者文件空间的概念。这个表空间是一个抽象的概念，他可以对应文件系统上一个或者多个真实文件（不同表空间对应的文件数量可能不同）。每一个表空间可以被划分为很多个页，表数据被存放在某个表空间下的某些页中。InnoDB将表空间划分几种不同的类型，我们一个个分析一下子。 系统表空间 这个系统表空间可以对应文件系统上一个或者多个实际的文件。在默认情况下，InnoDB会在数据目录下创建一个名为ibdata1，大小为12MB的文件，这个文件就是对应的系统表空间在文件系统上的表示。怎么才12MB？这是因为这个文件是自扩展文件，也就是当不够用的时候会自己增加文件大小。 当然，如果想让系统表空间对应文件系统上的多个实际文件，或者仅仅觉得原来的ibdata1这个文件名难听，那么可以在MySQL服务启动的时候，配置对应的文件路径以及他们的大小。比如像下面这样修改配置文件： 12[server]innodb_data_file_path=data1:512M;data2:512M:autoextend 这样，在MySQL启动之后会创建data1和data2这两个各自512MB大小的文件作为系统表空间。其中的autoextend表明，如果这两个文件不够用，则会自动扩展data2文件的大小。 我们也可以把系统表空间对应的文件路径不配置到数据目录下，甚至可以配置到单独的磁盘分区上，涉及到的启动参数就是innodb_data_file_path和innodb_data_home_dir。 需要注意的一点是，在一个MySQL服务器中，系统表空间只有一份。从MySQL5.5.7到MySQL5.6.6之间的各个版本中，我们表中的数据都会被默认存储到这个 **系统表空间**。 独立表空间 在MySQL5.6.6以及以后的版本中，InnoDB不在默认把各个表的数据存储到系统表空间，而是为每一个表建立一个独立的表空间，也就是说，创建多少张表就会对应多少个表空间。在使用独立表空间来存储表数据的时候，会在该表所属的数据库对应的子目录下创建一个表示该独立表空间的文件，其文件名和表名相同，只不过添加了一个.ibd扩展名。所以完整的文件名称：表名.ibd。 假如我们使用独立表空间来存储yhd数据库下的person_info表，那么在该数据库所对应的yhd文件目录下会为person_info表创建下面两个文件：person_info.frm,person_info.ibd。 其中ibd文件用来存储表中的数据。当然也可以自己指定是使用系统表空间还是独立表空间来存储数据。 其他类型表空间 除了上述两种表空间之外，还有一些不同类型的表空间，比如通用表空间，undo表空间，临时表空间。 MyISAM是如何存储数据的索引和数据在InnoDB是一回事，但是MyISAM中的索引相当于全部都是二级索引，该存储引擎的数据和索引是分开存放的。所以在文件系统中也是使用不同的文件来存储数据文件和索引文件，而且与InnoDB不同的是，MyISAM并没有什么表空间一说，表的数据和索引都存放到对应的数据库子目录下。 假设我们person_info表使用的是MyISAM存储引擎，那么在它所在数据库对应的yhd文件目录下会为person_info创建三个文件：person_info.frm,person_info.MYD,person_info.MYI。 其中person_info.MYD表示表的数据文件，也就是插入的用户记录，person_info.MYI表示表的索引文件，我们为该表创建的索引都会放到这个文件中。 3.3 其他的文件除了我们上边说的这些用户自己存储的数据以外，数据目录下还包括为了更好运行程序的一些额外文件，主要包括这几种类型的文件： 服务器进程文件。我们知道每运行一个MySQL服务器程序，都意味着启动一个进程。MySQL服务器会把自己的进程ID写入到一个文件中。 服务器日志文件。在服务器运行过程中，会产生各种各样的日志，比如常规的查询日志、错误日志、二进制日志、redo日志等各种日志，这些日志各有各的用途，现在先了解一下就可以了。 默认/自动生成的SSL和RSA证书和密钥文件。主要是为了客户端和服务器安全通信而创建的一些文件 4.文件系统对数据库的影响因为MySQL的数据都是存在文件系统中的，就不得不受到文件系统的一些制约，这在数据库和表的命名、表的大小和性能方面体现的比较明显，比如下边这些方面： 数据库名称和表名称不得超过文件系统所允许的最大长度。每个数据库都对应数据目录的一个子目录，数据库名称就是这个子目录的名称；每个表都会在数据库子目录下产生一个和表名同名的.frm文件，如果是InnoDB的独立表空间或者使用MyISAM引擎还会有别的文件的名称与表名一致。这些目录或文件名的长度都受限于文件系统所允许的长度～ 特殊字符的问题为了避免因为数据库名和表名出现某些特殊字符而造成文件系统不支持的情况，MySQL会把数据库名和表名中所有除数字和拉丁字母以外的所有字符在文件名里都映射成 @+编码值的形式作为文件名。比方说我们创建的表的名称为&#39;test?&#39;，由于?不属于数字或者拉丁字母，所以会被映射成编码值，所以这个表对应的.frm文件的名称就变成了test@003f.frm。 文件长度受文件系统最大长度限制对于InnoDB的独立表空间来说，每个表的数据都会被存储到一个与表名同名的.ibd文件中；对于MyISAM存储引擎来说，数据和索引会分别存放到与表同名的.MYD和.MYI文件中。这些文件会随着表中记录的增加而增大，它们的大小受限于文件系统支持的最大文件大小。 5.MySQL系统数据库简介我们前边提到了MySQL的几个系统数据库，这几个数据库包含了MySQL服务器运行过程中所需的一些信息以及一些运行状态信息，我们现在稍微了解一下。 mysql这个数据库贼核心，它存储了MySQL的用户账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等。 information_schema这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引等等。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据。 performance_schema这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，算是对MySQL服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等等信息。 sys这个数据库主要是通过视图的形式把information_schema和performance_schema结合起来，让程序员可以更方便的了解MySQL服务器的一些性能信息。 二，回顾前面数据页（也就是Index类型的页）由7部分组成，其中有两个部分是所有类型的页面都通用的。 所有类型的页都会包含下面两个部分。 File Header：记录页面的一些通用信息 File Trailer: 校验页是否完整，保证页面在从内存刷新到磁盘后内容是相同的 名称 占用空间大小（字节） 描述 FIL_PAGE_SPACE_OR_CHKSUM 4 页的校验和（checksum值） FIL_PAGE_OFFSET 4 页号 FIL_PAGE_PREV 4 上一个页的页号 FIL_PAGE_NEXT 4 下一个页的页号 FIL_PAGE_LSN 8 页面被最后修改时对应的日志序列位置 FIL_PAGE_TYPE 2 该页的类型 FIL_PAGE_FILE_FLUSH_LSN 8 仅仅在系统表空间的一个页中定义，代表文件至少被刷新到了对应的LSN值 FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID 4 页属于哪个表空间 表空间中的每一个页都对应着一个页号，也就是FIL_PAGE_OFFSET，这个页号由4个字节组成，也就是32个比特位，所以一个表空间最多可以拥有2³²个页，如果按照页的默认大小16KB来算，一个表空间最多支持64TB的数据。表空间的第一个页的页号为0，之后的页号分别是1，2，3…依此类推 某些类型的页可以组成链表，链表中的页可以不按照物理顺序存储，而是根据FIL_PAGE_PREV和FIL_PAGE_NEXT来存储上一个页和下一个页的页号。需要注意的是，这两个字段主要是为了INDEX类型的页，也就是我们之前一直说的数据页建立B+树后，为每层节点建立双向链表用的，一般类型的页是不使用这两个字段的。 每个页的类型由FIL_PAGE_TYPE表示，比如像数据页的该字段的值就是0x45BF，不同类型的页在该字段上的值是不同的。 InnoDB支持许多种类型的表空间，我们暂时重点关注系统表空间和独立表空间的结构。他们结构比较相似，但是由于系统表空间中额外包含了一些关于整个系统的信息，所以我们先分析独立表空间，再说系统表空间。 三，独立表空间1.区的概念为了更好的管理表中的页，InnoDB提出了区的概念。对于16KB的页来说，连续的64个页就是一个区。也就是说一个区默认占用1M空间。不论是系统表空间还是独立表空间，都可以看成是由若干区组成的，每256个区划分为一个组。 为什么要有区的概念？ 从理论上来讲，不引入区的概念只使用页的概念对存储引擎的运行并没有任何影响，但是我们来分析下： 我们每向表中插入一条记录，本质上就是向该表的聚簇索引以及所有二级索引代表的B+树的节点中插入数据。而B+树的每一层中的页都会形成一个双向链表，如果是以页为单位来分配存储空间的话，双向链表相邻的两个页之间的物理位置可能离得非常远。 B+树的范围查询只需要定位到最左边的记录和最右边的记录，然后沿着双向链表一直扫描就可以了，而如果链表中相邻的两个页物理位置离得非常远，就是所谓的随机I/O。磁盘的速度和内存的速度差了好几个数量级，随机I/O是非常慢的，所以我们应该尽量让链表中相邻的页的物理位置也相邻，这样进行范围查询的时候才可以使用所谓的顺序I/O。 所以才引入了区（extent）的概念，一个区就是在物理位置上连续的64个页。在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区为单位分配，甚至在表中的数据十分非常特别多的时候，可以一次性分配多个连续的区。虽然可能造成一点点空间的浪费（数据不足填充满整个区），但是从性能角度看，可以消除很多的随机I/O。 2.段的概念范围查询，其实是对B+树叶子节点中的记录进行顺序扫描，而如果不区分叶子节点和非叶子节点，统统把节点代表的页面放到申请到的区中的话，进行范围扫描的效果就大打折扣了。InnoDB对B+树的叶子节点和非叶子节点进行了区别对待：叶子节点有自己独有的区，非叶子节点也有自己独有的区。存放叶子节点的区的集合就算是一个段（segment），存放非叶子节点的区的集合也算是一个段。也就是说一个索引会生成2个段，一个叶子节点段，一个非叶子节点段。 默认情况下一个使用InnoDB存储引擎的表只有一个聚簇索引，一个索引会生成2个段，而段是以区为单位申请存储空间的，一个区默认占用1M存储空间，所以默认情况下一个只存了几条记录的小表也需要2M的存储空间么？以后每次添加一个索引都要多申请2M的存储空间么？ 为了考虑以完整的区为单位分配给某个段对于数据量较小的表太浪费存储空间的这种情况，InnoDB提出了碎片区的概念，也就是在一个碎片区中，并不是所有的页都是为了存储同一个段的数据而存在的，而是碎片区中的页可以用于不同的目的，比如有些页用于段A，有些页用于段B，有些页甚至哪个段都不属于。碎片区直属于表空间，并不属于任何一个段。所以此后为某个段分配存储空间的策略是这样的： 在刚开始向表中插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间的 当某个段已经占用了32个碎片区页面之后，就会以完整的区为单位来分配存储空间 所以现在段不能仅定义为是某些区的集合，更精确的应该是某些零散的页面以及一些完整的区的集合。除了索引的叶子节点段和非叶子节点段之外，InnoDB中还有为存储一些特殊的数据而定义的段，比如回滚段，当然我们现在并不关心别的类型的段，现在只需要知道段是一些零散的页面以及一些完整的区的集合就好了。 有的时候处于不同的阶段，对于某个概念的定义或者理解是不同的，随着知识水平的提升后续再来逐渐完善，就像小学的时候老师会告诉你最小的数是0，中学又告诉你最小的数是负无穷一样。 3.区的分类每个区都对应一个XDES Entry结构，这个结构中存储了一些与这个区有关的属性。这些区可以被分为下面四种类型。 空闲的区：现在还没有用到这个区中的任何页面，这些区会被加入到FREE链表。 有剩余空间的碎片区：表示碎片区中还有可用的页面，这些区会被加入到FREE_FRAG链表。 没有剩余空间的碎片区：表示碎片区中的所有页面都被使用，没有空闲页面；这些区会被加入到FULL_FRAG链表。 附属于某个段的区。每一个索引都可以分为叶子节点段和非叶子节点段，除此之外InnoDB还会另外定义一些特殊作用的段，在这些段中的数据量很大时将使用区来作为基本的分配单位；每个段所属的区又会被组织成下面几种链表。 FREE链表：在同一个段中，所有页面都是空闲页面的区对应的XDES Entry结构会被加入到这个链表。 NOT_FULL链表：在同一个段中，仍有空闲页面的区对应的XDES Entry结构会被加入到这个链表。 FULL链表：在同一个段中，已经没有空闲页面的区对应的XDES Entry结构会被加入到这个链表。 这四种类型的区也被叫做区的四种状态。 状态名 含义 FREE 空闲的区 FREE_FRAG 有剩余空间的碎片区 FULL_FRAG 没有剩余空间的碎片区 FSEG 附属于某个段的区 处于**FREE**、**FREE_FRAG**以及**FULL_FRAG**这三种状态的区都是独立的，算是直属于表空间；而处于**FSEG**状态的区是附属于某个段的。 每个段都会对应一个INODE Entry结构，该结构中存储了一些与这个段有关的属性。 表空间中第一个页面的类型为FSP_HDR，它存储了表空间的一些整体属性以及第一个组内256个区对应的XDES Entry结构。 除了表空间的第一个组以外，其余组的第一个页面的类型为XDES，这种页面的结构和FSP_HDR类型的页面对比，除了少了File Space header（记录表空间整体属性的部分）部分之外，其余部分是一样的。 每个组的第二个页面类型为IBUF_BITMAP，存储了一些关于Change Buffer的信息。 表空间中第一个组的第三个页面的类型是INODE，他是为了存储INODE Entry结构而设计的，这种类型的页面会组织成下面两个链表。 SEG_INODES_FULL链表：在该链表中，INODE类型的页面中已经没有空闲空间来存储额外的INODE Entry结构。 SEG_INODES_FREE链表：在该链表中，INODE类型的页面中还有空闲空间来存储额外的INODE Entry结构。 4. Segment Header一个索引会产生两个段，分别是叶子节点段和非叶子节点段，而每个段都会对应一个INODE Entry结构，那我们怎么知道某个段对应哪个**INODE Entry**结构呢？所以得找个地方记下来这个对应关系。INDEX类型的页时有一个Page Header部分，其中的PAGE_BTR_SEG_LEAF和PAGE_BTR_SEG_TOP都占用10个字节，它们其实对应一个叫Segment Header的结构，该结构图示如下： 各个部分的具体释义如下： 名称 占用字节数 描述 Space ID of the INODE Entry 4 INODE Entry结构所在的表空间ID Page Number of the INODE Entry 4 INODE Entry结构所在的页面页号 Byte Offset of the INODE Ent 2 INODE Entry结构在该页面中的偏移量 PAGE_BTR_SEG_LEAF记录着叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个页面的哪个偏移量，PAGE_BTR_SEG_TOP记录着非叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个页面的哪个偏移量。这样子索引和其对应的段的关系就建立起来了。不过需要注意的一点是，因为一个索引只对应两个段，所以只需要在索引的根页面中记录这两个结构即可。 其实Segment Header的作用就是记录哪个段对应哪个INODE Entry结构的。 5. 真实表空间对应的文件大小一个新建的表对应的.ibd文件只占用了96KB，才6个页的大小。刚开始的时候，表空间占用空间自然很小，因为表里面没有数据。不过，ibd文件是自扩展文件，随着数据的增多文件也在逐渐增大。 四，系统表空间系统表空间的结构和独立表空间基本类似，只不过由于整个MySQL进程只有一个系统表空间，在系统表空间中会额外记录一些有关整个系统信息的页面，所以会比独立表空间多出一些记录这些信息的页面。因为这个系统表空间相当于是表空间之首，所以它的表空间 ID（Space ID）是0。 1.系统表空间的整体结构系统表空间与独立表空间的一个非常明显的不同之处就是在表空间开头有许多记录整个系统属性的页面。 可以看到，系统表空间和独立表空间的前三个页面（页号分别为0、1、2，类型分别是FSP_HDR、IBUF_BITMAP、INODE）的类型是一致的，只是页号为3～7的页面是系统表空间特有的，我们来看一下这些多出来的页面都是干啥使的： 页号 页面类型 英文描述 描述 3 SYS Insert Buffer Header 存储Insert Buffer的头部信息 4 INDEX Insert Buffer Root 存储Insert Buffer的根页面 5 TRX_SYS Transaction System 事务系统的相关信息 6 SYS First Rollback Segment 第一个回滚段的页面 7 SYS Data Dictionary Header 数据字典头部信息 除了这几个记录系统属性的页面之外，系统表空间的extent 1和extent 2这两个区，也就是页号从64~`191这128个页面被称为Doublewrite buffer`，也就是双写缓冲区。不过上述的大部分知识都涉及到了事务和多版本控制的问题，现在我们只分析有关InnoDB数据字典的知识，其余的概念在后边再看。 1.1 InnoDB数据字典每当我们向一个表中插入一条记录的时候，MySQL先要校验一下插入语句对应的表存不存在，插入的列和表中的列是否符合，如果语法没有问题的话，还需要知道该表的聚簇索引和所有二级索引对应的根页面是哪个表空间的哪个页面，然后把记录插入对应索引的B+树中。所以说，MySQL除了保存着我们插入的用户数据之外，还需要保存许多额外的信息，比方说： 某个表属于哪个表空间，表里边有多少列 表对应的每一个列的类型是什么 该表有多少索引，每个索引对应哪几个字段，该索引对应的根页面在哪个表空间的哪个页面 该表有哪些外键，外键对应哪个表的哪些列 某个表空间对应文件系统上文件路径是什么 上述这些数据并不是我们使用INSERT语句插入的用户数据，实际上是为了更好的管理我们这些用户数据而不得已引入的一些额外数据，这些数据也称为元数据。InnoDB存储引擎特意定义了一些列的内部系统表（internal system table）来记录这些这些元数据： 表名 描述 SYS_TABLES 整个InnoDB存储引擎中所有的表的信息 SYS_COLUMNS 整个InnoDB存储引擎中所有的列的信息 SYS_INDEXES 整个InnoDB存储引擎中所有的索引的信息 SYS_FIELDS 整个InnoDB存储引擎中所有的索引对应的列的信息 SYS_FOREIGN 整个InnoDB存储引擎中所有的外键的信息 SYS_FOREIGN_COLS 整个InnoDB存储引擎中所有的外键对应列的信息 SYS_TABLESPACES 整个InnoDB存储引擎中所有的表空间信息 SYS_DATAFILES 整个InnoDB存储引擎中所有的表空间对应文件系统的文件路径信息 SYS_VIRTUAL 整个InnoDB存储引擎中所有的虚拟生成列的信息 这些系统表也被称为数据字典，它们都是以B+树的形式保存在系统表空间的某些页面中，其中SYS_TABLES、SYS_COLUMNS、SYS_INDEXES、SYS_FIELDS这四个表尤其重要，称之为基本系统表（basic system tables），我们先看看这4个表的结构： 1.2 SYS_TABLES表 列名 描述 name 表的名称 id InnoDB存储引擎每一张表都有一个唯一的ID n_cols 该表拥有的列的个数 type 表的类型，记录了一些文件格式，行格式，压缩等信息 Mix_id 已经过时，忽略 Mix_len 表的一些额外属性 Cluster_id 未使用，忽略 Space 该表所属空间的ID 这个SYS_TABLES表有两个索引： 以NAME列为主键的聚簇索引 以ID列建立的二级索引 1.3 SYS_COLUMNS表 列名 描述 TABLE_ID 该列所属表对应的ID POS 该列在表中是第几列 NAME 该列的名称 MTYPE main data type，主数据类型，就是那堆INT、CHAR、VARCHAR、FLOAT、DOUBLE等 PRTYPE precise type，精确数据类型，就是修饰主数据类型的那堆东东，比如是否允许NULL值，是否允许负数啥的 LEN 该列最多占用存储空间的字节数 PREC 该列的精度，不过这列貌似都没有使用，默认值都是0 这个SYS_COLUMNS表只有一个聚集索引： 以(TABLE_ID, POS)列为主键的聚簇索引 1.4 SYS_INDEXES表 列名 描述 TABLE_ID 该索引所属表对应的ID ID InnoDB存储引擎中每个索引都有一个唯一的ID NAME 该索引的名称 N_FIELDS 该索引包含列的个数 TYPE 该索引的类型，比如聚簇索引、唯一索引、更改缓冲区的索引、全文索引、普通的二级索引等等各种类型 SPACE 该索引根页面所在的表空间ID PAGE_NO 该索引根页面所在的页面号 MERGE_THRESHOLD 如果页面中的记录被删除到某个比例，就把该页面和相邻页面合并，这个值就是这个比例 这个SYS_INDEXES表只有一个聚集索引： 以(TABLE_ID, ID)列为主键的聚簇索引 1.5 SYS_FIELDS表 列名 描述 INDEX_ID 该索引列所属的索引的ID POS 该索引列在某个索引中是第几列 COL_NAME 该索引列的名称 这个SYS_FIELDS表只有一个聚集索引： 以(INDEX_ID, POS)列为主键的聚簇索引 1.6 Data Dictionary Header页面只要有了上述4个基本系统表，也就意味着可以获取其他系统表以及用户定义的表的所有元数据。比方说我们想看看SYS_TABLESPACES这个系统表里存储了哪些表空间以及表空间对应的属性，那就可以： 到SYS_TABLES表中根据表名定位到具体的记录，就可以获取到SYS_TABLESPACES表的TABLE_ID 使用这个TABLE_ID到SYS_COLUMNS表中就可以获取到属于该表的所有列的信息。 使用这个TABLE_ID还可以到SYS_INDEXES表中获取所有的索引的信息，索引的信息中包括对应的INDEX_ID，还记录着该索引对应的B+数根页面是哪个表空间的哪个页面。 使用INDEX_ID就可以到SYS_FIELDS表中获取所有索引列的信息。 这4个表的元数据去哪里获取呢？这4个表的元数据，就是它们有哪些列、哪些索引等信息是硬编码到代码中的，InnoDB用一个固定的页面来记录这4个表的聚簇索引和二级索引对应的B+树位置，这个页面就是页号为7的页面，类型为SYS，记录了Data Dictionary Header，也就是数据字典的头部信息。除了这4个表的5个索引的根页面信息外，这个页号为7的页面还记录了整个InnoDB存储引擎的一些全局属性。 这个页面由下边几个部分组成： 名称 中文名 占用空间（字节） 简单描述 File Header 文件头部 38 页的一些通用信息 Data Dictionary Header 数据字典头部信息 56 记录一些基本系统表的根页面位置以及InnoDB存储引擎的一些全局信息 Segment Header 段头部信息 10 记录本页面所在段对应的INODE Entry位置信息 Empty Space 尚未使用空间 16272 用于页结构的填充，没啥实际意义 File Trailer 文件尾部 8 校验页是否完整 这个页面里有Segment Header部分，意味着InnoDB把这些有关数据字典的信息当成一个段来分配存储空间，我们称之为数据字典段。由于目前我们需要记录的数据字典信息非常少（可以看到Data Dictionary Header部分仅占用了56字节），所以该段只有一个碎片页，也就是页号为7的这个页。 接下来我们需要看一下Data Dictionary Header部分的各个字段： Max Row ID：如果我们不显式的为表定义主键，而且表中也没有UNIQUE索引，那么InnoDB存储引擎会默认为我们生成一个名为row_id的列作为主键。因为它是主键，所以每条记录的row_id列的值不能重复。原则上只要一个表中的row_id列不重复就可以了，也就是说表a和表b拥有一样的row_id列也没啥关系，不过InnoDB只提供了这个Max Row ID字段，不论哪个拥有row_id列的表插入一条记录时，该记录的row_id列的值就是Max Row ID对应的值，然后再把Max Row ID对应的值加1，也就是说这个Max Row ID是全局共享的。 Max Table ID：InnoDB存储引擎中的所有的表都对应一个唯一的ID，每次新建一个表时，就会把本字段的值作为该表的ID，然后自增本字段的值。 Max Index ID：InnoDB存储引擎中的所有的索引都对应一个唯一的ID，每次新建一个索引时，就会把本字段的值作为该索引的ID，然后自增本字段的值。 Max Space ID：InnoDB存储引擎中的所有的表空间都对应一个唯一的ID，每次新建一个表空间时，就会把本字段的值作为该表空间的ID，然后自增本字段的值。 Mix ID Low(Unused)：这个字段没啥用，跳过。 Root of SYS_TABLES clust index：本字段代表SYS_TABLES表聚簇索引的根页面的页号。 Root of SYS_TABLE_IDS sec index：本字段代表SYS_TABLES表为ID列建立的二级索引的根页面的页号。 Root of SYS_COLUMNS clust index：本字段代表SYS_COLUMNS表聚簇索引的根页面的页号。 Root of SYS_INDEXES clust index本字段代表SYS_INDEXES表聚簇索引的根页面的页号。 Root of SYS_FIELDS clust index：本字段代表SYS_FIELDS表聚簇索引的根页面的页号。 Unused：这4个字节没用，跳过。 以上就是页号为7的页面的全部内容。 1.7 information_schema系统数据库用户是不能直接访问InnoDB的这些内部系统表的，除非你直接去解析系统表空间对应文件系统上的文件。不过InnoDB考虑到查看这些表的内容可能有助于大家分析问题，所以在系统数据库information_schema中提供了一些以innodb_sys开头的表： 12345678910111213141516171819mysql&gt; USE information_schema;Database changedmysql&gt; SHOW TABLES LIKE &#x27;innodb_sys%&#x27;;+--------------------------------------------+| Tables_in_information_schema (innodb_sys%) |+--------------------------------------------+| INNODB_SYS_DATAFILES || INNODB_SYS_VIRTUAL || INNODB_SYS_INDEXES || INNODB_SYS_TABLES || INNODB_SYS_FIELDS || INNODB_SYS_TABLESPACES || INNODB_SYS_FOREIGN_COLS || INNODB_SYS_COLUMNS || INNODB_SYS_FOREIGN || INNODB_SYS_TABLESTATS |+--------------------------------------------+10 rows in set (0.00 sec) 在information_schema数据库中的这些以INNODB_SYS开头的表并不是真正的内部系统表，而是在存储引擎启动时读取这些以SYS开头的系统表，然后填充到这些以INNODB_SYS开头的表中。以INNODB_SYS开头的表和以SYS开头的表中的字段并不完全一样。​ 补充一张表空间完整结构图","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[四]索引命中原理","slug":"MySQL/MySQL[四]索引命中原理","date":"2022-01-11T03:15:31.769Z","updated":"2022-01-11T03:19:35.568Z","comments":true,"path":"2022/01/11/MySQL/MySQL[四]索引命中原理/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E5%9B%9B]%E7%B4%A2%E5%BC%95%E5%91%BD%E4%B8%AD%E5%8E%9F%E7%90%86/","excerpt":"","text":"上一篇分析了InnoDB存储引擎的B+树索引，现在来进行一个简单的回顾。 每个索引都对应一颗B+树，B+树分为好多层，最下边一层是叶子结点，其余的是内结点。所有的用户记录都存储在B+树的叶子结点，所有目录项记录都存储在内节点。 InnoDB存储引擎会自动为主键建立聚簇索引，聚簇索引的叶子结点包含完整的用户记录。 我们可以为指定的列建立二级索引，二级索引的叶子结点包含的用户记录由索引列+主键组成，所以如果项通过二级索引来查找完整的用户记录的话，需要通过回表操作，也就是在通过二级索引找到主键值之后再到聚簇索引中查找完整的用户记录。 B+树中每层结点都是按照索引列值从大到小的顺序排序而组成了双向链表，而且每个页内的记录(不论是用户记录还是目录项记录)都是按照索引列的值从小到大的顺序而形成了一个单链表。如果是联合索引的话，则页面和记录先按照联合索引前边的列排序，如果该列值相同，在按照联合索引后边的列排序。 通过索引查找记录是从B+树的根节点开始，一层一层乡下搜索。由于每个页面都按照索引列的值建立了页目录，所以在这些页面中查找非常快。 一，做一些前置的准备为了这篇文章的演示，需要先建立一张简单的表，用来演示索引执行过程中出现的一些情况。 123456789101112131415161718192021create table single_table( # 主键索引 id int primary key auto_increment, key1 varchar(100), key2 int, key3 varchar(100), key_part1 varchar(100), key_part2 varchar(100), key_part3 varchar(100), common_field varchar(100), # 索引列key1 key idx_key1 (key1), # 唯一索引：索引列key2 unique key uk_key2 (key2), # 索引列key3 key idx_key3 (key3), # 联合索引：索引列：key_part1, key_part2, key_part3 key idx_key_part (key_part1, key_part2, key_part3)) engine = innodb charset = utf8; 再往表中插入100w条数据，具体的插入过程不在演示。 二，索引的代价凡事都是有利有弊的，索引可以加快查询的速度，但是同样的，他也有相应的缺点。 空间上 一个索引对应一个B+树，每一个B+树的每一个节点都是一个数据页。一个数据页大小默认是16kb，所以一张表的索引越多，占用的空间其实越大，特别是在数据量大的时候，所以一般我们建立索引，默认每张表不要超过5个。 时间上 在对表进行增删改操作的时候，要对所有索引对应的B+树进行修改。而且上一篇分析过，B+树的每一层节点都按照索引列的值从小到大的顺序排序组成了双向链表。页中的记录都按照索引列的值从小到大的顺序形成了一个单向链表。而增删改操作可能会对结点和记录的排序造成破坏，所以存储引擎需要额外的时间进行页面分裂，页回收等操作，好维护结点和记录的排序。索引越多，维护的时间成本越高。 还有一点就是执行查询语句之前，会先生成执行计划。一般情况下一条语句再一次执行过程中只会使用一个二级索引(有特殊的，后面会分析)，在生成执行计划的时候需要计算使用不同索引执行查询时所需成本，最后选取成本最低的索引执行查询。如果索引太多，分析成本就会很高，耗时严重，从而影响查询语句的执行性能。 为了合理的建立索引，一方面加快我们的查询速度，一方面又不会过分的占用我们的时间和空间，我们需要了解索引在查询执行期间到底是如何发挥作用的。 三，使用B+树索引1.扫描区间和边界条件先说什么是全表扫描？就是从头到尾依次遍历所有结点，再依次遍历结点中的所有记录。全表扫描虽然效率很低，但是却是一种万能的解决方案，所有查询都可以使用这种方案兜底。 我们可以利用B+树查找索引列值等于某个值的记录，这样可以明显减少需要扫描的记录数量。由于B+树叶子节点中的记录是按照索引列值从小到大的顺序排序的，所以只扫描某个区间或某些区间中的记录也是很快的，比如下面这个查询语句： 1explain select * from single_table where id&gt;=2 and id&lt;=100; 这个时候其实是走了主键索引，这个语句其实是想查找id值在区间【2，100】内的所有聚簇索引记录，我们可以通过主键索引先定位到id=2的记录，然后顺着这条记录的单向链表往后找就行了。 与全表扫描的100w数据相比，扫描这个区间的成本简直太小了，所以提升了查询效率。我们把这个案例中待扫描的id值所在区间称为扫描区间，把形成这个扫描区间的搜索条件称为形成这个扫描区间的边界条件。 其实对于全表扫描来讲，就是在【-∞，+∞】的区间进行扫描而已。 再来看一条查询语句： 12345explainselect *from single_tablewhere key2 in (1438, 6328) or (key2 &gt;= 38 and key2 &lt;= 79); 这个查询的搜索条件涉及到key2列，我们正好在key2列上建立了唯一索引。如果使用唯一索引执行这个查询，实际上相当于从三个区间获取二级索引的记录。 【1438，1438】 【6328，6328】 【38，79】 类似前面两个区间这种，只有一个值的区间，我们称为单点扫描区间，把类似第三个区间这样存在多个值的叫做范围扫描区间，另外，由于我们的查询列是*，导致从上述的区间每次获取到一条二级索引记录，就需要根据二级索引记录的id列的值取回表一次。 当然，并不是所有的条件都可以称为边界条件，比如下面的查询语句： 123456explainselect *from single_tablewhere key1 &gt; &#x27;aaa&#x27; and key3 &lt; &#x27;zzz&#x27; and common_field = &#x27;aaa&#x27;; 如果使用idx_key1执行查询，那么相应的扫描区间就变成了【’aaa’,+∞】，后面的条件就是普通搜索条件，这些普通的搜索条件需要在获取到idx_key1的二级索引记录后，在执行回表操作，在获取到完整的用户记录后才能去判断他们是否成立。 如果使用idx_key3执行查询，那么扫描区间就是【-∞,’zzz’】,其余的条件就是普通搜索条件，这些普通的搜索条件需要在获取到idx_key3的二级索引记录后，在执行回表操作，在获取到完整的用户记录后才能去判断他们是否成立。 在使用某个索引执行查询的时候，关键的问题就是通过搜索条件找出合适的区间，然后再去对应的B+树中扫描索引列值在这些扫描区间的记录，对于每一个区间来说，只需要定位到第一条，就可以沿着单链表一直往后扫符合条件的记录。 其实对于B+树索引来说： = &lt;=&gt; in not in is null is not null &gt; &lt; &gt;= &lt;= between != like 都会进行区间扫描，只不过区间扫描大小不同导致效率不同。 不过也有一些需要注意的点： in和多个 = 用or连接起来的效果其实是一样的，都会产生多个单点扫描区间 不等于 产生的区间比较操蛋： 1select * from single_table where key1 != &#x27;aaa&#x27; 这个时候idx_key1 执行查询的时候对应的扫描区间就是【-∞,’aaa’】和【’aaa’,+∞】。 like操作比较特殊，只有在匹配完整的字符串或者匹配字符串前缀的时候才会产生合适的扫描区间 比较字符串的大小其实就是逐个比较每个字符的大小。字符串的比较过程如下： 先比较字符串的第一个字符，第一个字符串小的字符就比较小 如果第一个字符一样的话就按照上面的规则比较第二个，以此类推。 对于某个索引列来说，字符串前缀相同的记录在由记录组成的单向链表中肯定是相邻的。比如我们有一个搜索条件是key1 like &#39;a%&#39;，对于二级索引idx_key1来说，所有字符串前缀为a的二级索引记录肯定是相邻的。这也就意味着我们只要定位到key1值得字符串前缀为a的第一条记录，就可以依次往后扫描，直到某条二级索引记录的字符串不是a为止。 很显然，key1 like &#39;a%&#39;形成的扫描区间相当于【’a’,’b’】。 在执行一个查询语句的时候，首先需要找出所有可用的索引以及使用他们时对应的扫描区间。接下来我们分析下怎么从包含若干个and或者or的复杂搜索条件中提取出正确的扫描区间。 1.1 所有搜索条件都可以生成合适的扫描区间的情况在使用某个索引执行查询的时候，有时每个小的搜索条件都可以生成一个合适的扫描区间来减少需要扫描的记录数量。 12345explainselect *from single_tablewhere key2 &gt; 100 and key2 &gt; 200; 在使用唯一索引进行查询的时候，这两个条件都可以形成一个扫描区间【100，+∞】，【200，+∞】。因为这两个条件是用and连接的，所以最终就是两个区间取交集【200，+∞】。 我们把sql改一改： 12345explainselect *from single_tablewhere key2 &gt; 100 or key2 &gt; 200; 这个时候因为是使用or进行两个条件的连接，所以两个条件的区间应该取并集：【100，+∞】。 1.2 有的搜索条件不能生成合适的扫描区间的情况在使用某个索引进行查询的时候，有些小的搜索条件并不能生成合适的扫描区间来减少需要扫描的行数。 12345explainselect *from single_tablewhere key2 &gt; 100 and common_field =&#x27;abc&#x27;; 在使用唯一索引进行查询的时候，第一个条件会定位出区间【100，+∞】，但是第二个条件是一个普通条件，相当于【-∞，+∞】，因为两个条件使用and连接的，所以最终取交集之后的区间就是【100，+∞】。 其实在使用唯一索引进行查询的时候，在寻找对应的扫描区间的过程中，搜索条件common_field =&#39;abc&#39;没有起到任何作用，我们可以直接把这个条件进行一个等价替换【TRUE】(true对应的扫描区间也是【-∞，+∞】)。 12345explainselect *from single_tablewhere key2 &gt; 100 and true; 在进行化简之后就变成： 1234explainselect *from single_tablewhere key2 &gt; 100 也就是说上面的查询语句在使用唯一索引进行查询的时候对应的扫描区间就是【100，+∞】。 再来看一下使用OR的情况： 12345explainselect *from single_tablewhere key2 &gt; 100 or common_field =&#x27;abc&#x27;; 同样进行化简 12345explainselect *from single_tablewhere key2 &gt; 100 or true; 继续化简 1234explainselect *from single_tablewhere true 可见如果此时强制使用唯一索引进行查询，对应的扫描区间就是【-∞，+∞】，再加上这是二级索引，每次匹配到一条都要进行回表，所以这个查询的代价甚至比全表扫描还大，这个时候再使用唯一索引就没意义了。 1.3从复杂的搜索条件中找出扫描区间来一个复杂点的条件： 12345select *from single_tablewhere (key1 &gt; &#x27;aaa&#x27; and key2 &gt; 748) or (key1 &lt; &#x27;eee&#x27; and key1 &gt; &#x27;ccc&#x27;) or (key1 like &#x27;%f&#x27; and key1 &gt; &#x27;aaa&#x27; and (key2 &lt; 8000 or common_field = &#x27;aaa&#x27;)); 这无语的SQL怎么搞？ 先看where子句里面都涉及到了哪些列，以及我们为哪些列建立了索引 对于可以用到的索引，我们来分析索引的扫描区间 1.3.1 使用idx_key1查询先把不能形成合适扫描区间的搜索条件干掉，怎么干掉？直接把他们替换成TRUE。 替换之后的效果： 12345select *from single_tablewhere (key1 &gt; &#x27;aaa&#x27; and TRUE) or (key1 &lt; &#x27;eee&#x27; and key1 &gt; &#x27;ccc&#x27;) or (TRUE and key1 &gt; &#x27;aaa&#x27; and (TRUE or TRUE)); 化简之后的结果： 1234select *from single_tablewhere (key1 &gt; &#x27;aaa&#x27; ) -- 【aaa,+∞】 or (key1 &lt; &#x27;eee&#x27; and key1 &gt; &#x27;ccc&#x27;) -- 【&#x27;ccc&#x27;,&#x27;eee&#x27;】 因为这两个条件之间是用OR连接起来的，所以我们应该取并集，最终：【aaa,+∞】。 也就是需要把所有key1在这个区间内的所有二级索引记录都取出来，针对获取到的每一条二级索引记录进行一次回表，在得到完整的用户记录之后在使用其他的搜索条件进行过滤。 1.3.2 使用唯一二级索引查询我们还是进行化简 12345select *from single_tablewhere (TRUE and key2 = 748) or (TRUE and TRUE) or (TRUE and TRUE and (key2 &lt; 8000 or common_field = &#x27;aaa&#x27;)); 再继续化简 1234select *from single_tablewhere key2 = 748 or TRUE 因为两个条件使用OR连接的，所以最终的结果就是【-∞，+∞】。 也就是需要把所有key2所有二级索引记录都取出来，针对获取到的每一条二级索引记录进行一次回表，在得到完整的用户记录之后在使用其他的搜索条件进行过滤，比全表扫描还耗时，所以这个时候我们是不会走唯一二级索引的。 在使用idx_key1执行上述查询的时候，搜索条件 key1 like &#39;%f&#39; 比较特殊。虽然他不能作为形成扫描区间的边界条件，但是idx_key1的二级索引记录是包含key1列的。因此我们可以先判断获取到的二级索引记录是否符合这个条件。如果符合在执行回表操作，如果不符合就不用回表了。这样就可以较少因为回表带来的性能损耗，这就是索引下推。 1.4使用联合索引执行查询时对应的扫描区间联合索引的索引列包含多个列，B+树中的每一层页面以及每一个页中的记录采用的排序规则比较复杂。以上面的表为例，idx_key_part (key_part1, key_part2, key_part3) 采用的排序规则如下： 先按照key_part1进行排序 key_part1相同按照key_part2进行排序，以此类推 1.4.1全值匹配原理对于下面这条查询语句来讲： 123select *from single_tablewhere key_part1 =&#x27;a&#x27;; 因为二级索引记录先按照key_part1进行值排序的，所以符合条件的所有记录肯定是相邻的。我们可以先定位到符合条件的第一条记录，沿着链表顺序往下扫描知道不符合条件为止（当然，对于获取到的每一条二级索引记录都需要进行回表）。此时的扫描区间【’a’,’a’】。 在看一条查询语句： 1234select *from single_tablewhere key_part1 = &#x27;a&#x27; and key_part2 = &#x27;b&#x27;; 按照联合索引的排序规则，最终的扫描区间其实就是【(‘a’,’b’),(‘a’,’b’)】。 在看一条SQL： 123select *from single_tablewhere key_part1 &lt;&#x27;a&#x27;; 因为二级索引记录先按照key_part1进行值排序的，所以符合条件的所有记录肯定是相邻的。我们可以先定位到符合条件的第一条记录，然后顺着单向链表继续往后扫描，直到遇到不符合规则的记录就停止。【-∞,’a’】 1.4.2最佳左前缀匹配原理在看一条SQL： 123select *from single_tablewhere key_part2 = &#x27;a&#x27;; 由于二级索引记录不是直接按照key_part2列的值进行排序的，所以符合条件的二级索引记录可能并不相邻，也就意味着我们不能通过搜索条件来减少需要扫描的行数，这种情况下，我们是不会使用这个索引的。 在看一条SQL： 1234select *from single_tablewhere key_part1 = &#x27;a&#x27; and key_part3 = &#x27;c&#x27;; 这个时候，其实是可以按照key_part1进行过滤的，但是因为接下来是按照key_part2进行排序的，所以满足搜索条件 key_part3 = &#39;c&#39;的二级索引值记录可能并不相邻，这个时候扫描区间其实就是【’a’,’a’】。因为第二个条件走不了索引。 针对获取到的每一条二级索引记录，如果没有开启索引条件下推的特性，则必须先回表获取完整的记录在来判断 key_part3 = &#39;c&#39;条件是否成立，如果开启了索引下推特性，可以判断完 key_part3 = &#39;c&#39;是否成立后在进行回表操作，索引下推是在MySQL5.6引入的，默认开启。 在看一条SQL： 1234select *from single_tablewhere key_part1 &lt; &#x27;a&#x27; and key_part2 = &#x27;c&#x27;; 因为二级索引记录先按照key_part1进行值排序的，所以符合条件的所有记录肯定是相邻的。但是对于key_part1 &lt; &#39;a&#39;条件的二级索引记录来说，并不是直接按照key_part2进行排序的，也就是说我们不能根据key_part2 = &#39;c&#39;来进一步减少扫描的行数。那么，如果使用当前索引执行查询，可以定位到符合key_part1 &lt; &#39;a&#39;的第一条记录，然后沿着单链表往后扫描，一直到不符合key_part1 &lt; &#39;a&#39;为止。 所以在使用当前索引执行SQL的时候，对应的扫描区间其实就是【-∞,’a’】。 在看一条SQL： 1234select *from single_tablewhere key_part1 &lt;= &#x27;a&#x27; and key_part2 = &#x27;c&#x27;; 这条SQL和上一条SQL很像，唯一的区别就是从小于变成了小于等于。很显然符合key_part1 &lt;= &#39;a&#39;的索引值记录是连续的，但是对于符合key_part1 &lt;= &#39;a&#39;条件的二级索引记录来说，并不是直接按照key_part2列排序的。但是，对于符合key_part1 = &#39;a&#39;的二级索引记录来说，是按照key_part2的值进行排序的。那么再确定需要扫描的二级索引记录的范围时，当二级索引记录的key_part1 = &#39;a&#39;时，也可以通过key_part2 = &#39;c&#39;来减少扫描行数，也就是说，当扫描到不符合key_part1 &lt;= &#39;a&#39; and key_part2 = &#39;c&#39;的第一条记录的时候，就可以结束扫描，而不需要将所有的key_part1 = &#39;a&#39;的记录全部扫描完。 2. 索引用于排序我们在写查询语句的时候经常需要对查询出来的记录通过ORDER BY子句按照某种规则进行排序。一般情况下，我们只能把记录都加载到内存中，再用一些排序算法，比如快速排序、归并排序等等在内存中对这些记录进行排序，有的时候可能查询的结果集太大以至于不能在内存中进行排序的话，还可能暂时借助磁盘的空间来存放中间结果，排序操作完成后再把排好序的结果集返回到客户端。在MySQL中，把这种在内存中或者磁盘上进行排序的方式统称为文件排序（英文名：filesort），跟文件这个词儿一沾边儿，就显得这些排序操作非常慢了（磁盘和内存的速度比起来，就像是飞机和蜗牛的对比）。但是如果ORDER BY子句里使用到了我们的索引列，就有可能省去在内存或文件中排序的步骤，比如下边这个简单的查询语句： 1SELECT * FROM single_table ORDER BY key_part1, key_part2, key_part3 LIMIT 10; 这个查询的结果集需要先按照key_part1值排序，如果记录的key_part1值相同，则需要按照key_part2来排序，如果key_part2的值相同，则需要按照key_part3排序。因为这个B+树索引本身就是按照上述规则排好序的，所以直接从索引中提取数据，然后进行回表操作取出该索引中不包含的列就好了。 2.1使用联合索引进行排序注意事项对于联合索引有个问题需要注意，ORDER BY的子句后边的列的顺序也必须按照索引列的顺序给出，如果给出ORDER BY key_part1, key_part3, key_part2的顺序，那也是用不了B+树索引，这种颠倒顺序就不能使用索引的原因我们上边详细说过了，这就不赘述了。 同理，ORDER BY key_part1、ORDER BY key_part1, key_part2这种匹配索引左边的列的形式可以使用部分的B+树索引。当联合索引左边列的值为常量，也可以使用后边的列进行排序，比如这样： 1SELECT * FROM single_table WHERE key_part1 = &#x27;A&#x27; ORDER BY key_part2, key_part3 LIMIT 10; 这个查询能使用联合索引进行排序是因为key_part1列的值相同的记录是按照key_part2, key_part3排序的。 2.2不可以使用索引进行排序的几种情况2.2.1ASC、DESC混用对于使用联合索引进行排序的场景，我们要求各个排序列的排序顺序是一致的，也就是要么各个列都是ASC规则排序，要么都是DESC规则排序。 ORDER BY子句后的列如果不加ASC或者DESC默认是按照ASC排序规则排序的，也就是升序排序的。 为啥会有这种规定呢？这个还得回头想想这个idx_key_part联合索引中记录的结构： 先按照记录的key_part1列的值进行升序排列。 如果记录的key_part1列的值相同，再按照key_part2列的值进行升序排列。 如果记录的key_part2列的值相同，再按照key_part3列的值进行升序排列。 如果查询中的各个排序列的排序顺序是一致的，比方说下边这两种情况： ORDER BY key_part1, key_part2 LIMIT 10这种情况直接从索引的最左边开始往右读10行记录就可以了。 ORDER BY key_part1 DESC, key_part2 DESC LIMIT 10，这种情况直接从索引的最右边开始往左读10行记录就可以了。 但是如果我们查询的需求是先按照key_part1列进行升序排列，再按照key_part2列进行降序排列的话，比如说这样的查询语句： 1SELECT * FROM single_table ORDER BY key_part1, key_part2 DESC LIMIT 10; 这样如果使用索引排序的话过程就是这样的： 先从索引的最左边确定key_part1列最小的值，然后找到key_part1列等于该值的所有记录，然后从name列等于该值的最右边的那条记录开始往左找10条记录。 如果key_part1列等于最小的值的记录不足10条，再继续往右找key_part1值第二小的记录，重复上边那个过程，直到找到10条记录为止。 这样不能高效使用索引，而要采取更复杂的算法去从索引中取数据，所以就规定使用联合索引的各个排序列的排序顺序必须是一致的。 2.2.2排序列包含非同一个索引的列有时候用来排序的多个列不是一个索引里的，这种情况也不能使用索引进行排序，比方说： 1SELECT * FROM single_table ORDER BY key_part1, common_field LIMIT 10; key_part1和common_field并不属于一个联合索引中的列，所以无法使用索引进行排序。 2.2.3排序列使用了复杂的表达式要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式，比方说这样： 1SELECT * FROM single_table ORDER BY UPPER(key_part1) LIMIT 10; 使用了UPPER函数修饰过的列就不是单独的列了，这样就无法使用索引进行排序了。 3. 索引用于分组有时候我们为了方便统计表中的一些信息，会把表中的记录按照某些列进行分组。比如下边这个分组查询： 1SELECT key_part1, key_part2, key_part3, COUNT(*) FROM single_table GROUP BY key_part1, key_part2, key_part3 这个查询语句相当于做了3次分组操作： 先把记录按照key_part1值进行分组，所有key_part1值相同的记录划分为一组。 将每个key_part1值相同的分组里的记录再按照key_part2的值进行分组，将key_part3值相同的记录放到一个小分组里，所以看起来就像在一个大分组里又化分了好多小分组。 再将上一步中产生的小分组按照key_part3的值分成更小的分组，所以整体上看起来就像是先把记录分成一个大分组，然后把大分组分成若干个小分组，然后把若干个小分组再细分成更多的小小分组。 然后针对那些小小分组进行统计，比如在我们这个查询语句中就是统计每个小小分组包含的记录条数。如果没有索引的话，这个分组过程全部需要在内存里实现，而如果有了索引的话，恰巧这个分组顺序又和我们的B+树中的索引列的顺序是一致的，而我们的B+树索引又是按照索引列排好序的，这不正好么，所以可以直接使用B+树索引进行分组。 和使用B+树索引进行排序是一个道理，分组列的顺序也需要和索引列的顺序一致，也可以只使用索引列中左边的列进行分组。 四，回表的代价看下边这个查询： 1SELECT * FROM single_table WHERE key_part1 &gt; &#x27;aaa&#x27; AND key_part1 &lt; &#x27;zzz&#x27;; 在使用idx_key_part索引进行查询时大致可以分为这两个步骤： 从索引idx_key_part对应的B+树中取出key_part1值在aaa～zzz之间的用户记录。 由于索引idx_key_part对应的B+树用户记录中只包含key_part1、key_part2、key_part3、id这4个字段，而查询列表是*，意味着要查询表中所有字段，也就是还要包括其他字段。这时需要把从上一步中获取到的每一条记录的id字段都到聚簇索引对应的B+树中找到完整的用户记录，也就是我们通常所说的回表，然后把完整的用户记录返回给查询用户。 由于索引idx_key_part对应的B+树中的记录首先会按照key_part1列的值进行排序，所以值在aaa～zzz之间的记录在磁盘中的存储是相连的，集中分布在一个或几个数据页中，我们可以很快的把这些连着的记录从磁盘中读出来，这种读取方式我们也可以称为顺序I/O。根据第1步中获取到的记录的id字段的值可能并不相连，而在聚簇索引中记录是根据id（也就是主键）的顺序排列的，所以根据这些并不连续的id值到聚簇索引中访问完整的用户记录可能分布在不同的数据页中，这样读取完整的用户记录可能要访问更多的数据页，这种读取方式我们也可以称为随机I/O。一般情况下，顺序I/O比随机I/O的性能高很多，所以步骤1的执行可能很快，而步骤2就慢一些。所以这个使用索引idx_key_part的查询有这么两个特点： 会使用到两个B+树索引，一个二级索引，一个聚簇索引。 访问二级索引使用顺序I/O，访问聚簇索引使用随机I/O。 需要回表的记录越多，使用二级索引的性能就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引。比方说key_part1值在aaa～zzz之间的用户记录数量占全部记录数量90%以上，那么如果使用idx_key_part索引的话，有90%多的id值需要回表，还不如直接去扫描聚簇索引（也就是全表扫描）。 那什么时候采用全表扫描的方式，什么时候使用采用二级索引 + 回表的方式去执行查询呢？这个就是查询优化器做的工作，查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用二级索引 + 回表的方式。当然优化器做的分析工作不仅仅是这么简单，但是大致上是这个过程。一般情况下，限制查询获取较少的记录数会让优化器更倾向于选择使用二级索引 + 回表的方式进行查询，因为回表的记录越少，性能提升就越高，比方说上边的查询可以改写成这样： 1SELECT * FROM single_table WHERE key_part1 &gt; &#x27;aaa&#x27; AND key_part1 &lt; &#x27;zzz&#x27; LIMIT 10; 添加了LIMIT 10的查询更容易让优化器采用二级索引 + 回表的方式进行查询。 对于有排序需求的查询，上边讨论的采用全表扫描还是二级索引 + 回表的方式进行查询的条件也是成立的，比方说下边这个查询： 1SELECT * FROM single_table ORDER BY key_part1, key_part2, key_part3; 由于查询列表是*，所以如果使用二级索引进行排序的话，需要把排序完的二级索引记录全部进行回表操作，这样操作的成本还不如直接遍历聚簇索引然后再进行文件排序（filesort）低，所以优化器会倾向于使用全表扫描的方式执行查询。如果我们加了LIMIT子句，比如这样： 1SELECT * FROM single_table ORDER BY key_part1, key_part2, key_part3 LIMIT 10; 这样需要回表的记录特别少，优化器就会倾向于使用二级索引 + 回表的方式执行查询。 五，更好的创建和使用索引1. 只为了用于搜索，排序&amp;分组的列创建索引也就是说，只为出现在WHERE子句中的列、连接子句中的连接列，或者出现在ORDER BY或GROUP BY子句中的列创建索引。而出现在查询列表中的列就没必要建立索引了： 1SELECT key_part1, key_part2 FROM single_table WHERE key_part3 = &#x27;Ashburn&#x27;; 像查询列表中的key_part1、key_part2这两个列就不需要建立索引，我们只需要为出现在WHERE子句中的key_part3列创建索引就可以了。 2. 考虑列的基数列的基数指的是某一列中不重复数据的个数，比方说某个列包含值2, 5, 8, 2, 5, 8, 2, 5, 8，虽然有9条记录，但该列的基数却是3。也就是说，在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。这个列的基数指标非常重要，直接影响我们是否能有效的利用索引。假设某个列的基数为1，也就是所有记录在该列中的值都一样，那为该列建立索引是没有用的，因为所有值都一样就无法排序，无法进行快速查找了～ 而且如果某个建立了二级索引的列的重复值特别多，那么使用这个二级索引查出的记录还可能要做回表操作，这样性能损耗就更大了。所以结论就是：最好为那些列的基数大的列建立索引，为基数太小列的建立索引效果可能不好。 3. 索引列的类型尽量小我们在定义表结构的时候要显式的指定列的类型，以整数类型为例，有TINYINT、MEDIUMINT、INT、BIGINT这么几种，它们占用的存储空间依次递增，我们这里所说的类型大小指的就是该类型表示的数据范围的大小。能表示的整数范围当然也是依次递增，如果我们想要对某个整数列建立索引的话，在表示的整数范围允许的情况下，尽量让索引列使用较小的类型，比如我们能使用INT就不要使用BIGINT，能使用MEDIUMINT就不要使用INT～ 这是因为： 数据类型越小，在查询时进行的比较操作越快（这是CPU层次的东西） 数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下更多的记录，从而减少磁盘I/O带来的性能损耗，也就意味着可以把更多的数据页缓存在内存中，从而加快读写效率。 这个建议对于表的主键来说更加适用，因为不仅是聚簇索引中会存储主键值，其他所有的二级索引的节点处都会存储一份记录的主键值，如果主键适用更小的数据类型，也就意味着节省更多的存储空间和更高效的I/O。 4. 为列前缀建立索引一个字符串其实是由若干个字符组成，如果我们在MySQL中使用utf8字符集去存储字符串的话，编码一个字符需要占用1~3个字节。假设我们的字符串很长，那存储一个字符串就需要占用很大的存储空间。在我们需要为这个字符串列建立索引时，那就意味着在对应的B+树中有这么两个问题： B+树索引中的记录需要把该列的完整字符串存储起来，而且字符串越长，在索引中占用的存储空间越大。 如果B+树索引中索引列存储的字符串很长，那在做字符串比较时会占用更多的时间。 索引列的字符串前缀其实也是排好序的，所以索引的设计者提出了个方案 — 只对字符串的前几个字符进行索引也就是说在二级索引的记录中只保留字符串前几个字符。这样在查找记录时虽然不能精确的定位到记录的位置，但是能定位到相应前缀所在的位置，然后根据前缀相同的记录的主键值回表查询完整的字符串值，再对比就好了。这样只在B+树中存储字符串的前几个字符的编码，既节约空间，又减少了字符串的比较时间，还大概能解决排序的问题。 5. 覆盖索引为了彻底告别回表操作带来的性能损耗，建议：最好在查询列表里只包含索引列，比如这样： 1SELECT key_part1, key_part2 FROM single_table WHERE key_part3 = &#x27;Ashburn&#x27;; 因为我们只查询key_part1, key_part2, 这2个索引列的值，所以在通过idx_key_part索引得到结果后就不必到聚簇索引中再查找记录的剩余列，这样就省去了回表操作带来的性能损耗。我们把这种只需要用到索引的查询方式称为索引覆盖。排序操作也优先使用覆盖索引的方式进行查询，比方说这个查询： 1SELECT key_part1, key_part2, key_part3 FROM person_info ORDER BYkey_part1, key_part2, key_part3; 虽然这个查询中没有LIMIT子句，但是采用了覆盖索引，所以查询优化器就会直接使用idx_key_part索引进行排序而不需要回表操作了。 当然，如果业务需要查询出索引以外的列，那还是以保证业务需求为重。但是尽量不要用用*号作为查询列表，最好把需要查询的列依次标明。 6.不要乱动列名假设表中有一个整数列my_col，我们为这个列建立了索引。下边的两个WHERE子句虽然语义是一致的，但是在效率上却有差别： WHERE my_col * 2 &lt; 4 WHERE my_col &lt; 4/2 第1个WHERE子句中my_col列并不是以单独列的形式出现的，而是以my_col * 2这样的表达式的形式出现的，存储引擎会依次遍历所有的记录，计算这个表达式的值是不是小于4，所以这种情况下是使用不到为my_col列建立的B+树索引的。而第2个WHERE子句中my_col列并是以单独列的形式出现的，这样的情况可以直接使用B+树索引。 所以结论就是：如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的。 7. 尽量维持有序插入对于一个使用InnoDB存储引擎的表来说，在我们没有显式的创建索引时，表中的数据实际上都是存储在聚簇索引的叶子节点的。而记录又是存储在数据页中的，数据页和记录又是按照记录主键值从小到大的顺序进行排序，所以如果我们插入的记录的主键值是依次增大的话，那我们每插满一个数据页就换到下一个数据页继续插，而如果我们插入的主键值忽大忽小的话，这就比较麻烦了，假设某个数据页存储的记录已经满了，它存储的主键值在1~100之间： 如果此时再插入一条主键值为9的记录，那它插入的位置就如下图： 可这个数据页已经满了，再插进来咋办呢？我们需要把当前页面分裂成两个页面，把本页中的一些记录移动到新创建的这个页中。页面分裂和记录移位意味着什么？意味着：性能损耗！所以如果我们想尽量避免这样无谓的性能损耗，最好让插入的记录的主键值依次递增，这样就不会发生这样的性能损耗了。所以我们建议：让主键具有**AUTO_INCREMENT**，让存储引擎自己为表生成主键，而不是我们手动插入 。 8.冗余和重复索引我们知道，通过idx_key_part索引就可以对key_part1列进行快速搜索，再创建一个专门针对key_part1列的索引就算是一个冗余索引，维护这个索引只会增加维护的成本，并不会对搜索有什么好处。 至此，索引命中的原理和我们在建立索引的时候应该注意什么就分析完了，好家伙，又是一个通宵。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[三]InnoDB索引结构","slug":"MySQL/MySQL[三]InnoDB索引结构","date":"2022-01-11T03:08:18.570Z","updated":"2022-01-11T03:14:40.784Z","comments":true,"path":"2022/01/11/MySQL/MySQL[三]InnoDB索引结构/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E4%B8%89]InnoDB%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84/","excerpt":"","text":"索引其实就是对数据按照某种格式进行存储的文件。就InnoDB来讲，索引文件里面会有很多的基本单元【页】。​ 为什么有页的概念？​ 查询数据的时候直接交互磁盘，效率显然又会很慢，所以真正处理数据的过程其实是在内存中，这样就需要把磁盘的数据加载到内存，如果是写操作，可能还要将内存的数据再次刷新到磁盘。如果内存与磁盘的数据交互过程是基于一条条记录来进行的，显然又会很慢，所以InnoDB采取的方式是将数据划分为若干个页，以页来作为内存和磁盘交互的基本单位，默认大小为16KB。 ​ 数据或者叫记录，其实是以【行】的格式存储在页里面的，可以简单的理解成页里面的一行对应一条记录。​ 当然索引文件里面肯定不光只有页，还会有其余的东西，页里面也不光只有行格式，也会有额外的信息，这个下面我们会详细分析，至此我们仅仅需要明确一下索引的概念和层级关系。 明确了这个层级关系之后，接下来我们来从最基础的行格式来进行分析。 一，行格式我们平时都是以记录为单位向表中插入数据的，这些记录在磁盘上的存储形式被称为行格式或者记录格式，截至目前，一共有4种行格式。分别是 compact redundant dynamic compressed，MySQL5.7默认的行格式为dynamic。 1. 如何指定行格式123CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称 ALTER TABLE 表名 ROW_FORMAT=行格式名称 比如我们创建一张表来指定行格式： 12345678create table record_format( c1 varchar(10), c2 varchar(10) not null, c3 char(10), c4 varchar(10))charset=ascii row_format=compact;INSERT INTO record_format_demo(c1, c2, c3, c4) VALUES(&#x27;aaaa&#x27;, &#x27;bbb&#x27;, &#x27;cc&#x27;, &#x27;d&#x27;), (&#x27;eeee&#x27;, &#x27;fff&#x27;, NULL, NULL); 2.compact 行格式首先我们来看Compact行格式。 一条完整的行格式可以被分为两个部分：记录额外信息的部分&amp;记录真实数据的部分。 2.1 额外的信息额外的信息实包含三部分：变长字段的长度列表，NULL值列表和记录头信息。 2.1.1 变长字段长度列表MySQL支持很多的变长字段，我们就以最经典的varchar来进行举例，变长字段的数据存储多少字节其实是不固定的，所以在存储真实的数据的时候，要记录一下真实数据的字节数，这样的话，一个变长字段列实际上就占用了两部分的空间来存储：【真实数据】&amp;【真实数据占用字节数】。 注意：对于一个列varchar(100)，我们实际上存储一个10字节的数据，当在内存中为这个列的数据分配内存空间的时候，实际上会分配100字节，但是这个列的数据在磁盘上，实际上只会分配10字节。 在Compact行格式中，会把所有的变长字段占用的真实长度全部逆序存储在记录的开头位置，形成一个变长字段长度列表。 比如我们刚才创建的那张表，我们来分析一下： c1,c2,c4三个列都是变长字段，所以这三个列的值的长度其实都需要保存到变长字段长度列表，因为这张表的字符集的ASCII，所以每个字符实际只占用1字节来进行编码： 列名 储存内容 内容长度(十进制表示) 内容长度(十六进制表示) C1 ‘aaaa’ 4 0x04 C2 ‘bbb’ 3 0x03 C4 ‘d’ 1 0x01 因为这些长度是按照逆序来存放的，所以最终变长字段长度列表的字节串用十六进制表示的效果就是【010304】。 因为我们演示的这条记录中，c1,c2,c4列中的字符串都比较短，所以真实的数据占用的字节数就比较小，真实数据的长度用一个字节就可以表示，但是如果变长列的内容占用字节数比较多，可能就需要用2个字节来表示。对此InnoDB的规定是： 【W】：某个字符集中表示一个字符最多需要使用的字节数 【M】：当前列类型最多能存储的字符数(比如varchar(100),M=100),如果换算成字节数就是W*M 【L】：真实占用的字节数 如果M*W&lt;=255,那么使用1字节来表示字符串实际用到的字节数。 InnoDB在读记录的变长字段长度列表的时候会先去查看表结构，判断用几个字节去存储的。 如果M*W&gt;=255,这个时候再次分为两种情况： 如果L&lt;=127，那就用1个字节表示 否则就用2个字节表示 如果某个变长字段允许存储的最大字节数大于255的时候，怎么区分他正在读取的字节是一个单独的字段长度还是半个字段长度呢？ InnoDB用该字节的第一个二进制为作为标志位，0：单独的字段长度，1：半个字段长度。 对于一些占用字节数特别多的字段，单个页都无法存储的时候，InnoDB会把一部分数据放到所谓的溢出页，在变长字段长度列表中只会记录当前页的字段长度，所以用两个字节也可以存的下。 此外，变长字段的长度列表中只存储真实数据值为非NULL的列占用的长度，真实数据为NULL的列的长度是不存储的。 也并不是所有的记录都会有变长字段长度列表，假如表中的列要是没有变长字段，或者记录中的变长字段值都是NULL，那就没有变长字段长度列表了。 2.1.2 NULL值列表如果一条记录有多个字段的真实值为NULL，不统一管理的话就会比较占用空间，所以抽取出来了NULL值列表。 当然如果这个表的所有字段都是NOT NULL约束的，就不会有NULL值列表。 看一下处理过程： 首先统计出表中允许存储NULL的字段 如果表中没有NULL字段的列，那就没必要再往下了，否则将每个允许存储NULL的列对应的一个二进制位按照列的顺序逆序排列。1：NULL，0：不是NULL。 MySQL规定NULL值必须用整数个字节的位表示，如果使用的二进制位个数不是整数个字节，则在字节的高位补0。 以此类推，如果一个表中有9个字段允许为NULL，那么这个记录的NULL值列表部分就需要2个字节来表示。 这个时候再来看我们上面创建的表中的记录。 2.1.3 记录头信息由五个固定的字节组成，换算成二进制就是40位，每一部分代表不同的信息。 名称 大小(bit) 描述 预留位1 1 没有使用 预留位2 1 没有使用 delete_mask 1 标记该记录是否被删除 min_rec_mask 1 B+树的每层非叶子节点中的最小记录都会添加该标记 n_owned 4 表示当前记录拥有的记录数 heap_no 13 表示当前记录在记录堆的位置信息 record_type 3 表示当前记录的类型 0 ：普通记录，1：B+树非页节点记录，2：最小记录，3：最大记录 next_record 16 下一条记录的相对位置 接下来来看记录的真实数据。 2.2 真实数据除了表中显式定义的列，MySQL会往我们的表中放一些隐藏列。 列名 是否必须 占用空间 描述 row_id 否 6字节 行ID，唯一标识一条记录 transaction_id 是 6字节 事务ID roll_pointer 是 7字节 回滚指针 【row_id】：这个玩意，跟主键的选择有关，如果我们显式定义了表的主键，就不会有它，如果我们没显式定义主键，那么会去选择一个unique的列作为主键，如果unique的列也没有，那么就会生成一个row_id列作为隐藏的主键。 【transaction_id】&amp;【roll_pointer】和一致性非锁读(MVCC)有关,后面遇到的时候我会在分析介绍。 在完善下我们开头创建的那张表的记录形象。 至此，其实就剩下我们显式插入数据库的真实记录了，但是还有一个特殊的类型需要说明一下。 2.2.1 CHAR 也是变长的？在Compact行格式下只会把变长类型的列的长度逆序记录到变长字段长度列表，但是这其实和我们的字符集有关系，上面我们创建的表显式指定为ASCII字符集，这个时候一个字符只会用一个字节表示，但是假如我们指定的是其它字符集，比如utf8，这个时候一个字符用几个字节表示就不确定了，所以CHAR列的真实字节长度也会被记录到变长字段长度列表。 另外，变长字符集的CHAR(M)类型的列要求至少占用M个字节，而VARCHAR(M)就没有这个要求。 对于使用utf8字符集的CHAR(10)的列来说，该列存储的数据字节长度的范围是10～30个字节。即使我们向该列中存储一个空字符串也会占用10个字节，这是怕将来更新该列的值的字节长度大于原有值的字节长度而小于10个字节时，可以在该记录处直接更新，而不是在存储空间中重新分配一个新的记录空间，导致原有的记录空间成为所谓的碎片。 3. 行溢出上面提到了，如果一条记录的真实字节数太大，就会导致行溢出，把超出的一部分数据存储到其他行或者页。 3.1 varchar(M)最多能存储的数据varchar(M)的列最多可以占用65535个字节。其中M代表该类型最多存储的字符数量。 实际上，MySQL对一条记录占用的最大存储空间是有限制的，除了BLOB，TEXT类型的列之外，其他所有的列(不包含隐藏列和记录头信息)占用的字节长度加起来不能超过65535个字节。这个65535个字节除了列本身的数据之外，还包括一些其他的数据，比如说我们为了存储一个varchar列，其实还需要占用3部分空间。 真实数据 真实数据占用的字节长度 NULL值标识，如果该列有NOT_NULL属性则可以没有这部分存储空间 如果该varchar类型的列没有NOT NULL属性那最多只能存储65532个字节的数据，因为真实数据的长度可能占用2个字节，NULL值标识需要占用1个字节。 如果VARCHAR类型的列有NOT NULL属性，那最多只能存储65533个字节的数据，因为真实数据的长度可能占用2个字节，不需要NULL值标识。 如果VARCHAR(M)类型的列使用的不是ascii字符集，那会怎么样呢？ 如果VARCHAR(M)类型的列使用的不是ascii字符集，那M的最大取值取决于该字符集表示一个字符最多需要的字节数。在列的值允许为NULL的情况下，gbk字符集表示一个字符最多需要2个字节，那在该字符集下，M的最大取值就是32766（也就是：65532/2），也就是说最多能存储32766个字符；utf8字符集表示一个字符最多需要3个字节，那在该字符集下，M的最大取值就是21844，就是说最多能存储21844（也就是：65532/3）个字符。 上述所言在列的值允许为NULL的情况下，gbk字符集下M的最大取值就是32766，utf8字符集下M的最大取值就是21844，这都是在表中只有一个字段的情况下说的，一定要记住一个行中的所有列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节！ 3.2 记录中的数据太多产生溢出MySQL中磁盘和内存交互的基本单位是页，也就是说MySQL是以页为基本单位来管理存储空间的，我们的记录都会被分配到某个页中存储。而一个页的大小一般是16KB，也就是16384字节，而一个VARCHAR(M)类型的列就最多可以存储65532个字节，这样就可能造成一个页存放不了一条记录的尴尬情况。 在Compact和Redundant行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的一部分数据，把剩余的数据分散存储在几个其他的页中，然后记录的真实数据处用20个字节存储指向这些页的地址（当然这20个字节中还包括这些分散在其他页面中的数据的占用的字节数），从而可以找到剩余数据所在的页。 从图中可以看出来，对于Compact和Redundant行格式来说，如果某一列中的数据非常多的话，在本记录的真实数据处只会存储该列的前768个字节的数据和一个指向其他页的地址，然后把剩下的数据存放到其他页中，这个过程也叫做行溢出，存储超出768字节的那些页面也被称为溢出页。画一个简图就是这样： 不只是 VARCHAR(M)类型的列，其他的 TEXT、BLOB 类型的列在存储数据非常多的时候也会发生行溢出。 3.3 行溢出的临界点发生行溢出的临界点是什么呢？也就是说在列存储多少字节的数据时就会发生行溢出？ MySQL中规定一个页中至少存放两行记录，至于为什么这么规定我们之后再说，现在看一下这个规定造成的影响。我们往表中插入亮条记录，每条记录最少插入多少字节的数据才会行溢出呢？ 分析一下页空间是如何利用的 每个页除了存放我们的记录以外，也需要存储一些额外的信息，乱七八糟的额外信息加起来需要132个字节的空间（现在只要知道这个数字就好了），其他的空间都可以被用来存储记录。 每个记录需要的额外信息是27字节。这27个字节包括下边这些部分： 内容 大小(字节) 真实数据的长度 2 列是否是NULL值 1 头信息 5 row_id 6 transaction_id 6 roll_pointer 7 因为表中具体有多少列不确定，所以没法确定具体的临界点，只需要知道插入的字段数据长度很大就会导致行溢出的现象。 4.Dynamic &amp; Compressed 行格式这俩行格式和Compact行格式挺像，只不过在处理行溢出数据时有点儿分歧，它们不会在记录的真实数据处存储字段真实数据的前768个字节，而是把所有的字节都存储到其他页面中，只在记录的真实数据处存储其他页面的地址，就像这样： Compressed行格式和Dynamic不同的一点是，Compressed行格式会采用压缩算法对页面进行压缩，以节省空间。 至此，行格式就分析的差不多了，接下来我们来看页的存储结构。 二，页的存储结构InnoDB为了不同的目的设计了许多种页，比如存放表空间头部信息的页，存放 Insert Buffer信息的页，存放Innode信息的页，存放undo日志信息的页等等。 本节分析存放表中记录的页，官方成为索引页，为了分析方便，我们暂且叫做数据页。 系统变量innodb_page_size表明了InnoDB存储引擎中的页大小，默认值是16384字节，也就是16kb。 该变量只能在第一次初始化MySQL数据目录时指定，之后就再也不能更改了。 数据页代表的这块16kb的存储空间被划分为多个部分，不同部分有不同的功能。 从图中可以看出，一个InnoDB数据页的存储空间大致被划分为了7个部分，有的部分占用的字节数是确定的，有的占用的字节数不是确定的。 名称 中文名 占用空间大小（字节） 简单描述 File Header 文件头部 38 页的一些通用信息 Page Header 页面头部 56 数据页专有的一些信息 Infifmum + Supremum 最小记录和最大记录 26 两个虚拟的行记录 User Records 用户记录 不确定 实际存储的行记录内容 Free Space 空闲空间 不确定 页中尚未使用的空间 Page Directory 页面目录 不确定 页中某些记录的相对位置 File Trailer 文件尾部 8 校验页是否完整 1. 记录在页中的存储我们先来创建一张表 1234567mysql&gt; create table page_demo( -&gt; c1 int , -&gt; c2 int , -&gt; c3 varchar(10000), -&gt; primary key(c1) -&gt; ) charset=ascii row_format=Compact;Query OK, 0 rows affected (0.03 sec) 因为我们指定了主键，所以存储实际数据的列里面不会有隐藏的row_id,我们来看一下他的行格式。 再次回顾下记录头中5个字节表示的数据。 名称 大小(bit) 描述 预留位1 1 没有使用 预留位2 1 没有使用 delete_mask 1 标记该记录是否被删除 min_rec_mask 1 B+树的每层非叶子节点中的最小记录都会添加该标记 n_owned 4 表示当前记录拥有的记录数 heap_no 13 表示当前记录在记录堆的位置信息 record_type 3 表示当前记录的类型 0 ：普通记录，1：B+树非页节点记录，2：最小记录，3：最大记录 next_record 16 下一条记录的相对位置 针对当前这个表的行格式简化图： 接下来我们往表中插入几条数据： 1INSERT INTO page_demo VALUES(1, 100, &#x27;aaaa&#x27;), (2, 200, &#x27;bbbb&#x27;), (3, 300, &#x27;cccc&#x27;), (4, 400, &#x27;dddd&#x27;); 为了分析这些记录在页的User Records 部分中是怎么表示的，把记录头信息和实际的列数据都用十进制表示出来了（其实是一堆二进制位），所以这些记录的示意图就是： 分析一下头信息中的每个属性是什么意思。 1.1 delete_mask标记当前记录是否被删除，占用1个二进制位，0：未删除，1：删除。 被删除的记录不会立即从磁盘上删除，因为删除他们之后吧其他的记录在磁盘上重新排列需要性能消耗，所以只是打一个删除标记，所有被删掉的数据会组成一个垃圾链表，在这个链表中的记录占用的空间成为可重用空间，之后如果有新的记录插入到表中，可能会把这些删除的记录覆盖掉。 将delete_mask 设置为1 和 将被删除的记录加入到垃圾链表中其实是两个阶段。 1.2 min_rec_maskB+树的每层非叶子节点中的最小记录都会添加该标记，如果这个字段的值是0，意味着不是B+树的非叶子节点中的最小记录。 1.3 n_owned1.4 heap_no这个属性表示当前记录在本页中的位置，我们插入的四条记录在本页中的位置分别是 2，3，4 ，5 。为什么不见 0 和 1 的记录呢？ 这是因为InnoDB自动给每个页里边加了两个记录，由于这两个记录并不是我们自己插入的，所以有时候也称为虚拟记录。这两个伪记录一个代表最小记录，一个代表最大记录。 记录是如何比较大小的？对于一条完整的记录来说，比较记录大小就是比较主键的大小。比方说我们插入的4行记录的主键值分别为1，2，3，4，这也就意味着这四条记录的大小从大到小递增。 但是不管我们往页中插入了多少自己的记录，InnoDB都规定他们定义的两条伪记录分别为最小记录和最大记录。这两条记录的构造十分简单，都是由5字节大小的记录头信息和8字节大小的一个固定的部分组成的。 由于这两条记录不是我们自己定义的记录，所以他们并不存放在页的User Records部分，他们被单独放在一个称为Infimum+Supremum的部分。 从图中我们可以看出来，最小记录和最大记录的heap_no值分别是0 和 1 ， 也就是说他们的位置最靠前。 1.5 record_type这个属性表示当前记录的类型。0：普通记录，1：B+树非叶子节点记录，2：最小记录，3：最大记录。 我们自己插入的记录是普通记录 0 ， 而最大记录和最小记录record_type 分别为 2 和 3。 1.6 next_record表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。这其实是一条链表，可以通过一条记录找到他的下一条记录，但是下一条记录指的并不是按照我们插入顺序的下一条记录，而是按照主键值由小到大的顺序的下一条记录。而且规定 infimum记录 的下一条记录就是本页主键值最小的用户记录，而本页中主键最大的用户记录的下一条记录就是supremum记录。 如果从中删除一条记录，这个链表也是会跟着变化的，假如现在删除第二条记录 1delete from page_demo where c1 =2 ; 删除第二条记录以后： 发生的变化： 第二条记录并没有从存储空间中移除，而是把该记录的delete_mask设置为1 第二条记录的next_records值变成了0，意味着该记录没有下一条记录了 第一条记录的next record指向了第三条记录 最大记录的 n_owned 值从5 变成了4 所以，不论我们怎么对页中的记录做增删改查操作，InnoDB始终会维护一条记录的单链表，链表中各个节点是按照主键值由小到大的顺序连接起来的。 next_records 为啥要指向记录头信息和真实数据之间的位置呢？为啥不干脆指向整条记录的开头位置，也就是记录的额外信息开头的位置呢？ 因为这个位置刚刚好，向左读取就是记录头信息，向右读取就是真实数据。我们前边还说过变长字段长度列表，null值列表中的信息都是逆序存放的，这样可以使记录中位置靠前的字段和他们对应的字段长度信息在内存中的距离更近，可能会提高高速缓存的命中率。 因为主键值为2的记录已经被我们删除了，但是存储空间并没有回收，如果再次把这条记录插入到表中，会发生什么？ 1INSERT INTO page_demo VALUES(2, 200, &#x27;bbbb&#x27;); 从图中可以看到，InnoDB并没有因为新记录的插入而为他申请新的存储空间，而是直接复用了原来删除的记录的存储空间。 2. Page Directory（页目录）如果我们想根据主键值查找页中某条记录该咋办？ 1select * from page_demo where c1 = 3; 将所有正常的记录(包括两条隐藏记录但是不包括已经标记为删除的记录)划分为几组 每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的n_owned属性表示该组拥有多少条记录 将每个组的最后一条记录的地址偏移量单独提取出来按照顺序存储到靠近页的尾部的地方，这个地方就是所谓的【Page Directory】,也就是页目录。页目录中的这些地址偏移量被称为槽，所以页目录就是由槽组成的 比方说刚才创建的表中正常的记录由6条，InnoDB会把他们分成两组，第一组中只有一条最小记录，第二组中是剩余的5条记录。 现在页目录部分中有两个槽，也就意味着我们的记录被分成了两个组，槽1中的值为112，代表最大记录的地址偏移量；槽0的值为99，代表最小记录的地址偏移量。 注意最大和最小记录的头信息的n_owned属性： 最小记录中的n_owned值为1，这就代表着以最小记录结尾的这个分组中只有1条记录，也就是最小记录本身 最大记录中的n_owned值为5，这就代表着以最大记录结尾的这个分组中只有5条记录，包括最大记录本身还有我们自己插入的4条记录 【99】&amp;【112】这样的地址偏移量很不直观，我们用箭头指向的方式替代数字。 InnoDB对每个分组中的记录条数是有规定的：对于最小记录所在的分组只能有 1 条记录，最大记录所在的分组拥有的记录条数只能在 1~8 条之间，剩下的分组中记录的条数范围只能在是 4~8 条之间。所以分组是按照下边的步骤进行的： 初始情况下一个数据页里只有最小记录和最大记录两条记录，它们分属于两个分组。 之后每插入一条记录，都会从页目录中找到主键值比本记录的主键值大并且差值最小的槽，然后把该槽对应的记录的n_owned值加1，表示本组内又添加了一条记录，直到该组中的记录数等于8个。 在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中4条记录，另一个5条记录。这个过程会在页目录中新增一个槽来记录这个新增分组中最大的那条记录的偏移量。 由于现在page_demo表中的记录太少，无法演示添加了页目录之后加快查找速度的过程，所以再往page_demo表中添加一些记录： 1INSERT INTO page_demo VALUES(5, 500, &#x27;eeee&#x27;), (6, 600, &#x27;ffff&#x27;), (7, 700, &#x27;gggg&#x27;), (8, 800, &#x27;hhhh&#x27;), (9, 900, &#x27;iiii&#x27;), (10, 1000, &#x27;jjjj&#x27;), (11, 1100, &#x27;kkkk&#x27;), (12, 1200, &#x27;llll&#x27;), (13, 1300, &#x27;mmmm&#x27;), (14, 1400, &#x27;nnnn&#x27;), (15, 1500, &#x27;oooo&#x27;), (16, 1600, &#x27;pppp&#x27;); 现在看怎么从这个页目录中查找记录。因为各个槽代表的记录的主键值都是从小到大排序的，所以我们可以使用所谓的二分法来进行快速查找。5个槽的编号分别是：0、1、2、3、4，所以初始情况下最低的槽就是low=0，最高的槽就是high=4。比方说我们想找主键值为6的记录，过程是这样的： 计算中间槽的位置：(0+4)/2=2，所以查看槽2对应记录的主键值为8，又因为8 &gt; 6，所以设置high=2，low保持不变。 重新计算中间槽的位置：(0+2)/2=1，所以查看槽1对应的主键值为4，又因为4 &lt; 6，所以设置low=1，high保持不变。 因为high - low的值为1，所以确定主键值为6的记录在槽2对应的组中。此刻我们需要找到槽2中主键值最小的那条记录，然后沿着单向链表遍历槽2中的记录。但是我们前边又说过，每个槽对应的记录都是该组中主键值最大的记录，这里槽2对应的记录是主键值为8的记录，怎么定位一个组中最小的记录呢？别忘了各个槽都是挨着的，我们可以很轻易的拿到槽1对应的记录（主键值为4），该条记录的下一条记录就是槽2中主键值最小的记录，该记录的主键值为5。所以我们可以从这条主键值为5的记录出发，遍历槽2中的各条记录，直到找到主键值为6的那条记录即可。由于一个组中包含的记录条数只能是1~8条，所以遍历一个组中的记录的代价是很小的。 所以在一个数据页中查找指定主键值的记录的过程分为两步： 通过二分法确定该记录所在的槽，并找到该槽所在分组中主键值最小的那条记录。 通过记录的next_record属性遍历该槽所在的组中的各个记录。 3.Page Header（页面头部）为了能得到一个数据页中存储的记录的状态信息，比如本页中已经存储了多少条记录，第一条记录的地址是什么，页目录中存储了多少个槽等等，特意在页中定义了一个叫Page Header的部分，它是页结构的第二部分，这个部分占用固定的56个字节，专门存储各种状态信息。 名称 占用空间大小（字节） 描述 PAGE_N_DIR_SLOTS 2 在页目录中的槽数量 PAGE_HEAP_TOP 2 还未使用的空间最小地址，也就是说从该地址之后就是Free Space PAGE_N_HEAP 2 本页中的记录的数量（包括最小和最大记录以及标记为删除的记录） PAGE_FREE 2 第一个已经标记为删除的记录地址（各个已删除的记录通过next_record也会组成一个单链表，这个单链表中的记录可以被重新利用） PAGE_GARBAGE 2 已删除记录占用的字节数 PAGE_LAST_INSERT 2 最后插入记录的位置 PAGE_DIRECTION 2 记录插入的方向 PAGE_N_DIRECTION 2 一个方向连续插入的记录数量 PAGE_N_RECS 2 该页中记录的数量（不包括最小和最大记录以及被标记为删除的记录） PAGE_MAX_TRX_ID 8 修改当前页的最大事务ID，该值仅在二级索引中定义 PAGE_LEVEL 2 当前页在B+树中所处的层级 PAGE_INDEX_ID 8 索引ID，表示当前页属于哪个索引 PAGE_BTR_SEG_LEAF 10 B+树叶子段的头部信息，仅在B+树的Root页定义 PAGE_BTR_SEG_TOP 10 B+树非叶子段的头部信息，仅在B+树的Root页定义 4.File Header（文件头部）File Header针对各种类型的页都通用，也就是说不同类型的页都会以File Header作为第一个组成部分，它描述了一些针对各种页都通用的一些信息，比方说这个页的编号是多少，它的上一个页、下一个页是谁，这个部分占用固定的38个字节。 名称 占用空间大小（字节） 描述 FIL_PAGE_SPACE_OR_CHKSUM 4 页的校验和（checksum值） FIL_PAGE_OFFSET 4 页号 FIL_PAGE_PREV 4 上一个页的页号 FIL_PAGE_NEXT 4 下一个页的页号 FIL_PAGE_LSN 8 页面被最后修改时对应的日志序列位置（英文名是：Log Sequence Number） FIL_PAGE_TYPE 2 该页的类型 FIL_PAGE_FILE_FLUSH_LSN 8 仅在系统表空间的一个页中定义，代表文件至少被刷新到了对应的LSN值 FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID 4 页属于哪个表空间 InnoDB为了不同的目的而把页分为不同的类型，我们上边介绍的其实都是存储记录的数据页，其实还有很多别的类型的页，具体如下表： 类型名称 十六进制 描述 FIL_PAGE_TYPE_ALLOCATED 0x0000 最新分配，还没使用 FIL_PAGE_UNDO_LOG 0x0002 Undo日志页 FIL_PAGE_INODE 0x0003 段信息节点 FIL_PAGE_IBUF_FREE_LIST 0x0004 Insert Buffer空闲列表 FIL_PAGE_IBUF_BITMAP 0x0005 Insert Buffer位图 FIL_PAGE_TYPE_SYS 0x0006 系统页 FIL_PAGE_TYPE_TRX_SYS 0x0007 事务系统数据 FIL_PAGE_TYPE_FSP_HDR 0x0008 表空间头部信息 FIL_PAGE_TYPE_XDES 0x0009 扩展描述页 FIL_PAGE_TYPE_BLOB 0x000A 溢出页 FIL_PAGE_INDEX 0x45BF 索引页，也就是我们所说的数据页 我们存放记录的数据页的类型其实是FIL_PAGE_INDEX，也就是所谓的索引页。 有时候我们存放某种类型的数据占用的空间非常大（比方说一张表中可以有成千上万条记录），InnoDB可能不可以一次性为这么多数据分配一个非常大的存储空间，如果分散到多个不连续的页中存储的话需要把这些页关联起来，FIL_PAGE_PREV和FIL_PAGE_NEXT就分别代表本页的上一个和下一个页的页号。这样通过建立一个双向链表把许许多多的页就都串联起来了，而无需这些页在物理上真正连着。需要注意的是，并不是所有类型的页都有上一个和下一个页的属性，不过我们现在分析的数据页（也就是类型为FIL_PAGE_INDEX的页）是有这两个属性的，所以所有的数据页其实是一个双链表。 5.File Trailer(文件尾部)如果页中的数据在内存中被修改了，那么在修改后的某个时间需要把数据同步到磁盘中。但是在同步了一半的时候中断电了咋办？ 为了检测一个页是否完整，在每个页的尾部都加了一个File Trailer部分，这个部分由8个字节组成，可以分成2个小部分： 前四个字节代表校验和 后四个字节代表页面被最后修改时对应的日志序列位置 这个File Trailer &amp; File Header 类似，都是所有类型的页通用的。 至此，整个数据页的结构我们也基本上分析完了，现在在回头看一下开头我们那张恐怖的图，是不是感觉清晰很多了呢？接下来，我们来分析索引的结构。 三，索引1.假如没有索引我们先来看看没有索引的情况下，我们进行数据的查找(毕竟没有对比就没有伤害)。 1.1 在一个页中查找假设表中的记录很少，所有的记录仅仅用一个页就存放下了，这个时候按照不同的搜索条件其实可以分为两种情况讨论： 【以主键为搜索的条件】：可以再页目录中根据二分查找快速定位到槽，在根据槽定位到该组的最小索引记录，然后进行遍历匹配查找。 【以其他列作为搜索条件】：在数据页中并没有为非主键列建立所谓的页目录，所以无法通过二分法快速定位相应的槽。在这种情况下，只能从最小记录开始依次往后遍历单链表中的每条记录，然后对比每条记录是否符合搜索条件，显然，效率很低。 1.2 在很多页中查找很多时候，表的记录一个页都是存储不下的，这个时候的查找其实分为两个步骤： 【定位到记录所在的页】 【从所在的页内查找相应的记录】 因为我们不能快速的定位到所在的页，所以只能从第一页开始沿着双链表往后遍历定位页，定位到页以后在根据在一个页中的查找方式进行匹配查找，显而易见，这个时候效率低的可怕。 有了痛点，就会有大牛去思考整个生命周期，完善逻辑和资源倾斜，形成一套自己的方法论，想办法为快速查找赋能。 2. 索引我们先创建一张表： 1234567mysql&gt; CREATE TABLE index_demo( -&gt; c1 INT, -&gt; c2 INT, -&gt; c3 CHAR(1), -&gt; PRIMARY KEY(c1) -&gt; ) ROW_FORMAT = Compact;Query OK, 0 rows affected (0.03 sec) 2.1 一个简单的索引方案我们在根据某个搜索条件查找一些记录时为什么要遍历所有的数据页呢？ 因为各个页中的记录并没有规律，我们并不知道我们的搜索条件匹配哪些页中的记录，所以 不得不 依次遍历所有的数据页。 如果我们想快速的定位到需要查找的记录在哪些数据页中该咋办？ 对比根据主键值快速定位一条记录从而在页中的位置建立页目录，我们也可以想办法为快速定位记录所在的数据页而建立一个别的目录。 【下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值。】 假设我们现在每一页只能放三条记录，现在已经放了主键为1,3,5的三条记录。这个时候我们再添加一条主键为4的记录，我们不得不为他分配一个新的页。 注意：新分配的数据页编号可能和原来并不是连续的，也就是说我们使用的这些页在存储空间里可能并不挨着。他们只是通过维护着上一页和下一页的编号而建立了链表关系。 原来页中主键最大的值为5，现在我们新插入一条记录，如果直接放在新页里面，那就会有问题，这不符合下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值得要求，所以在插入主键值为4 的记录的时候需要伴随一次记录的移动，也就是把主键值为5 的记录移动到新分配的页中，然后把主键值为4 的记录插入到原来的页中。 这个过程表明了在对页中的记录进行增删改操作的过程中，我们必须通过一些诸如记录移动的操作来始终保证这个状态一直成立：下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值。这个过程我们也可以称为页分裂。 【给所有的页建立一个目录项。】 由于数据页的编号可能并不是连续的，所以在向index_demo表中插入许多条记录后，可能是这样的效果： 因为这些16KB的页在物理存储上可能并不挨着，所以如果想从这么多页中根据主键值快速定位某些记录所在的页，我们需要给它们做个目录，每个页对应一个目录项，每个目录项包括下边两个部分： 页的用户记录中最小的主键值，我们用key来表示。 页号，我们用page_no表示。 以页28为例，它对应目录项2，这个目录项中包含着该页的页号28以及该页中用户记录的最小主键值5。我们只需要把几个目录项在物理存储器上连续存储，比如把他们放到一个数组里，就可以实现根据主键值快速查找某条记录的功能了。比方说我们想找主键值为20的记录，具体查找过程分两步： 先从目录项中根据二分法快速确定出主键值为20的记录在目录项3中（因为 12 &lt; 20 &lt; 209），它对应的页是页9。 再根据前边说的在页中查找记录的方式去页9中定位具体的记录。 至此，针对数据页做的简易目录就搞定了。这个目录其实就是【索引】。 2.2 InnoDB中的索引方案上面的方案存在什么样的问题？ InnoDB是使用页来作为管理存储空间的基本单位，也就是最多能保证16KB的连续存储空间，而随着表中记录数量的增多，需要非常大的连续的存储空间才能把所有的目录项都放下，这对记录数量非常多的表是不现实的。 我们时常会对记录进行增删，假设我们把页28中的记录都删除了，页28也就没有存在的必要了，那意味着目录项2也就没有存在的必要了，这就需要把目录项2后的目录项都向前移动一下。 InnoDB复用了之前存储用户记录的数据页来存储目录项，为了和用户记录做一下区分，我们把这些用来表示目录项的记录称为目录项记录。 那InnoDB怎么区分一条记录是普通的用户记录还是目录项记录呢？通过记录头信息里的record_type属性，它的各个取值代表的意思如下： 0：普通的用户记录 **1**：目录项记录 2：最小记录 3：最大记录 把前边使用到的目录项放到数据页中的样子就是这样： 从图中可以看出来，我们新分配了一个编号为30的页来专门存储目录项记录。这里再次强调一遍目录项记录和普通的用户记录的不同点： 目录项记录的record_type值是1，而普通用户记录的record_type值是0。 目录项记录只有主键值和页的编号两个列，而普通的用户记录的列是用户自己定义的，可能包含很多列，另外还有InnoDB自己添加的隐藏列。 头信息里面有一个叫min_rec_mask的属性，只有在存储目录项记录的页中的主键值最小的目录项记录的min_rec_mask值为1，其他别的记录的min_rec_mask值都是0。 除此之外，两者就没有区别了，页的组成结构也是一样一样的（就是我们前边介绍过的7个部分），都会为主键值生成Page Directory（页目录），从而在按照主键值进行查找时可以使用二分法来加快查询速度。 现在以查找主键为20的记录为例，根据某个主键值去查找记录的步骤就可以大致拆分成下边两步： 先到存储目录项记录的页，也就是页30中通过二分法快速定位到对应目录项，因为12 &lt; 20 &lt; 209，所以定位到对应的记录所在的页就是页9。 再到存储用户记录的页9中根据二分法快速定位到主键值为20的用户记录。 虽然说目录项记录中只存储主键值和对应的页号，比用户记录需要的存储空间小多了，但是不论怎么说一个页只有16KB大小，能存放的目录项记录也是有限的，那如果表中的数据太多，以至于一个数据页不足以存放所有的目录项记录，该咋办呢？ 当然是再多整一个存储**目录项记录**的页。 从图中可以看出，我们插入了一条主键值为320的用户记录之后需要两个新的数据页： 为存储该用户记录而新生成了页31。 因为原先存储目录项记录的页30的容量已满（我们前边假设只能存储4条目录项记录），所以不得不需要一个新的页32来存放页31对应的目录项。 现在因为存储目录项记录的页不止一个，所以如果我们想根据主键值查找一条用户记录大致需要3个步骤，以查找主键值为20的记录为例： 确定目录项记录页 我们现在的存储目录项记录的页有两个，即页30和页32，又因为页30表示的目录项的主键值的范围是[1, 320)，页32表示的目录项的主键值不小于320，所以主键值为20的记录对应的目录项记录在页30中。 通过目录项记录页确定用户记录真实所在的页。 在真实存储用户记录的页中定位到具体的记录。 那么问题来了，在这个查询步骤的第1步中我们需要定位存储目录项记录的页，但是这些页在存储空间中也可能不挨着，如果我们表中的数据非常多则会产生很多存储目录项记录的页，那我们怎么根据主键值快速定位一个存储目录项记录的页呢？ 为这些存储目录项记录的页再生成一个更高级的目录，就像是一个多级目录一样，大目录里嵌套小目录，小目录里才是实际的数据，所以现在各个页的示意图就是这样子： 随着表中记录的增加，这个目录的层级会继续增加，如果简化一下，那么我们可以用下边这个图来描述它： 其实这是一种组织数据的形式，或者说是一种数据结构，它的名称是B+树。 不论是存放用户记录的数据页，还是存放目录项记录的数据页，我们都把它们存放到B+树这个数据结构中了，所以我们也称这些数据页为节点。从图中可以看出来，我们的实际用户记录其实都存放在B+树的最底层的节点上，这些节点也被称为叶子节点或叶节点，其余用来存放目录项的节点称为非叶子节点或者内节点，其中B+树最上边的那个节点也称为根节点。 从图中可以看出来，一个B+树的节点其实可以分成好多层，InnoDB规定最下边的那层，也就是存放我们用户记录的那层为第0层，之后依次往上加。之前的分析我们做了一个非常极端的假设：存放用户记录的页最多存放3条记录，存放目录项记录的页最多存放4条记录。其实真实环境中一个页存放的记录数量是非常大的，假设所有存放用户记录的叶子节点代表的数据页可以存放100条用户记录，所有存放目录项记录的内节点代表的数据页可以存放1000条目录项记录，那么： 如果B+树只有1层，也就是只有1个用于存放用户记录的节点，最多能存放100条记录。 如果B+树有2层，最多能存放1000×100=100000条记录。 如果B+树有3层，最多能存放1000×1000×100=100000000条记录。 如果B+树有4层，最多能存放1000×1000×1000×100=100000000000条记录。 一般情况下，我们用到的B+树都不会超过4层，那我们通过主键值去查找某条记录最多只需要做4个页面内的查找（查找3个目录项页和一个用户记录页），又因为在每个页面内有所谓的Page Directory（页目录），所以在页面内也可以通过二分法实现快速定位记录。 2.3 聚簇索引上边介绍的B+树本身就是一个目录，或者说本身就是一个索引。它有两个特点： 使用记录主键值的大小进行记录和页的排序，这包括三个方面的含义： 页内的记录是按照主键的大小顺序排成一个单向链表。 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表。 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个双向链表。 B+树的叶子节点存储的是完整的用户记录。所谓完整的用户记录，就是指这个记录中存储了所有列的值（包括隐藏列）。 我们把具有这两种特性的B+树称为聚簇索引，所有完整的用户记录都存放在这个聚簇索引的叶子节点处。这种聚簇索引并不需要我们在MySQL语句中显式的使用INDEX语句去创建，InnoDB存储引擎会自动的为我们创建聚簇索引。另外，在InnoDB存储引擎中，聚簇索引就是数据的存储方式（所有的用户记录都存储在了叶子节点），也就是所谓的索引即数据，数据即索引。 2.4 二级索引聚簇索引只能在搜索条件是主键值时才能发挥作用，因为B+树中的数据都是按照主键进行排序的。那如果我们想以别的列作为搜索条件怎么办？ 我们可以多建几棵B+树，不同的B+树中的数据采用不同的排序规则。比方说我们用c2列的大小作为数据页、页中记录的排序规则，再建一棵B+树，效果如下图所示： 这个B+树与上边介绍的聚簇索引有几处不同： 使用记录c2列的大小进行记录和页的排序，这包括三个方面的含义： 页内的记录是按照c2列的大小顺序排成一个单向链表。 各个存放用户记录的页也是根据页中记录的c2列大小顺序排成一个双向链表。 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的c2列大小顺序排成一个双向链表。 B+树的叶子节点存储的并不是完整的用户记录，而只是c2列+主键这两个列的值。 目录项记录中不再是主键+页号的搭配，而变成了c2列+页号的搭配。 所以如果我们现在想通过c2列的值查找某些记录的话就可以使用我们刚刚建好的这个B+树了。以查找c2列的值为4的记录为例，查找过程如下： 确定目录项记录页 根据根页面，也就是页44，可以快速定位到目录项记录所在的页为页42（因为2 &lt; 4 &lt; 9）。 通过目录项记录页确定用户记录真实所在的页。 在页42中可以快速定位到实际存储用户记录的页，但是由于c2列并没有唯一性约束，所以c2列值为4的记录可能分布在多个数据页中，又因为2 &lt; 4 ≤ 4，所以确定实际存储用户记录的页在页34和页35中。 在真实存储用户记录的页中定位到具体的记录. 到页34和页35中定位到具体的记录。 但是这个B+树的叶子节点中的记录只存储了c2和c1（也就是主键）两个列，所以我们必须再根据主键值去聚簇索引中再查找一遍完整的用户记录。 我们根据这个以**c2**列大小排序的**B+**树只能确定我们要查找记录的主键值，所以如果我们想根据**c2**列的值查找到完整的用户记录的话，仍然需要到**聚簇索引**中再查一遍，这个过程也被称为**回表**。也就是根据c2列的值查询一条完整的用户记录需要使用到2棵B+树！！！ 为什么我们还需要一次回表操作呢？直接把完整的用户记录放到叶子节点不就好了么？ 如果把完整的用户记录放到叶子节点是可以不用回表，相当于每建立一棵B+树都需要把所有的用户记录再都拷贝一遍，这就有点太浪费存储空间了。因为这种按照非主键列建立的B+树需要一次回表操作才可以定位到完整的用户记录，所以这种B+树也被称为二级索引（英文名secondary index），或者辅助索引。由于我们使用的是c2列的大小作为B+树的排序规则，所以我们也称这个B+树为为c2列建立的索引。 假设我们的查询结果是十条，那就是要进行10次回表，那这样的话，效率不是又慢了？ 在MySQL5.6对这种情况进行了优化，如果发现查询结果会导致多次回表，那么就会进行IO合并，拿到所有的主键再去进行回表。 2.5 联合索引我们也可以同时以多个列的大小作为排序规则，也就是同时为多个列建立索引，比方说我们想让B+树按照c2和c3列的大小进行排序，这个包含两层含义： 先把各个记录和页按照c2列进行排序。 在记录的c2列相同的情况下，采用c3列进行排序 为c2和c3列建立的索引的示意图如下： 3. InnoDB的B+树索引的注意事项3.1 跟页面永远固定不动前边介绍B+树索引的时候，为了理解上的方便，先把存储用户记录的叶子节点都画出来，然后接着画存储目录项记录的内节点，实际上B+树的形成过程是这样的： 每当为某个表创建一个B+树索引（聚簇索引不是人为创建的，默认就有）的时候，都会为这个索引创建一个根节点页面。最开始表中没有数据的时候，每个B+树索引对应的根节点中既没有用户记录，也没有目录项记录。 随后向表中插入用户记录时，先把用户记录存储到这个根节点中。 当根节点中的可用空间用完时继续插入记录，此时会将根节点中的所有记录复制到一个新分配的页，比如页a中，然后对这个新页进行页分裂的操作，得到另一个新页，比如页b。这时新插入的记录根据键值（也就是聚簇索引中的主键值，二级索引中对应的索引列的值）的大小就会被分配到页a或者页b中，而根节点便升级为存储目录项记录的页。 这个过程需要特别注意的是：一个B+树索引的根节点自诞生之日起，便不会再移动。这样只要我们对某个表建立一个索引，那么它的根节点的页号便会被记录到某个地方，然后凡是InnoDB存储引擎需要用到这个索引的时候，都会从那个固定的地方取出根节点的页号，从而来访问这个索引。 3.2 内节点中目录项记录的唯一性我们知道B+树索引的内节点中目录项记录的内容是索引列 + 页号的搭配，但是这个搭配对于二级索引来说有点儿不严谨。假设表中的数据是这样的： c1 c2 c3 1 1 ‘u’ 3 1 ‘d’ 5 1 ‘y’ 7 1 ‘a’ 如果二级索引中目录项记录的内容只是索引列 + 页号的搭配的话，那么为c2列建立索引后的B+树应该长这样： 如果我们想新插入一行记录，其中c1、c2、c3的值分别是：9、1、&#39;c&#39;，那么在修改这个为c2列建立的二级索引对应的B+树时便碰到了个大问题：由于页3中存储的目录项记录是由c2列 + 页号的值构成的，页3中的两条目录项记录对应的c2列的值都是1，而我们新插入的这条记录的c2列的值也是1，那我们这条新插入的记录到底应该放到页4中，还是应该放到页5中? 为了让新插入记录能找到自己在那个页里，我们需要保证在B+树的同一层内节点的目录项记录除页号这个字段以外是唯一的。所以对于二级索引的内节点的目录项记录的内容实际上是由三个部分构成的： 索引列的值 主键值 页号 也就是我们把主键值也添加到二级索引内节点中的目录项记录了，这样就能保证B+树每一层节点中各条目录项记录除页号这个字段外是唯一的。 这样我们再插入记录(9, 1, &#39;c&#39;)时，由于页3中存储的目录项记录是由c2列 + 主键 + 页号的值构成的，可以先把新记录的c2列的值和页3中各目录项记录的c2列的值作比较，如果c2列的值相同的话，可以接着比较主键值，因为B+树同一层中不同目录项记录的c2列 + 主键的值肯定是不一样的，所以最后肯定能定位唯一的一条目录项记录，在本例中最后确定新记录应该被插入到页5中。 3.3 一个页面最少存储2条记录B+树只需要很少的层级就可以轻松存储数亿条记录，这是因为B+树本质上就是一个大的多层级目录，每经过一个目录时都会过滤掉许多无效的子目录，直到最后访问到存储真实数据的目录。那如果一个大的目录中只存放一个子目录会怎么样？那就是目录层级非常多，而且最后的那个存放真实数据的目录中只能存放一条记录，会导致效率很低。 其实让B+数的叶子结点值存储一条记录，让内节点存储多条记录，也还是可以发挥B+数的作用的。但是InnoDB为了避免数的层级过高，要求所有的数据页都至少可以容纳两条记录。 4. MyISAM中的索引方案简单介绍MyISAM的索引方案虽然也使用树形结构，但是却将索引和数据分开存储： 将表中的记录按照记录的插入顺序单独存储在一个文件中，称之为数据文件。这个文件并不划分为若干个数据页，有多少记录就往这个文件中塞多少记录就成了。我们可以通过行号而快速访问到一条记录。 使用MyISAM存储引擎的表会把索引信息另外存储到一个称为索引文件的另一个文件中。MyISAM会单独为表的主键创建一个索引，只不过在索引的叶子节点中存储的不是完整的用户记录，而是主键值 + 行号的组合。也就是先通过索引找到对应的行号，再通过行号去找对应的记录！这一点和InnoDB是完全不相同的，在InnoDB存储引擎中，我们只需要根据主键值对聚簇索引进行一次查找就能找到对应的记录，而在MyISAM中却需要进行一次回表操作，意味着MyISAM中建立的索引相当于全部都是二级索引！ 如果有需要的话，我们也可以对其它的列分别建立索引或者建立联合索引，原理和InnoDB中的索引差不多，不过在叶子节点处存储的是相应的列 + 行号。这些索引也全部都是二级索引。 由于在插入数据的时候并没有刻意按照主键大小排序，所以我们并不能在MyIsaM数据上使用二分法进行查找。 5. 创建和删除索引的语句InnoDB和MyISAM会自动为主键或者声明为UNIQUE的列去自动建立B+树索引，但是如果我们想为其他的列建立索引就需要我们显式的去指明。 我们可以在创建表的时候指定需要建立索引的单个列或者建立联合索引的多个列： 1234CREATE TALBE 表名 ( 各种列的信息 ··· , [KEY|INDEX] 索引名 (需要被索引的单个列或多个列)) 我们也可以在修改表结构的时候添加索引： 1ALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的单个列或多个列); 也可以在修改表结构的时候删除索引： 1ALTER TABLE 表名 DROP [INDEX|KEY] 索引名; 至此，整个索引相关的结构我们就都分析完了。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[一]入门","slug":"MySQL/MySQL[一]入门","date":"2022-01-11T02:49:27.263Z","updated":"2022-01-11T03:14:44.975Z","comments":true,"path":"2022/01/11/MySQL/MySQL[一]入门/","link":"","permalink":"https://yinhuidong.github.io/2022/01/11/MySQL/MySQL[%E4%B8%80]%E5%85%A5%E9%97%A8/","excerpt":"","text":"一，MYSQL入门1.数据库相关概念123DB：数据库：存储数据的仓库，保存了一系列有组织的数据。DBMS：数据库管理系统：数据库是通过DBMS创建和操作的容器。SQL：结构化查询语言：专门用来与数据库通信的语言。 2.数据库的好处121.可以持久化数据到本地2.可以实现结构化查询，方便管理 3.数据库存储数据特点12345671.将数据放到表中，表放到库中。2.一个数据库有多张表，每个表都有一个名字，用来标识自己。表名具有唯一性。3.表具有一些特性，这些特性定义了数据在表中如何存储，类似Java中类的设计。4.表有列组成，我们也称为字段。所有表都是由一个列或多个列组成的，每一列类似Java中的属性。5.表中的数据按照行来存储，每一行类似于Java中的对象。 4.mysql的安装与使用参照mysql安装文档 5.Mysql常用命令12345678910111213141516171819显示数据库-----&gt;show Databases;使用数据库-----&gt;use 数据库名；显示表----&gt;show tables;显式指定数据库的表----&gt;show tables from 数据库名；查看位于那个数据库----&gt;select database();显示表结构---&gt;desc 表名；查看数据库版本：---&gt;select version();查看数据库版本2:-----&gt;Dos:mysql --version;查看数据库信息-----&gt;show CREATE DATABASE mydb1;查看服务器中的数据库，并把mydb1的字符集修改为utf-8-----&gt;ALTER DATABASE mydb1character set utf8;删除数据库-----&gt;drop database mydb1;表中增加一栏信息-----&gt;alter table student add image blob;删除表-----&gt;drop table student;修改地址-----&gt;alter table student modify address varchar(100);删除一个属性-----&gt; alter table student drop image;修改表名-----&gt;rename table student to students;查看表的创建细节-----&gt;show create table students;修改表的字符集为 gbk-----&gt;alter table students character set gbk;列名name修改为studentname-----&gt;alter table students change name studentname varchar(100); 6.mysql语法规范12345671.不区分大小写，建议关键字大写，表名列名小写。2.每条命令最好用分号结尾。3.每条语句可以缩进，换行。4.注释单行注释：#注释文字 -- 注释文字多行注释：/* */ 二，DQL查询语言1.基础查询12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758**语法： select 查询列表 from 表名****查询列表：表中的字段，常量，表达式，函数****查询的结果是张虚拟的表格**1.查询表中的单个字段select last_name from employee;2.查询表中的多个字段select last_name,salary,email from employee;3.查询表中的所有字段select * from employee;4.查询常量值select 100;select &#x27;john&#x27;;5.查询表达式select 100*98;6.查询函数select version();7.起别名select last_name as name from employee;select last_name name from employee;8.去重查询员工表中涉及到的所有的部门编号select distinct department_id from employee;9.+的作用#运算符：两个操作数都为数值型，则做加法运算；#其中一方为字符型，试图将字符型数值转换成数值型，#如果转换成功，继续做加法运算；否则，将字符型数值#转换为0；10.使用concat实现连接#案例：查询员工名和性连接成一个字段SELECT CONCAT(username,PASSWORD) FROM USER;#任何数与null做运算结果都为null 2.条件查询语法： select 查询列表 from 表名 where 筛选条件 分类： ①按照条件表达式筛选条件运算符：&gt;,&lt;,=,!=,&gt;=,&lt;= 123456查询员工工资&gt;1w2的员工信息select * from employee where salary &gt;12000;查询部门编号！=90号的员工名和部门编号select name, dep_id from employee where dep_id 1=90； ②按照逻辑表达式筛选逻辑运算符：&amp;&amp;,||,!,AND,OR,NOT 1234查询工资在一万到两万之见的员工名，工资以及奖金。select name,salary ,jiangjin where salary between 10000 and 20000;查询部门编号不在90-110之间，或者工资高于15000的员工信息。select * from employee where department&lt;90||department&gt;110 ||salary &gt;15000; ③模糊查询like：一般和通配符搭配使用通配符：%任意多个字符，包含0个字符_任意单个字符BETWEEN AND:包含临界值IN:判断某个字段的值是否属于in列表中的某一项IS NULL,IS NOT NULL:=或者！=不能用来判断null安全等于&lt;=&gt;可以判断null 123456789101112131415查询员工名中包含a的员工信息select * from emp where name like %a%;查询员工名中第三个字符为e第五个字符为a的员工名和工资select name ,salary from emp where name like %__e_a%;员工名中第二个字符为_的员工名select name from emp where name like %_\\_%;查询员工编号在100到120之间的所有员工信息select * from emp where id between 100 and 120;查询员工的工种编号是IT_PRIG,AD_PRES,AD_VP中的一个员工名和工种编号；select name , id from emp where id in(IT_PRIG,AD_PRES,AD_VP);查询没有奖金的员工名和奖金率select salary , jjl from emp where salary is Null;查询有奖金的员工名和奖金率select salary ,jjl from emp where salary is not null; ④IF null的使用：123查询员工号为176的员工的姓名和部门号和年薪SELECT last_name ,department_id , salary*(1+IFNULL(commission_pct,0))*12 &#x27;年薪&#x27;FROM employees WHERE employee_id =176; 3.排序查询语法： select 查询列表 from 表 where 筛选条件 order by 排序列表 asc 或desc （升序或者降序，默认为升序） 12345678910查询员工信息，要求工资从高到低排序select * from emp order by salary desc;查询部门编号大于等于90的员工信息，按照入职时间先后排序select * from emp where dep_id &gt;=90 order by createtime asc;按照员工年薪的高低显示员工的信息和年薪select * ,年薪 from emp order by salary*(1+if null(jjl,0))*12 as 年薪 desc;按姓名长度显示员工的姓名和工资select name ,salary from emp order by length(name) asc;查询员工信息，先按照工资排序，再按照员工编号排序select * from emp order by salary asc,id asc; 4.常见函数功能：类似Java中的方法分类：单行函数分组函数 1.单行函数1.字符函数12345678910111213141516171819202122232425262728293031323334353637381.length 获取参数值的字节个数select * from emp order by length(name);2.concat 拼接字符串select concat(last_name,first_name) as 姓名 from emp;3.upper，lower 大小写转换函数案例：将姓变大写，名字变小写，然后拼接SELECT CONCAT(UPPER(last_name),LOWER(first_name))FROM employees;4.substr,SUBSTRING 截取字符串SELECT SUBSTR(&#x27;李莫愁&#x27;,2);SELECT SUBSTR(&#x27;李莫愁&#x27;,2,3);案例：姓名中首字符大写，其他的小写然后用_拼接显示出来SELECT CONCAT( UPPER(SUBSTR(last_name, 1, 1)), &#x27;_&#x27;, LOWER(SUBSTR(last_name, 2)) ) output FROM employees ;5.instr:返回字串第一次出现的索引，如果找不到返回0SELECT INSTR(&#x27;风急天高猿啸哀&#x27;,&#x27;天&#x27;) AS out_put;6.trim :去掉前后空格或前后指定字符SELECT LENGTH(TRIM(&#x27; 张三丰 &#x27;)) AS out_put;SELECT TRIM(&#x27;a&#x27; FROM &#x27;aaaa1aa2aaa3aaa&#x27;) AS out_put;7.lpad :用指定字符填满指定长度（左填充）SELECT LPAD(&#x27;苍老师&#x27;,10,&#x27;*&#x27;);8.rpad:用指定字符填满指定长度（右填充）SELECT RPAD(&#x27;苍老师&#x27;,10,&#x27;*&#x27;);9.replace 替换SELECT REPLACE(&#x27;千锋培训机构&#x27;,&#x27;千锋&#x27;,&#x27;尚硅谷&#x27;); 2.数学函数12345678910111.round:四舍五入SELECT ROUND(1.666);SELECT ROUND(1.567,2);2.ceil 向上取整SELECT CEIL(1.52);3.floor 向下取整SELECT FLOOR(1.52);4.truncate:截断（小数点后保留几位）SELECT TRUNCATE(1.65,2);5.mod:取余SELECT MOD(10,3); 3.日期函数123456789101112131415161718192021222324252627281.now:返回当前系统日期时间SELECT NOW();2.curdate:返回当前系统日期SELECT CURDATE();3.curtime:返回当前时间SELECT CURTIME();4.获取指定部分的年月日时分秒SELECT YEAR(NOW());SELECT YEAR(hiredate) FROM employees;5.str_to_date将字符通过指定的格式转化成日期SELECT STR_TO_DATE(&#x27;1998-3-2&#x27;,&#x27;%Y-%c-%d&#x27;) AS out_put;案例：查询入职时间为1992-4-3的员工信息SELECT * FROM employeesWHERE hiredate=STR_TO_DATE(&#x27;2016-3-3&#x27;,&#x27;%Y-%c-%d&#x27;);6.date_format 将日期转换成字符SELECT DATE_FORMAT(NOW(),&#x27;%y年%m月%d日&#x27;) AS 日期;案例：查询有奖金的员工名和入职日期（xx月/xx日 xx年）SELECT last_name, DATE_FORMAT(hiredate, &#x27;%c月/%d日 %y&#x27;) FROM employees WHERE commission_pct IS NOT NULL ; 4.其他函数123SELECT VERSION();SELECT DATABASE();SELECT USER(); 5.流程控制函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465661.if:IF else效果SELECT IF(10&gt;5,&#x27;true&#x27;,&#x27;false&#x27;);案例：查询如果有奖金就备注有，没有就备注没有。SELECT last_name, commission_pct, IF( commission_pct IS NULL, &#x27;没奖金&#x27;, &#x27;有奖金&#x27; ) AS 备注 FROM employees ;2.case函数1)switch-CASE语法:CASE 要判断的字段或者表达式WHEN 常量1 THEN 要显示的值1或者语句1WHEN 常量2 THEN 要显示的值2或者语句2...ELSE 要显示的值n或者语句n；案例：查询员工的工资，要求部门号==30，显示的工资为1.1倍，部门号==40，显示的工资为1.2倍，部门号==50，显示的工资为1.3倍，其他部门，显示原有工资。SELECT salary AS 原始工资, department_id , CASE department_id WHEN 30 THEN salary * 1.1 WHEN 40 THEN salary * 1.2 WHEN 50 THEN salary * 1.3 ELSE salary END AS 新工资 FROM employees ;2)CASE 使用2：语法：CASE WHEN 条件1 THEN 要显示的值1或语句1WHEN 条件2 THEN 要显示的值2或语句2...ELSE 要显示的值n或语句nEND案例：查询员工的工资情况如果&gt;2w，显示A如果&gt;1.5w，显示B如果&gt;1w，显示C否则，显示DSELECT salary, CASE WHEN salary &gt; 20000 THEN &#x27;A&#x27; WHEN salary &gt; 15000 THEN &#x27;B&#x27; WHEN salary &gt; 10000 THEN &#x27;C&#x27; ELSE &#x27;D&#x27; END AS 工资等级 FROM employees ; 2.分组函数功能：用作统计使用 123456789101112131415161718192021222324251.sum :求和SELECT SUM(salary) FROM employees;2.avg：平均值SELECT AVG(salary) FROM employees;3.max：最大值SELECT MAX(salary) FROM employees;4.min：最小值SELECT MIN(salary) FROM employees;5.count：计算个数SELECT COUNT(salary) FROM employees;总结①.sum,avg一般用于处理数值类型②.max，min，count用来处理任何类型③.以上分组函数都忽略null值④.可以和distinct搭配SELECT SUM(DISTINCT salary) 纯净,SUM(salary) FROM employees;6.count的详细介绍①select COUNT(*) FROM employees;②select COUNT(1) FROM employees;③和分组函数一同查询的字段要求是group by后的字段。 5.分组查询GROUP BY 和分组函数对应分组查询中分组条件分为两类 数据源 位置 关键字 分组前筛选 原始表 GROUP BY 子句的前面 WHERE 分组后筛选 分组后的结果集 GROUP BY 子句的后面 HAVING 分组函数做条件肯定是放在having子句中。group BY 子句支持单个字段分组，多个字段分组（多个字段之间用逗号隔开没有顺序要求），表达式或函数。也可以添加排序，放在整个分组查询的最后。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869案例：查询每个工种的最高工资SELECT MAX(salary), job_id FROM employees GROUP BY job_id ORDER BY MAX(salary) ASC ;案例：查询邮箱中包含a字符的，每个部门的平均工资SELECT AVG(salary), department_id FROM employees WHERE email LIKE &#x27;%a%&#x27; GROUP BY department_id ;#select Avg(salary),dep_id from employee where email like %a% group by dep_id ;案例：查询有奖金的每个领导手下员工的最高工资SELECT MAX(salary), manager_id FROM employees WHERE commission_pct IS NOT NULL GROUP BY manager_id ;#select max(salary) ,manage_id from employees where commission_pct is not null group by manager_id;案例：哪个部门的员工个数大于二？SELECT COUNT(*), department_id FROM employees GROUP BY department_id HAVING COUNT(*) &gt; 2 ;#select dep_id from emp group by dep_id having count(*)&gt;2;案例：查询每个工种有奖金的员工的最高工资&gt;12000的工种编号和最高工资SELECT MAX(salary), job_id FROM employees WHERE commission_pct IS NOT NULL GROUP BY job_id HAVING MAX(salary) &gt; 12000 ;#select job_id ,max(salary) from emp where commission_pct IS NOT NULL group by job_id having max(salary)&gt;12000;案例：查询领导编号&gt;102的每个领导手下的最低工资&gt;5000的领导编号是哪个？SELECT manager_id ,MIN(salary)FROM employeesWHERE manager_id&gt;102GROUP BY manager_idHAVING MIN(salary)&gt;5000;#select manager_id from emp where manager_id&gt;102 group by manager_id having min(salary)&gt;5000;#按照员工姓名的长度分组，查询每一组的员工个数，筛选员工个数&gt;5的有哪些？SELECT COUNT(*) AS cFROM employeesGROUP BY LENGTH(last_name) HAVING c&gt;5;# select count(*) from emp group by length(name) having count(*)&gt;5;#查询每个部门每个工种的员工的平均工资SELECT AVG(salary),job_idFROM employeesGROUP BY department_id,job_id;#select avg(salary) from emp group by dep_id,job_id;#查询每个部门每个工种的员工的平均工资并且按照平均工资的高低显示SELECT AVG(salary),job_idFROM employeesGROUP BY department_id,job_idORDER BY AVG(salary) ASC;#select avg(salary) from emp group by dep_id,job_id order by avg(salary) asc; 6.连接查询又称为多表查询，当查询的字段来自多个表时，就会用到连接查询。**笛卡尔乘积现象：表1有m行，表2有n行，结果：m_n行_发生原因：没有有效的连接条件 分类 ①按年代分类sql92:仅仅支持内连接sql99：不支持全外连接 ②按功能分类 内连接 外连接 交叉连接 等值连接 左外连接 非等值连接 右外连接 自连接 全外连接 1.等值连接①多表等值连接的结果为多表的交集部分②n表连接，至少需要n-1个连接条件③多表的顺序没有要求④一般需要为表起别名⑤可以搭配前面介绍的所有子句使用，比如排序，分组，筛选 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#案例一：查询女优名对应的男优名SELECT NAME, boyName FROM beauty, boys WHERE beauty.boyfriend_id = boys.`id` ;#select name, boyname from girl ,boy where girl.boyfriend_id=boy.id;#案例：查询员工名和对应的部门名SELECT last_name, department_name FROM employees, departments WHERE employees.`department_id` = departments.`department_id` ;#select name ,dep_name from emp e,dep d where e.dep.id= d.id;#案例：查询员工名，工种号，工种名。SELECT last_name, emp.`job_id`, job_title FROM employees emp, jobs job WHERE emp.`job_id` = job.`job_id` ;#select name , e.job_id,job_title from emp e,job j where e.job_id=j.id;#案例：查询有奖金的员工名和部门名SELECT last_name, department_name FROM employees emp, departments dep WHERE commission_pct IS NOT NULL &amp;&amp; emp.`department_id` = dep.`department_id` ;#select name ,dep_name from emp e ,dep d where e.dep_id =d.id &amp;&amp;e.salary_pct is not null;#案例：查询城市名第二个字符为o的部门SELECT department_name FROM locations l, departments d WHERE l.`location_id` = d.`location_id` AND l.`city` LIKE &#x27;_o%&#x27; ;#select dep_name from location l , dep d where l.city like %_o% &amp;&amp; l.id =d.location_id;#案例：查询每个城市的部门个数SELECT COUNT(*), city FROM locations l, departments d WHERE l.`location_id` = d.`location_id` GROUP BY l.`city` ;#select count(*),city from loca l,dep d where l.loc_id=d.loc_id group by count(*) asc;#案例：查询有奖金的每个部门的部门名和部门的领导编号和该部门的最低工资SELECT d.`department_name`, d.manager_id, MIN(salary) FROM employees e, departments d WHERE e.`department_id` = d.`department_id` AND e.`commission_pct` IS NOT NULL GROUP BY d.`department_id`, d.`department_name` ;#select dep_name ,d.manager_id ,min(salary) from emp e ,dep d where e.`department_id` = d.`department_id` AND e.`commission_pct` IS NOT NULL GROUP BY d.`department_id`,d.`department_name` ;#案例：查询每个工种的工种名和员工的个数，并且按照员工个数降序排序SELECT j.job_title, COUNT(*) FROM jobs j, employees e WHERE j.`job_id` = e.`job_id` GROUP BY e.`job_id`, j.`job_title` ORDER BY COUNT(*) DESC ;#案例：查询员工名，部门名和所在城市SELECT last_name, department_name, city FROM employees e, departments d, locations l WHERE e.`department_id` = d.`department_id` AND d.`location_id` = l.`location_id` ; 2.非等值连接123456789#案例：查询员工的工资和工资级别SELECT DISTINCT salary, grade_level FROM employees e, job_grades j WHERE e.salary &gt;= j.lowest_sal &amp;&amp; e.salary &lt;= j.highest_sal ORDER BY salary ASC ; 3.自连接12345678#案例：查询员工名和上级的名称SELECT e.last_name, m.last_name FROM employees e, employees m WHERE e.manager_id = m.employee_id ; 4.内连接INNER 可以省略 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#查询员工名，部门名SELECT last_name, department_name FROM employees e INNER JOIN departments d ON e.department_id = d.department_id ;#查询名字中包含e的员工名和工种名SELECT last_name, job_title FROM employees e INNER JOIN jobs j ON e.job_id = j.job_id WHERE last_name LIKE &#x27;%e%&#x27; ;#查询部门个数&gt;3的城市名和部门个数SELECT city, COUNT(*) FROM departments d INNER JOIN locations l ON d.`location_id` = l.`location_id` GROUP BY cityHAVING COUNT(*) &gt; 3 ;#查询哪个部门的部门员工个数&gt;3的部门名和员工个数，并按照个数降序排序SELECT department_name, COUNT(*) FROM employees e INNER JOIN departments d ON e.`department_id` = d.`department_id` GROUP BY e.department_id HAVING COUNT(*) &gt; 3 ORDER BY COUNT(*) DESC ;#查询员工名，部门名，工种名，并按照部门名降序排序SELECT last_name, department_name, job_title FROM employees e INNER JOIN departments d ON e.`department_id` = d.`department_id` INNER JOIN jobs j ON e.`job_id` = j.`job_id` ORDER BY department_name DESC ;#查询员工工资级别SELECT grade_level, salaryFROM job_grades j INNER JOIN employees e ON e.`salary` BETWEEN j.`lowest_sal` AND j.`highest_sal` ;#查询每个工资级别的个数，并且降序排序SELECT grade_level,COUNT(*)FROM employees eINNER JOIN job_grades jON e.`salary` BETWEEN j.`lowest_sal` AND j.`highest_sal` GROUP BY grade_levelORDER BY COUNT(*) DESC;#查询员工的名字和上级的名字SELECT e1.last_name, e2.last_nameFROM employees e1INNER JOIN employees e2ON e1.`employee_id`=e2.`manager_id`; 5.左外连接语法：SELECT 查询列表FROM 表1 【连接类型】JOIN 表2ON 连接条件WHERE 筛选条件GROUP BY 分组HAVING 筛选条件ORDER BY 排序条件连接类型：内连接：inner左外连接：left右外连接：right全外连接：full交叉连接：cross外连接用于查询一个表中有，另一个表中没有的数据左外连接，left左边是主表右外连接，right右边是主表Mysql不支持全外连接 1234567#没有男朋友的女生SELECT g.`name`,b.`boyName`FROM beauty gLEFT JOIN boys bON g.`boyfriend_id`=b.`id`WHERE b.`boyName` IS NULL; 6.交叉连接笛卡尔乘积 7.子查询出现在其它语句中的select语句，称为子查询或内查询外部的查询语句，称为主查询或外查询分类： ①按照子查询出现的位置： select后面 from后面 where或having后面 exists后面 仅仅支持标量子查询 支持表子查询 标量子查询，列子查询 表子查询 ②按照结果集的行列数不同： 标量子查询 列子查询 行子查询 表子查询 结果只有一行一列 结果一列多行 一行多列 多行多列 1）where或having后面特点：子查询一般放在小括号内子查询一般放在条件的右边标量子查询，一般搭配着单行操作符列子查询：一般搭配多行操作符使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211.标量子查询#谁的工资比Abel高SELECT last_name FROM employees WHERE salary &gt; (SELECT salary FROM employees WHERE last_name = &#x27;Abel&#x27;) ;#返回job_id于141号员工相同，salary比143号员工多的员工 姓名，job_id和工资SELECT last_name, job_id, salary FROM employees WHERE job_id = (SELECT job_id FROM employees WHERE employee_id = 141) AND salary &gt; (SELECT salary FROM employees WHERE employee_id = 143)#返回公司工资工资最少的员工的姓名，job_id,salarySELECT last_name, job_id, salary FROM employees WHERE salary = (SELECT MIN(salary) FROM employees);#查询最低工资大于50号部门最低工资的部门id和其最低工资SELECT department_id, MIN(salary) FROM employees GROUP BY department_id HAVING MIN(salary) &gt; (SELECT MIN(salary) FROM employees WHERE department_id = 50) ;2.列子查询多行操作符：IN / NOT in：等于列表中的任意一个ANY / SOME ：和子查询返回的某一个值比较ALL ：和子查询返回的所有值比较#返回location_id是1400或者1700的部门中的所有员工姓名SELECT last_name FROM employees WHERE department_id IN (SELECT DISTINCT department_id FROM departments WHERE location_id IN (1400, 1700)) ;#返回其他工种中比job_id为IT_PROG部门任意工资低的员工#工号，姓名，job_id以及salarySELECT employee_id, last_name, job_id, salary FROM employees WHERE salary &lt; (SELECT MAX(salary) FROM employees WHERE job_id = &#x27;IT_PROG&#x27;) AND job_id !=&#x27;IT_PROG&#x27;;#返回其他工种中比job_id为IT_PROG部门所有工资低的员工#工号，姓名，job_id以及salarySELECT employee_id, last_name, job_id, salary FROM employees WHERE salary &lt; (SELECT MIN(salary) FROM employees WHERE job_id = &#x27;IT_PROG&#x27;) AND job_id !=&#x27;IT_PROG&#x27;;*********************************3.行子查询#查询员工编号最小并且工资最高的员工信息SELECT * FROM employees WHERE employee_id = (SELECT MIN(employee_id) FROM employees) AND salary = (SELECT MAX(salary) FROM employees) 2）SELECT 后面123456789101112131415161718192021#查询每个部门的员工个数SELECT d.*, (SELECT COUNT(*) FROM employees e WHERE e.department_id = d.department_id) FROM departments d ;#查询员工号等于102的部门名SELECT department_name FROM departments WHERE department_id = (SELECT department_id FROM employees WHERE employee_id = 102) ; 3）FROM 后面1234567891011121314#查询每个部门平均工资的工资等级SELECT grade_level ,aa.department_idFROM (SELECT AVG(salary) ag, department_id FROM employees GROUP BY department_id) aa INNER JOIN job_grades j ON aa.ag BETWEEN lowest_sal AND highest_sal ; 4）exists后面（相关子查询）12345678#查询有员工的部门名SELECT department_name FROM departments dWHERE EXISTS(SELECT * FROM employees e WHERE d.department_id=e.department_id);#查询没有女朋友的男生信息SELECT bo.* FROM boys bo WHEREbo.`id` NOT IN(SELECT boyfriend_id FROM beauty); 5）子查询经典案例祥讲1234567891011121314151617181920212223242526272829303132331.查询工资最低的员工信息：last_name,salarySELECT last_name,salary FROM employeesWHERE salary=(SELECT MIN(salary) FROM employees);2.查询平均工资最低的部门信息SELECT * FROM departments WHERE department_id=(SELECT department_id FROM employees GROUP BY department_id ORDER BY AVG(salary)LIMIT 1)3.查询平均工资最低的部门信息和该部门的平均工资SELECT d.*,a1.ag FROM departments d JOIN (SELECT AVG(salary) ag,department_id FROM employees GROUP BY department_id ORDER BY AVG(salary)LIMIT 1) a1ON d.department_id=a1.department_id4.查询平均工资最高的job信息SELECT j.* FROM jobs j WHERE j.job_id=(SELECT job_id FROM employeesGROUP BY job_id ORDER BY AVG(salary) DESC LIMIT 1)5.查询平均工资高于公司平均工资的部门有哪些SELECT department_id FROM (SELECT department_id ,AVG(salary) AS avg1 FROM employees GROUP BY department_id) e1WHERE e1.avg1&gt;(SELECT AVG(salary) AS avg2 FROM employees) 6.查询出公司中所有manager的详细信息SELECT * FROM employeesWHERE employee_id IN(SELECT DISTINCT manager_id FROM employees);7.各个部门中，最高工资中最低的那个部门的最低工资是多少SELECT MIN(salary) FROM employees GROUP BY department_idHAVING department_id=(SELECT department_id FROM employees GROUP BY department_id ORDER BY MAX(salary)LIMIT 1)8.查询平均工资最高的部门的manager的详细信息：last_name,department_id,email,salarySELECT last_name,department_id,email,salary FROM employees WHERE employee_id=(SELECT manager_id FROM departments WHERE department_id=(SELECT department_id FROM employees GROUP BY department_id ORDER BY AVG(salary)DESC LIMIT 1)) 8.分页查询**语法：limit(currentPage-1)size,size 123456789#查询前五条员工信息SELECT * FROM employees LIMIT 0,5;#查询第11-25条员工信息SELECT * FROM employees LIMIT 10,15;#查询有奖金的员工，并且工资最高的前十名显示出来SELECT * FROM employeesWHERE commission_pct IS NOT NULLORDER BY salary DESC LIMIT 0 ,10; 9.联合查询要查询的结果来自于多个表，且多个表没有直接的连接关系，单查询的信息一致时特点：1.要求多条查询语句的查询列数是一致的2.要求多条查询语句的查询的每一列的类型和顺序最好一致3.union关键字默认去重，如果使用union all 可以不去除重复项 1234案例：查询员工部门编号大于90或邮箱包含a的员工信息SELECT * FROM employees WHERE department_id&gt;90UNIONSELECT * FROM employees WHERE email LIKE &#x27;%a%&#x27;; 三，DML数据操作语言插入insert 1234567891011121314151617一：插入语句#插入beauty一行数据INSERT INTO beauty(NAME,sex,borndate,phone,photo,boyfriend_id)VALUES(&#x27;波多野吉依&#x27;,&#x27;女&#x27;,&#x27;1998-11-11&#x27;,&#x27;13342969497&#x27;,NULL,10)#可以为null的列如何不插入值直接写null，或列名少写一列INSERT INTO beauty(NAME,sex,borndate,phone,photo,boyfriend_id)VALUES(&#x27;小泽玛利亚&#x27;,&#x27;女&#x27;,&#x27;1999-11-11&#x27;,&#x27;13342456497&#x27;,NULL,11)INSERT INTO beauty VALUES(15,&#x27;马蓉&#x27;,&#x27;女&#x27;,&#x27;1989-11-11&#x27;,&#x27;13342456123&#x27;,NULL,12);INSERT INTO beauty SET id=16,NAME=&#x27;刘亦菲&#x27;, sex=&#x27;女&#x27;,borndate=&#x27;1989-10-01&#x27;,phone=&#x27;15945231056&#x27;,boyfriend_id=16;#insert 嵌套子查询，将一个表的数据插入另一张表INSERT INTO beauty (NAME,sex,borndate,phone,boyfriend_id)SELECT &#x27;妲己&#x27;,&#x27;女&#x27;,&#x27;1111-11-11&#x27;,&#x27;13146587954&#x27;,0; 修改update 1234567891011121314151617181920二，修改 UPDATE beauty SET phone=&#x27;110&#x27; WHERE id=16;多表修改：sql99UPDATE 表1 别名INNER|LEFT|RIGHT JOIN 表2 别名ON 连接条件SET 列=值WHERE 筛选条件#修改张无忌的女朋友手机号为114UPDATE beauty gINNER JOIN boys bON g.boyfriend_id=b.idSET g.phone=&#x27;114&#x27;WHERE b.boyName=&#x27;张无忌&#x27;;#修改没有男朋友的女生的男朋友编号都为4号UPDATE beauty gLEFT JOIN boys bON g.`boyfriend_id`=b.idSET g.`boyfriend_id`=4WHERE b.id=NULL; 删除delete 1234567891011121314151617181920212223三，删除DELETE 和 TRUNCATE 的区别：1.delete可以加where条件，truncate不行2.truncate删除效率高3.加入要删除的表中有自增列，用delete删除整个表后在插入数据，从断点处开始插入用truncate删除后在插入数据，从1开始。4.truncate删除没有返回值，delete有返回值5.truncate删除不能回滚，delete删除可以回滚DELETE FROM beauty WHERE id=17;语法：truncate TABLE 表名;#删除张无忌的女朋友的信息DELETE g FROM beauty gINNER JOIN boys bON g.boyfriend_id=b.idWHERE b.id=1;#删除黄晓明以及他女朋友的信息DELETE b,g FROM beauty gINNER JOIN boys bON b.`id`=g.`boyfriend_id`WHERE b.`boyName`=&#x27;黄晓明&#x27;;多表删除 :TRUNCATETRUNCATE TABLE boys 四，DDL数据定义语言1.库和表的管理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849一，库的管理创建 CREATECREATE DATABASE IF NOT EXISTS mydb1 ;修改 ALTER1.更改字符集ALTER DATABASE mydb1 CHARACTER SET utf8;删除 DROPDROP DATABASE IF EXISTS school;二，表的管理创建 CREATECREATE TABLE book(id INT PRIMARY KEY,b_name VARCHAR(30),price DOUBLE,author_id INT ,publishDate DATE);DESC book ;CREATE TABLE author(id INT PRIMARY KEY ,au_name VARCHAR(20),nation VARCHAR(10));DESC author;修改 ALTER1.修改列名ALTER TABLE book CHANGE COLUMN publishDate pub_date DATETIME;2.修改列的类型或约束ALTER TABLE book MODIFY COLUMN pub_date DATE;3.添加新列ALTER TABLE author ADD COLUMN annual DOUBLE;4.删除新列ALTER TABLE author DROP COLUMN annual;5.修改表名ALTER TABLE author RENAME TO book_author;删除 DROPDROP TABLE IF EXISTS my_employee;SHOW TABLES;复制1.仅仅复制表的结构CREATE TABLE copy LIKE book_author;2.复制表的结构加数据CREATE TABLE copy2SELECT * FROM book_author;3.复制部分结构CREATE TABLE copy3 SELECT id,au_nameFROM book_authorWHERE id=0; 2.数据类型数值型1.整型 TINYINT SMALLINT MEDIUMINT INT/INTEGER BIGINT 1 2 3 4 8 12345如何设置无符号和有符号(默认有符号)DROP TABLE tab_int;CREATE TABLE tab_int(t1 INT,t2 INT UNSIGNED);INSERT INTO tab_int(t1,t2) VALUES(-1,1);DESC tab_int; 1）如果插入的数值超出了整形的范围，会报out of range异常，并且插入临界值。2）如果不设置长度，会有默认的长度。长度代表了显示的最大宽度，如果不够会用0在左边填充，但必须搭配zerofill使用。2.小数①定点数dec（M,D）②浮点数float（4） ，double（8）M，D的意思：M指定一共多少位，D指定小数几位，超出会四舍五入。MD都可以省略，如果是dec，则M默认为10，D默认为0如果是浮点数，则会根据插入数值的精度改变精度定点型精度相对较高。3.字符型①较短的文本CHAR(M)默认为1,VARCHAR(M)M:字符数char：固定长度字符，比较耗费空间，但是效率高。varchar：可变长度字符 123456789ENUM 枚举类CREATE TABLE tab_char( t1 ENUM(&#x27;a&#x27;,&#x27;c&#x27;,&#x27;b&#x27;));SET 集合CREATE TABLE tab_set(s1 SET(&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;));INSERT INTO tab_set(s1) VALUES(&#x27;a,b&#x27;); BINARY:保存较短的二进制。②较长的文本text（文本）,BLOB(较大的二进制)4.日期型DATE:日期DATETIME:日期加时间，8字节timestamp：跟时区有关系，建议使用，4字节time：时间year：年 123456789CREATE TABLE tab_date(t1 DATETIME,t2 TIMESTAMP);INSERT INTO tab_date(t1,t2)VALUES(NOW(),NOW());SELECT * FROM tab_date;SET time_zone=&#x27;+9:00&#x27;;#设置时区为东9区 3.常见约束含义：一种限制，用于限制表中的数据，保证数据的一致性。 NOT NULL DEFAULT PRIMARY KEY 唯一，且不为空 UNIQUE 唯一，可以为空 CHECK Mysql不支持 FOREIGN KEY 外键约束，用于限制两个表的关系，用于保证该字段的值必须来自于主表的关联列的值。约束的分类：列级约束：除外键约束表级约束：除了非空，默认。CREATE TABLE 表名(字段1 字段类型 列级约束,字段2 字段类型 列级约束,表级约束); 1234567891011121314151617181920212223242526#创建表时添加列级约束DROP TABLE tab_test;CREATE TABLE tab_test(id INT PRIMARY KEY,stu_name VARCHAR(20) NOT NULL,gender CHAR DEFAULT &#x27;男&#x27;,seat_id INT UNIQUE, major_id INT REFERENCES tab_major(id) );CREATE TABLE tab_major(id INT PRIMARY KEY ,major_name VARCHAR(20) NOT NULL);DESC tab_test;SHOW INDEX FROM tab_test;#查看索引信息#添加表级约束CREATE TABLE tab_test(id INT PRIMARY KEY AUTO_INCREMENT,stu_name VARCHAR(20) NOT NULL,gender CHAR DEFAULT &#x27;男&#x27;,seat_id INT UNIQUE, major_id INT ,CONSTRAINT m_id FOREIGN KEY(major_id) REFERENCES tab_major(id) );CONSTRAINT m_id 可以省略 面试题：主键约束和唯一约束的区别：都可以保证唯一性，主键不能为空 ，unique 能为空，但是只能有一个null。主键只能有1个，unique可以有多个。都允许两个列组合成一个约束。面试题：外键：要求在从表设置外键关系从表的外键列类型和主表的关联列类型一致，名称无要求要求主表的关联列必须是主键或者唯一键插入数据应该先插入主表再插入从表删除数据应该先删除从表，在删除主表二，修改表时添加约束 1234567891011CREATE TABLE tab_test2(id INT ,stu_name VARCHAR(20) ,gender CHAR ,seat_id INT , major_id INT );ALTER TABLE tab_test2 MODIFY COLUMN stu_name VARCHAR(20) NOT NULL ;ALTER TABLE tab_test2 MODIFY COLUMN id INT PRIMARY KEY AUTO_INCREMENT;#添加外键ALTER TABLE tab_test2 ADD FOREIGN KEY(major_id) REFERENCES tab_major(id); 4.标识列自增长列 AUTO_INCREMENT特点：1.表示必须和一个key搭配2.一个表最多一个标识列3.标识列类型只能是数值型4.标识列可以通过set auto_increment_increment=3;设置步长 1234CREATE tab_auto(id INT PRIMARY KEY AUTO_INCREMENT,NAME VARCHAR(20) NOT NULL); 五，TCL语言：事务控制语言事务：一个或一组sql语句组成的执行单元， 要么全部执行,要么都不执行。存储引擎:在MySQL中的数据用各种不同的技术存储在文件中。通过show ENGINES;来查看mysql支持的存储引擎。innodb引擎支持事务。事务的ACID属性：1.原子性:事务是一个不可分割的工作单位，要么都发生，要么都不发生。2.一致性：事务必须使数据库从一个一致性状态变为另一个一致性状态。3.隔离性：一个事务的执行不能被另一个事务干扰。4.持久性：事务一旦被提交，对数据库事务的改变就是永久性的。 DELETE 和 TRUNCATE 在事务中的区别： 1234567891011演示deleteSET autocommit=0;START TRANSACTION;DELETE FROM tab_teacher;ROLLBACK;演示 TRUNCATESET autocommit=0;START TRANSACTION;TRUNCATE TABLE tab_teacher;ROLLBACK;DELETE 是直接删除表中数据，truncate是江表删除，创建一张与原来一样的空表。 六，视图含义：虚拟表，和普通表格一样使用通过表动态生成的数据 1.创建视图语法：CREATE VIEW 视图名AS查询语句 ; 12345678910111213141516171819202122# 案例：查询姓名中包含a字符的员工名，部门名和工种信息create view view1 as select e.last_name,d.department_name ,j.job_title from employees einner join departments d on e.department_id = d.department_id inner join jobs j on e.job_id = j.job_idwhere e.last_name like &#x27;%a%&#x27;;select * from view1;# 案例：查询各个部门的平均工资级别create view view2 asselect j.grade_level ,aa.department_id from job_grades jinner join (select avg(salary) avg_s,department_id from employees group by department_id) aa on aa.avg_s between j.lowest_sal and j.highest_sal;select * from view2;# 案例：查询平均工资最低的部门信息create view view3 asselect avg(salary) avg_s ,department_idfrom employeesgroup by department_idorder by avg_s asclimit 1;select * from view3; 2.视图修改①create OR REPLACE VIEW 视图名 AS 查询语句;②alter VIEW 视图名 AS 查询语句; 3.删除视图DROP VIEW v1,v2; 4.查看视图DESC v1; 12345678910#创建视图emp_v1，要求查询电话号码以011开头的员工姓名和工资，邮箱CREATE VIEW emp_v1 ASSELECT last_name ,salary,email FROM employees WHEREphone_number LIKE &#x27;%011&#x27;;#创建视图emp_v2,要求查询部门的最高工资高于12000的部门信息CREATE VIEW v4 ASSELECT department_id FROM employees GROUP BY department_idHAVING MAX(salary)&gt; 12000;CREATE VIEW emp_v2 ASSELECT * FROM departments WHERE department_id IN(SELECT * FROM v4); 5.视图的更新视图的可更新性和视图中查询的定义有关，以下类型的视图是不能更新的。1.包含以下关键字的sql语句：分组函数，distinct，group by，having，union2.常量视图3.select中包含子查询的4.join5.from 一个不能更新的视图6.where子句的子查询引用了from子句的表 6.视图和表的对比： 创建语法的关键字 是否实际占用物理空间 使用 视图 CREATE VIEW 只是保存了sql逻辑 增删改查，一般不能增删改 表 CREATE TABLE 占用 增删改查 七，变量系统变量 ：变量由系统提供，不是用户自定义，属于服务器层面。查看系统所有变量：show GLOBAL VARIABLES;查看满足条件的部分系统变量： SHOW GLOBAL VARIABLES LIKE ‘%char%’;查看指定的某个系统变量的值： SELECT @@global.autocommit;为某个系统变量赋值：set @@global.系统变量名=值;全局变量:GLOBAL作用域：服务器每次启动将为所有的全局变量赋初始值，针对于所有的会话有效，但不能跨重启。会话变量:SESSION作用域：针对当前的会话有效。用户自定义变量用户变量声明： SET/SELECT @用户变量名 :=值;赋值：通过 SELECT 字段 INTO 变量名;或 SET/SELECT @用户变量名 :=值;使用：select @用户变量名;应用在任何地方。作用域：针对当前会话和连接有效。局部变量作用域：作用在定义它的begin END 块中。声明： DECLARE 变量名 类型 （default 值）;赋值：通过 SELECT 字段 INTO 变量名;或 SET/SELECT @变量名 :=值;使用：select @变量名;只能放在begin END 中的第一句话 八，存储过程和函数存储过程：一组预先定义好的sql语句集合，理解成批处理语句。1.提高代码的重用性2.简化操作3.减少了编译次数并且减少了和数据库服务器的连接次数，提高了效率。 1.创建语法：CREATE PROCEDURE 存储过程名（参数列表）BEGIN一组合法的sql语句;END参数列表：参数模式 参数名 参数类型 参数模式：in：该参数可以作为输入，也就是该参数需要调用方传入值OUT ：该参数可以作为输出，也就是该参数可以作为返回值inout：该参数既可以作为输入又可以作为输出 如果存储过程只有一句话，begin END 可以省略 存储过程体中的每条sql语句的结尾需要必须加分号，存储过程的结尾可以使用 DELIMITER 重新设置。 2.调用CALL 存储过程名（实参列表）; 3.案例1234567891011121314151617181920212223242526272829303132333435363738394041424344#插入到admin表中五条记录DELIMITER $CREATE PROCEDURE my_a()BEGININSERT INTO admin(username,PASSWORD) VALUES(&#x27;yin&#x27;,&#x27;666&#x27;);INSERT INTO admin(username,PASSWORD) VALUES(&#x27;aa&#x27;,&#x27;123&#x27;);INSERT INTO admin(username,PASSWORD) VALUES(&#x27;bb&#x27;,&#x27;666&#x27;);INSERT INTO admin(username,PASSWORD) VALUES(&#x27;cc&#x27;,&#x27;123&#x27;);INSERT INTO admin(username,PASSWORD) VALUES(&#x27;dd&#x27;,&#x27;666&#x27;);END $#创建存储过程实现 根据女生名查询对应的男生信息DELIMITER $CREATE PROCEDURE my_b(IN beauty_name VARCHAR(20))BEGIN SELECT bo.* FROM boys bo RIGHT JOIN beauty b ON bo.id=b.boyfriend_id WHERE b.name=beauty_name;END $CALL my_b(&#x27;热巴&#x27;);#根据女生名返回他的男朋友名DELIMITER $CREATE PROCEDURE my_d(IN beautyName VARCHAR(20),OUT boyName VARCHAR(20))BEGIN SELECT bo.boyName INTO boyName FROM boys bo INNER JOIN beauty b ON bo.id=b.boyfriend_id WHERE b.name=beautyName;END $CALL my_d(&#x27;小昭&#x27;,@b_name);SELECT @b_name;#传入两个值a，b，最终翻倍返回a和bDELIMITER $CREATE PROCEDURE my_e(INOUT a INT ,INOUT b INT )BEGIN SET a=a*2; SET b=b*2;END $SET @m=10;SET @n=20;CALL my_e(@m,@n);SELECT @m,@n; 4.删除存储过程12DROP PROCEDURE 存储过程名DROP PROCEDURE my_a; 5.查看存储过程的信息1SHOW CREATE PROCEDURE my_b; 函数存储过程可以有0/n个返回值：适合批量增删改函数有且仅有一个返回值：适合查询 1.创建12345DELIMITER $CREATE FUNCTION 函数名(参数列表) RETURNS 返回类型BEGINEND 注意：参数列表：参数名，参数类型一定会有return语句 2.使用SELECT 函数名(参数列表) 12345678910111213141516171819#返回公司员工个数DELIMITER $CREATE FUNCTION my_f1() RETURNS INTBEGINDECLARE c INT DEFAULT 0 ; SELECT COUNT(*) INTO c FROM employees; RETURN c;END $SELECT my_f1();#根据员工名返回他的工资DELIMITER $CREATE FUNCTION my_f2(NAME VARCHAR(20)) RETURNS DOUBLEBEGIN DECLARE c DOUBLE; SELECT salary INTO c FROM employees WHERE last_name=NAME; RETURN c;END $SET @a=&#x27;Hunold&#x27;;SELECT my_f2(@a); 3.查看1SHOW CREATE FUNCTION my_f2; 4.删除1DROP FUNCTION my_f2; 九，流程控制分支结构1.if （表达式1，表达式2，表达式3）如果表达式1成立，就返回表达式2的值，否则返回表达式3的值。应用在任何地方 2.case1)switch-CASE语法:CASE 要判断的字段或者表达式WHEN 常量1 THEN 要显示的值1或者语句1WHEN 常量2 THEN 要显示的值2或者语句2…ELSE 要显示的值n或者语句n； 1234567891011121314151617181920案例：查询员工的工资，要求部门号==30，显示的工资为1.1倍，部门号==40，显示的工资为1.2倍，部门号==50，显示的工资为1.3倍，其他部门，显示原有工资。SELECT salary AS 原始工资, department_id , CASE department_id WHEN 30 THEN salary * 1.1 WHEN 40 THEN salary * 1.2 WHEN 50 THEN salary * 1.3 ELSE salary END AS 新工资 FROM employees ; 2)CASE 使用2：语法：CASEWHEN 条件1 THEN 要显示的值1或语句1WHEN 条件2 THEN 要显示的值2或语句2…ELSE 要显示的值n或语句nEND 12345678910111213141516171819202122232425262728293031323334案例：查询员工的工资情况如果&gt;2w，显示A如果&gt;1.5w，显示B如果&gt;1w，显示C否则，显示DSELECT salary, CASE WHEN salary &gt; 20000 THEN &#x27;A&#x27; WHEN salary &gt; 15000 THEN &#x27;B&#x27; WHEN salary &gt; 10000 THEN &#x27;C&#x27; ELSE &#x27;D&#x27; END AS 工资等级 FROM employees 可以放在任何地方 #创建存储过程，根据传入的成绩，显示等级，90A,80B，70C，60D ，F DELIMITER $ CREATE PROCEDURE my_1(IN score INT) BEGIN CASE WHEN score BETWEEN 90 AND 100 THEN SELECT &#x27;A&#x27;; WHEN score BETWEEN 80 AND 90 THEN SELECT &#x27;B&#x27;; WHEN score BETWEEN 70 AND 80 THEN SELECT &#x27;C&#x27;; WHEN score BETWEEN 70 AND 60 THEN SELECT &#x27;D&#x27;; ELSE SELECT &#x27;E&#x27;; END CASE; END $CALL my_1(95); 3.if语法：IF 条件1 THEN 语句1;ELSEIF 条件2 THEN 语句2;…ELSE 语句n;END IF;只能用在begin end中 12345678910111213#创建存储过程，根据传入的成绩，返回等级，90A,80B，70C，60D ，FDELIMITER $ CREATE FUNCTION my_2( score INT) RETURNS CHAR BEGIN IF score &gt;=90 THEN RETURN&#x27;A&#x27;; ELSEIF score &gt;=80 THEN RETURN&#x27;B&#x27;; ELSEIF score &gt;=70 THEN RETURN&#x27;C&#x27;; ELSEIF score &gt;=60 THEN RETURN&#x27;D&#x27;; ELSE RETURN&#x27;E&#x27;; END IF; END $ SELECT my_2(85); 循环结构在存储过程或函数里面使用 1.while语法：标签:WHILE 循环条件 DO循环体;END WHILE 标签;循环控制和标签搭配使用 2.loop语法：标签： LOOP循环体;END LOOP 标签; 3.repeat语法：标签： REPEAT循环体;UNTIL 结束循环的条件END REPEAT 标签; 循环控制ITERATE 类似continueLEAVE 类似break left join==left outer join a left join b 就是取a和b的交集加a剩下的部分 inner join a inner join b就是取交集","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"MySQL[二]概述","slug":"MySQL/MySQL[二]概述","date":"2022-01-10T13:58:17.078Z","updated":"2022-01-11T03:14:31.883Z","comments":true,"path":"2022/01/10/MySQL/MySQL[二]概述/","link":"","permalink":"https://yinhuidong.github.io/2022/01/10/MySQL/MySQL[%E4%BA%8C]%E6%A6%82%E8%BF%B0/","excerpt":"","text":"一，一条SQL的查询流程 去连接池获取连接 查询缓存，命中返回，否则继续向下 词法解析&amp;预处理 词法解析拆分SQL，语法分析检查SQL的正确性生成一颗解析树，预处理检查表名，列名，生成一颗解析树。 优化器优化，优化计划，查询计划 执行引擎生成执行计划 存储引擎查询SQL，加入缓存，返回结果。 1.获取连接MySQL支持多种通信协议，可以使用同步/异步的方式，支持长连接，短连接。​ 1.1 通信类型​ 一般来说，连接数据库都是同步连接。​ 同步连接：依赖于被调用方，受限制于被调用方的性能；一般只能一对一。 异步连接：避免阻塞，但不能节省SQL的执行时间，并发情况下，每个SQL的执行都要单独建立连接，占用大量CPU资源；异步连接必须使用连接池减少线程创建销毁的开销。 1.2 连接方式MySQL长短连接都支持，一般我们会在连接池中使用长连接。保持长连接会消耗内存，长时间不活动的连接，MySQL服务器会断开。​ 12show global variables like &#x27;wait_timeout&#x27;; -- 非交互式超时时间，如 JDBC 程序show global variables like &#x27;interactive_timeout&#x27;; -- 交互式超时时间，如数据库工具 默认长连接断开时间是8小时。 可以使用 show status;查看当前MySQL有多少个连接。 1show global status like &#x27;Thread%&#x27;; Threads_cached 缓存中的线程连接数 Threads_connected 当前打开的连接数 Threads_created 为处理连接创建的线程数 Threads_running 非睡眠状态的连接数，通常指并发连接数 每产生一个连接或者会话，服务端就会创建一个线程来处理。杀死会话本质就是kill 线程。​ 可以使用SHOW PROCESSLIST; （root 用户）查看 SQL 的执行状态。​ +—-+——+———–+——+———+——+———-+| Id | User | Host | db | Command | Time | State | Info |+—-+——+———–+——+———+——+———-+| 11 | root | localhost | NULL | Query | 0 | starting | show processlist |+—-+——+———–+——+———+——+———-+ 状态 含义 Sleep 线程正在等待客户端，以向它发送一个新语句 Query 线程正在执行查询或往客户端发送数据 Locked 该查询被其它查询锁定 Copying to tmp table on disk 临时结果集合大于 tmp_table_size。线程把临时表从存储器内部格式改变为磁盘模式，以节约存储器 Sending data 线程正在为 SELECT 语句处理行，同时正在向客户端发送数据 Sorting for group 线程正在进行分类，以满足 GROUP BY 要求 Sorting for order 线程正在进行分类，以满足 ORDER BY 要求 在5.7版本，MySQL的默认连接数是151个，我们最大可以修改为16384个 （214）。​ 123show variables like &#x27;max_connections&#x27;;set [global | session] max_connections =10000; 1.3 通信协议​ 编程语言的连接模块都是用 TCP 协议连接到 MySQL 服务器的，比如mysql-connector-java-x.x.xx.jar。 类unix系统上，支持 Socket套接字文件进行进程间通信。/tmp/mysql.sock windows系统上还支持命名管道和共享内存。 ​ 1.4 通信方式MySQL使用了半双工通信，所以客户端发送SQL语句给服务端的时候，不管SQL有多大，都是一次发过去的。​ 比如我们用MyBatis动态SQL生成了一个批量插入的语句，插入10万条数据，values后面跟了一长串的内容，或者 where 条件 in 里面的值太多，会出现问题。这个时候我们必须要调整 MySQL 服务器配置 max_allowed_packet 参数的值（默认是 4M），把它调大，否则就会报错。 对于服务端来说，也是一次性发送所有的数据，不能因为你已经取到了想要的数据就中断操作，这个时候会对网络和内存产生大量消耗。在程序里面避免不带 limit 的这种操作，比如一次把所有满足条件的数据全部查出来，一定要先 count 一下。如果数据量的话，可以分批查询。 2.查询缓存MySQL 的缓存默认是关闭的。​ 1show variables like &#x27;query_cache%&#x27;; MySQL不推荐使用自带的缓存，命中条件过于苛刻。且表里数据发生变化，整张表的缓存全部失效，MySQL8移除掉了缓存。 3.语法解析&amp;预处理3.1 词法解析词法分析就是把一个完整的 SQL 语句打碎成一个个的单词。​ 1select name from user where id =1; 它会打碎成 8 个符号，每个符号是什么类型，从哪里开始到哪里结束。​ 3.2 语法解析语法分析会对 SQL 做一些语法检查，比如单引号有没有闭合，然后根据 MySQL 定义的语法规则，根据 SQL 语句生成一个数据结构。这个数据结构我们把它叫做解析树（select_lex）。​ 任何数据库的中间件，比如 Mycat，Sharding-JDBC（用到了 Druid Parser），都必须要有词法和语法分析功能。 3.3 预处理​ 如果写了一个词法和语法都正确的 SQL，但是表名或者字段不存在，会在哪里报错？是在数据库的执行层还是解析器？​ 实际上还是在解析的时候报错，解析 SQL 的环节里面有个预处理器。它会检查生成的解析树，解决解析器无法解析的语义。比如，它会检查表和列名是否存在，检查名字和别名，保证没有歧义。预处理之后得到一个新的解析树。​ 4.查询优化&amp;查询执行计划一条SQL语句的执行方式有很多种，但是最终返回的结果都是相同的。查询优化器的目的就是根据解析树生成不同的执行计划（Execution Plan），然后选择一种最优的执行计划，MySQL 里面使用的是基于开销（cost）的优化器，那种执行计划开销最小，就用哪种。 12# 查看查询的开销show status like &#x27;Last_query_cost&#x27;; 4.1 优化器的作用 多表联查，以哪张表为基准表 用不用索引，用哪个索引 。。。。 ​ 4.2 优化器是怎么得到执行计划的 首先我们要启用优化器的追踪（默认是关闭的）。 开启这开关是会消耗性能的，因为它要把优化分析的结果写到表里面，所以不要轻易开启，或者查看完之后关闭它（改成 off）。 接着执行一个 SQL 语句，优化器会生成执行计划： 这个时候优化器分析的过程已经记录到系统表里面了，我们可以查询： 它是一个 JSON 类型的数据，主要分成三部分，准备阶段、优化阶段和执行阶段。 expanded_query 是优化后的 SQL 语句。 considered_execution_plans 里面列出了所有的执行计划。 分析完记得关掉它 通过追踪优化器，可以看到优化器对sql的初始优化，表的读取顺序，为什么采用了这种读取顺序。为什么采用了某个索引或者采用了全表查询。 4.3 优化器得到的结果​ 优化器最终会把解析树变成一个查询执行计划，查询执行计划是一个数据结构。 当然，这个执行计划是不是一定是最优的执行计划呢？不一定，因为 MySQL 也有可能覆盖不到所有的执行计划。​ MySQL 提供了一个执行计划的工具。我们在 SQL 语句前面加上 EXPLAIN，就可以看到执行计划的信息。​ Explain 的结果也不一定最终执行的方式。​ 4.4 选错索引这里错误决定分两类，第一，彻底错误。第二，基于成本最低，但执行速度不是最快。 由于InnoDB的 MVCC 功能和随机采样方式，默认随机采取几个数据页，当做总体数据。以部分代表整体，本来就有错误的风险。加上数据不断地添加过程中，索引树可能会分裂，结果更加不准确。 执行 ANALYZE TABLE ,可以重新构建索引，使索引树不过于分裂。 调整参数，加大InnoDB采样的页数，页数越大越精确，但性能消耗更高。一般不建议这么干。 在优化阶段，会对表中所有索引进行对比，优化器基于成本的原因，选择成本最低的索引，所以会错过最佳索引。带来的问题便是，执行速度很慢。 通过explain查看执行计划，结合sql条件查看可以利用哪些索引。 使用 force index(indexName)强制走指定索引。弊端就是后期若索引名发生改变，或索引被删除，该sql语句需要调整。 5. 存储引擎得到执行计划以后，SQL 语句是不是终于可以执行了？ 从逻辑的角度来说，我们的数据是放在哪里的，或者说放在一个什么结构里面？ 执行计划在哪里执行？是谁去执行？ 表在存储数据的同时，还要组织数据的存储结构，这个存储结构就是由存储引擎决定的，所以也可以把存储引擎叫做表类型。 在 MySQL 里面，支持多种存储引擎，他们是可以替换的，所以叫做插件式的存储引擎。​ 5.1 查看存储引擎我们数据库里面已经存在的表，我们怎么查看它们的存储引擎呢？​ 1show table status from `数据库名`; 或者通过 DDL 建表语句来查看。​ 在 MySQL 里面，我们创建的每一张表都可以指定它的存储引擎，而不是一个数据库只能使用一个存储引擎。存储引擎的使用是以表为单位的。而且，创建表之后还可以修改存储引擎。​ 一张表使用的存储引擎决定存储数据的结构，那在服务器上它们是怎么存储的呢？先要找到数据库存放数据的路径：默认情况下，每个数据库有一个自己文件夹，以 yhd数据库为例。任何一个存储引擎都有一个 frm 文件，这个是表结构定义文件。不同的存储引擎存放数据的方式不一样，产生的文件也不一样，innodb 是 1 个，memory 没有，myisam 是两个。 5.2 存储引擎比较①常见存储引擎MyISAM 和 InnoDB 是我们用得最多的两个存储引擎，在 MySQL 5.5 版本之前，默认的存储引擎是 MyISAM，它是 MySQL 自带的。 5.5 版本之后默认的存储引擎改成了 InnoDB，最主要的原因还是 InnoDB 支持事务，支持行级别的锁，对于业务一致性要求高的场景来说更适合。 ②数据库支持的存储引擎可以用这个命令查看数据库对存储引擎的支持情况： 1show engines ; 其中有存储引擎的描述和对事务、XA 协议和 Savepoints 的支持。 XA 协议用来实现分布式事务（分为本地资源管理器，事务管理器）。 Savepoints 用来实现子事务（嵌套事务）。创建了一个 Savepoints 之后，事务就可以回滚到这个点，不会影响到创建 Savepoints 之前的操作。 ③MyISAM（3 个文件）应用范围比较小。表级锁定限制了读/写的性能，因此在 Web 和数据仓库配置中，它通常用于只读或以读为主的工作。 特点 支持表级别的锁（插入和更新会锁表）。不支持事务。 拥有较高的插入（insert）和查询（select）速度。 存储了表的行数（count 速度更快）。 适合：只读之类的数据分析的项目。 ④InnoDB（2个文件）mysql 5.7 中的默认存储引擎。InnoDB 是一个事务安全（与 ACID 兼容）的 MySQL存储引擎，它具有提交、回滚和崩溃恢复功能来保护用户数据。InnoDB 行级锁（不升级为更粗粒度的锁）和 Oracle 风格的一致非锁读提高了多用户并发性和性能。InnoDB 将用户数据存储在聚集索引中，以减少基于主键的常见查询的 I/O。为了保持数据完整性，InnoDB 还支持外键引用完整性约束。 特点 支持事务，支持外键，因此数据的完整性、一致性更高。 支持行级别的锁和表级别的锁。 支持读写并发，写不阻塞读（MVCC）。 特殊的索引存放方式，可以减少 IO，提升查询效率。 适合：经常更新的表，存在并发读写或者有事务处理的业务系统。 ⑤Memory(1个文件)基于内存的存储引擎。 特征： 基于内存的表，服务器重启后，表结构会被保留，但表中的数据会被清空。 不需要进行磁盘IO，比 MYISAM 快了一个数量级。 表级锁，故并发插入性能较低。 每一行是固定的，VARCHAR 列在 memory 存储引擎中会变成 CHAR，可能导致内存浪费。 不支持 BLOB 或 TEXT 列，如果sql返回的结果列中包含 BLOB 或 TEXT，就直接采用 MYISAM 存储引擎，在磁盘上建临时表 支持哈希索引，B+树索引 MEMORY 存储引擎在很多地方可以发挥很好的作用： 用于查找或映射表，例如邮编和州名的映射表 用于缓存周期性聚合数据的结果 用于保存数据分析中产生的中间结果。即SQL执行过程中用到的临时表 监控MySQL内存中的执行情况，例如：information_schema 库下的表基本都是 memory 存储引擎，监控InnoDB缓冲池中page(INNODB_BUFFER_PAGE表)，InnoDB缓冲池状态(INNODB_BUFFER_POOL_STATS表)、InnoDB缓存页淘汰记录(INNODB_BUFFER_PAGE_LRU表)、InnoDB锁等待(INNODB_LOCK_WAITS表)、InnoDB锁信息(INNODB_LOCKS表)、InnoDB中正在执行的事务(INNODB_TRX表)等。 MEMORY 存储引擎默认 hash 索引，故等值查询特别快。同时也支持B+树索引。虽然查询速度特别快，但依旧无法取代传统的磁盘建表。 ⑥CSV(3个文件)它的表实际上是带有逗号分隔值的文本文件。csv表允许以csv格式导入或转储数据，以便与读写相同格式的脚本和应用程序交换数据。因为 csv 表没有索引，所以通常在正常操作期间将数据保存在 innodb 表中，并且只在导入或导出阶段使用 csv 表。 特点 不允许空行，不支持索引。格式通用，可以直接编辑，适合在不同数据库之间导入导出。​ 5.3 如何选择存储引擎 如果对数据一致性要求比较高，需要事务支持，可以选择 InnoDB。 如果数据查询多更新少，对查询性能要求比较高，可以选择 MyISAM。 如果需要一个用于查询的临时表，可以选择 Memory。 ​ 6.执行引擎执行引擎，它利用存储引擎提供的相应的 API 来完成操作。 为什么我们修改了表的存储引擎，操作方式不需要做任何改变？因为不同功能的存储引擎实现的 API 是相同的。 最后把数据返回给客户端，即使没有结果也要返回。​ 二，一条SQL的更新流程更新和查询很多地方并没有区别，仅仅在于拿到数据之后的操作。 1.内存结构InnnoDB 的数据都是放在磁盘上的，InnoDB 操作数据有一个最小的逻辑单位，叫做页（索引页和数据页）。我们对于数据的操作，不是每次都直接操作磁盘，因为磁盘的速度太慢了。InnoDB 使用了一种缓冲池的技术，也就是把磁盘读到的页放到一块内存区域里面。这个内存区域就叫 Buffer Pool。​ 下一次读取相同的页，先判断是不是在缓冲池里面，如果是，就直接读取，不用再次访问磁盘。 修改数据的时候，先修改缓冲池里面的页。内存的数据页和磁盘数据不一致的时候，我们把它叫做脏页。InnoDB 里面有专门的后台线程把 Buffer Pool 的数据写入到磁盘，每隔一段时间就一次性地把多个修改写入磁盘，这个动作就叫做刷脏。 Buffer Pool 是 InnoDB 里面非常重要的一个结构，主要分为 3 个部分： Buffer Pool、Change Buffer、Adaptive HashIndex，另外还有一个（redo）log buffer。​ 1.1 buffer poolBuffer Pool 缓存的是页信息，包括数据页、索引页，默认大小是 128M（134217728 字节），可以调整。 查看服务器状态，里面有很多跟 Buffer Pool 相关的信息： 1SHOW STATUS LIKE &#x27;%innodb_buffer_pool%&#x27;; 查看参数（系统变量）： 1SHOW VARIABLES like &#x27;%innodb_buffer_pool%&#x27;; 内存的缓冲池写满了怎么办？（Redis 设置的内存满了怎么办？）InnoDB 用 LRU算法来管理缓冲池（链表实现，不是传统的 LRU，分成了 young 和 old），经过淘汰的数据就是热点数据。 内存缓冲区对于提升读写性能有很大的作用。当需要更新一个数据页时，如果数据页在 Buffer Pool 中存在，那么就直接更新好了。否则的话就需要从磁盘加载到内存，再对内存的数据页进行操作。也就是说，如果没有命中缓冲池，至少要产生一次磁盘 IO。​ 1.2 ChangeBuffer写缓冲如果这个数据页不是唯一索引，不存在数据重复的情况，也就不需要从磁盘加载索引页判断数据是不是重复（唯一性检查）。这种情况下可以先把修改记录在内存的缓冲池中，从而提升更新语句（Insert、Delete、Update）的执行速度。 这一块区域就是 Change Buffer。5.5 之前叫 Insert Buffer 插入缓冲，现在也能支持 delete 和 update。 最后把 Change Buffer 记录到数据页的操作叫做 merge。什么时候发生 merge？有几种情况：在访问这个数据页的时候，或者通过后台线程、或者数据库 shut down、redo log 写满时触发。 如果数据库大部分索引都是非唯一索引，并且业务是写多读少，不会在写数据后立刻读取，就可以使用 Change Buffer（写缓冲）。写多读少的业务，调大这个值： 1SHOW VARIABLES LIKE &#x27;innodb_change_buffer_max_size&#x27;; 代表 Change Buffer 占 Buffer Pool 的比例，默认 25%。​ 1.3 Adaptive Hash Index当我们需要访问某个页中的数据时，就会把该页从磁盘加载到Buffer Pool中，如果该页已经在Buffer Pool中的话直接使用就可以了。那么问题也就来了，我们怎么知道该页在不在Buffer Pool中呢？ 我们其实是根据表空间号 + 页号来定位一个页的，也就相当于表空间号 + 页号是一个key，缓存页就是对应的value，怎么通过一个key来快速找着一个value呢？那肯定是哈希表。 所以我们可以用表空间号 + 页号作为key，缓存页作为value创建一个哈希表，在需要访问某个页的数据时，先从哈希表中根据表空间号 + 页号看看有没有对应的缓存页，如果有，直接使用该缓存页就好，如果没有，那就从free链表中选一个空闲的缓存页，然后把磁盘中对应的页加载到该缓存页的位置。​ 1.4 （redo）Log Buffer​ 如果 Buffer Pool 里面的脏页还没有刷入磁盘时，数据库宕机或者重启，这些数据丢失。如果写操作写到一半，甚至可能会破坏数据文件导致数据库不可用。为了避免这个问题，InnoDB 把所有对页面的修改操作专门写入一个日志文件，并且在数据库启动时从这个文件进行恢复操作（实现 crash-safe）——用它来实现事务的持久性。​ 这个文件就是磁盘的 redo log（叫做重做日志），对应于/var/lib/mysql/目录下的ib_logfile0 和 ib_logfile1，每个 48M。这 种 日 志 和 磁 盘 配 合 的 整 个 过 程 ， 其 实 就 是 MySQL 里 的 WAL 技 术（Write-Ahead Logging），它的关键点就是先写日志，再写磁盘。 1show variables like &#x27;innodb_log%&#x27;; 值 含义 innodb_log_file_size 指定每个文件的大小，默认 48M innodb_log_files_in_group 指定文件的数量，默认为 2 innodb_log_group_home_dir 指定文件所在路径，相对或绝对。如果不指定，则为datadir 路径。 同样是写磁盘，为什么不直接写到 db file 里面去？为什么先写日志再写磁盘？ 磁盘的最小组成单元是扇区，通常是 512 个字节。操作系统和内存打交道，最小的单位是页 Page。操作系统和磁盘打交道，读写磁盘，最小的单位是块 Block。​ 如果我们所需要的数据是随机分散在不同页的不同扇区中，那么找到相应的数据需要等到磁臂旋转到指定的页，然后盘片寻找到对应的扇区，才能找到我们所需要的一块数据，依次进行此过程直到找完所有数据，这个就是随机 IO，读取数据速度较慢。 假设我们已经找到了第一块数据，并且其他所需的数据就在这一块数据后边，那么就不需要重新寻址，可以依次拿到我们所需的数据，这个就叫顺序 IO。 刷盘是随机 I/O，而记录日志是顺序 I/O，顺序 I/O 效率更高。因此先把修改写入日志，可以延迟刷盘时机，进而提升系统吞吐。 当然 redo log 也不是每一次都直接写入磁盘，在 Buffer Pool 里面有一块内存区域（Log Buffer）专门用来保存即将要写入日志文件的数据，默认 16M，它一样可以节省磁盘 IO。​ 1SHOW VARIABLES LIKE &#x27;innodb_log_buffer_size&#x27;; redo log 的内容主要是用于崩溃恢复。磁盘的数据文件，数据来自 buffer pool。redo log 写入磁盘，不是写入数据文件。 那么，Log Buffer 什么时候写入 log file？ 在我们写入数据到磁盘的时候，操作系统本身是有缓存的。flush 就是把操作系统缓冲区写入到磁盘。 log buffer 写入磁盘的时机，由一个参数控制，默认是 1。 1SHOW VARIABLES LIKE &#x27;innodb_flush_log_at_trx_commit&#x27;; 值 含义 0（延迟写） log buffer 将每秒一次地写入 log file 中，并且 log file 的 flush 操作同时进行。该模式下，在事务提交的时候，不会主动触发写入磁盘的操作。 1（默认，实时写，实时刷） 每次事务提交时 MySQL 都会把 log buffer 的数据写入 log file，并且刷到磁盘中去。 2（实时写，延迟刷） 每次事务提交时 MySQL 都会把 log buffer 的数据写入 log file。但是 flush 操作并不会同时进行。该模式下，MySQL 会每秒执行一次 flush 操作。 redo log，它又分成内存和磁盘两部分。redo log 有什么特点？ redo log 是 InnoDB 存储引擎实现的，并不是所有存储引擎都有。 不是记录数据页更新之后的状态，而是记录这个页做了什么改动，属于物理日志。（redo log 记录的是执行的结果） redo log 的大小是固定的，前面的内容会被覆盖。 check point 是当前要覆盖的位置。如果 write pos 跟 check point 重叠，说明 redolog 已经写满，这时候需要同步 redo log 到磁盘中。 这是 MySQL 的内存结构，总结一下，分为：Buffer pool、change buffer、Adaptive Hash Index、 log buffer。 磁盘结构里面主要是各种各样的表空间，叫做 Table space。 1.5 缓存的疑问缓存（cache）是在读取硬盘中的数据时，把最常用的数据保存在内存的缓存区中，再次读取该数据时，就不去硬盘中读取了，而在缓存中读取。缓冲（buffer）是在向硬盘写入数据时，先把数据放入缓冲区,然后再一起向硬盘写入，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。 然后，InnoDB架构中，有非常重要的一个部分——缓冲池。该缓冲池需要占用服务器内存，且专用于MySQL的服务器，建议把80%的内存交给MySQL。 缓冲池有一个缓存的功能。这个缓存，是InnoDB自带的，而且经常会用到。该缓存功能并不是MySQL架构中的缓存组件。这是两者最大的区别。 MySQL组件中的缓存 所处位置：MySQL架构中的缓存组件 缓存内容：缓存的是SQL 和 该SQL的查询结果。如果SQL的大小写，格式，注释不一致，则被认为是不同的SQL，重新查询数据库，并缓存一份数据。 可否关闭：是可以手动关闭，并卸载该组件的。 InnoDB中的缓存 所处位置：InnoDB架构中的缓冲池 缓存内容：缓存的是所有需要查找的数据，所在的数据页。 可否关闭：是InnoDB缓冲池自带的功能，无法关闭，无法卸载。如果InnoDB的缓冲池被关闭或卸载，则InnoDB直接瘫痪。所以说缓冲池是InnoDB的最重要的一部分。 不建议使用MySQL的缓存是指，不建议使用MySQL架构中的缓存组件，并不是同时否定了InnoDB中的缓存功能。​ 2.磁盘结构表空间可以看做是 InnoDB 存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。InnoDB 的表空间分为 5 大类。​ 2.1 系统表空间在默认情况下 InnoDB 存储引擎有一个共享表空间（对应文件/var/lib/mysql/ibdata1），也叫系统表空间。 InnoDB 系统表空间包含 InnoDB 数据字典和双写缓冲区，（Change Buffer 和 UndoLogs），如果没有指定 file-per-table，也包含用户创建的表和索引数据。 undo 在后面介绍，因为有独立的表空间。 数据字典：由内部系统表组成，存储表和索引的元数据（定义信息）。 双写缓冲（InnoDB 的一大特性） InnoDB 的页和操作系统的页大小不一致，InnoDB 页大小一般为 16K，操作系统页大小为 4K，InnoDB 的页写入到磁盘时，一个页需要分 4 次写。 如果存储引擎正在写入页的数据到磁盘时发生了宕机，可能出现页只写了一部分的情况，比如只写了 4K，就宕机了，这种情况叫做部分写失效（partial page write），可能会导致数据丢失。 1show variables like &#x27;innodb_doublewrite&#x27;; 如果这个页本身已经损坏了，用它来做崩溃恢复是没有意义的。所以在对于应用 redo log 之前，需要一个页的副本。如果出现了写入失效，就用页的副本来还原这个页，然后再应用 redo log。这个页的副本就是 double write，InnoDB 的双写技术。通过它实现了数据页的可靠性。 跟 redo log 一样，double write 由两部分组成，一部分是内存的 double write，一个部分是磁盘上的 double write。因为 double write 是顺序写入的，不会带来很大的开销。 在MySQL5.7之前，所有的表共享一个系统表空间，这个文件会越来越大，而且它的空间不会收缩。​ 2.2 独占表空间我们可以让每张表独占一个表空间。这个开关通过 innodb_file_per_table 设置，默认开启。 1SHOW VARIABLES LIKE &#x27;innodb_file_per_table&#x27;; 开启后，则每张表会开辟一个表空间，这个文件就是数据目录下的 ibd 文件，存放表的索引和数据。但是其他类的数据，如回滚（undo）信息，插入缓冲索引页、系统事务信息，二次写缓冲（Double write buffer）等还是存放在原来的共享表空间内。​ 2.3 通用表空间通用表空间也是一种共享的表空间，跟 ibdata1 类似。 可以创建一个通用的表空间，用来存储不同数据库的表，数据路径和文件可以自定义。语法： 1create tablespace ts2673 add datafile &#x27;/var/lib/mysql/ts2673.ibd&#x27; file_block_size=16K engine=innodb; 在创建表的时候可以指定表空间，用 ALTER 修改表空间可以转移表空间。 1create table t2673(id integer) tablespace ts2673; 不同表空间的数据是可以移动的。删除表空间需要先删除里面的所有表： 12drop table t2673;drop tablespace ts2673; 2.4 临时表空间存储临时表的数据，包括用户创建的临时表，和磁盘的内部临时表。对应数据目录下的 ibtmp1 文件。当数据服务器正常关闭时，该表空间被删除，下次重新产生。 memory向template的过渡，还有磁盘上简历临时表用的什么存储引擎？ 8.0之前，内存临时表用Memory引擎创建，但假如字段中有BLOB或TEXT,或结果太大，就会转用MYISM在磁盘上建表，8.0之后内存临时表由MEMORY引擎更改为TempTable引擎，相比于前者，后者支持以变长方式存储VARCHAR，VARBINARY等变长字段。从MySQL 8.0.13开始，TempTable引擎支持BLOB字段。如果超过内存表大小，则用InnoDB建表。 2.5 redo log2.6 undo log 表空间undo log（撤销日志或回滚日志）记录了事务发生之前的数据状态（不包括 select）。 如果修改数据时出现异常，可以用 undo log 来实现回滚操作（保持原子性）。 在执行 undo 的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，属于逻辑格式的日志(记录操作)。 redo Log 和 undo Log 与事务密切相关，统称为事务日志。 undo Log 的数据默认在系统表空间 ibdata1 文件中，因为共享表空间不会自动收缩，也可以单独创建一个 undo 表空间。 1show global variables like &#x27;%undo%&#x27;; 2.7 一条SQL的更新流程12# id =1 的记录原 name = &#x27;yhd&#x27;update user set name = &#x27;二十&#x27; where id=1; 事务开始，从内存或者磁盘取到这条数据，返回给server的执行器 执行器修改这一行数据的值为二十 记录name =yhd 到undo log 记录name = 二十 到redo log 调用存储引擎接口，在buffer pool 中修改 name =二十 事务提交 ​ 内存和磁盘之间，工作着很多后台线程。 3.后台线程后台线程的主要作用是负责刷新内存池中的数据和把修改的数据页刷新到磁盘。后台线程分为：master线程，IO 线程，purge 线程，page cleaner 线程。​ 3.1 Master 线程Master Thread是InnoDB存储引擎非常核心的一个后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲、UNDO页的回收等。​ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546void master_thread()&#123; loop: for(int i = 0; i &lt; 10; ++i)&#123; thread_sleep(1); // sleep 1秒 do log buffer flush to disk; if(last_one_second_ios &lt; 5) do merge at most 5 insert buffer; if(buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct) // 如果缓冲池中的脏页比例大于innodb_max_dirty_pages_pct(默认是75时) do buffer pool flush 100 dirty page; // 刷新100脏页到磁盘 if(no user activity) goto backgroud loop; &#125; if(last_ten_second_ios &lt; 200) // 如果过去10内磁盘IO次数小于设置的innodb_io_capacity的值（默认是200） do buffer pool flush 100 dirty page; do merge at most 5 insert buffer; // 合并插入缓冲是innodb_io_capacity的5%（10）（总是） do log buffer flush to disk; do full purge; if(buf_get_modified_ratio_pct &gt; 70%) do buffer pool flush 100 dirty page; else buffer pool flush 10 dirty page; backgroud loop： // 后台循环 do full purge // 删除无用的undo页 （总是） do merge 20 insert buffer; // 合并插入缓冲是innodb_io_capacity的5%（10）（总是） if not idle // 如果不空闲，就跳回主循环，如果空闲就跳入flush loop goto loop: // 跳到主循环 else goto flush loop flush loop: // 刷新循环 do buffer pool flush 100 dirty page; if(buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct) // 如果缓冲池中的脏页比例大于innodb_max_dirty_pages_pct的值（默认75%） goto flush loop; // 跳到刷新循环，不断刷新脏页，直到符合条件 goto suspend loop; // 完成刷新脏页的任务后，跳入suspend loop suspend loop: suspend_thread(); //master线程挂起，等待事件发生 waiting event; goto loop;&#125; Master Thread具有最高的线程优先级别。内部由多个循环组成：主循环（loop）、后台循环（backgroup loop）、刷新循环（flush loop）、暂停循环（suspend loop）。Master Thread会根据数据库运行的状态在loop、backgroup loop、flush loop和suspend loop中进行切换。loop是主循环，大多数的操作都在这个循环中，主要有两大部分的操作——每秒钟的操作和每10秒钟的操作。​ ①每秒钟的操作​ ​日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）；即使某个事务还没有提交，InnoDB存储引擎仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件。这也解释了为什么再大的事务提交的时间也是很短的。 合并插入缓冲（可能）；合并插入缓冲并不是每秒都会发生的。InnoDB存储引擎会判断当前一秒内发生的IO次数是否小于5次，如果小于5次，InnoDB存储引擎认为当前的IO压力很小，可以执行合并插入缓冲的操作； 至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）； 刷新100个脏页也不是每秒都会发生的，InnoDB存储引擎通过判断当前缓冲池中脏页的比例(buf_get_modified_ratio_pct)是否超过了配置文件中 innodb_max_dirty_pages_pct这个参数（默认是75，代表75%），如果超过了这个值，InnoDB存储引擎则认为需要做磁盘同步的操作，将100个脏页写入磁盘中。 如果当前没有用户活动，则切换到background loop(可能)。 ​ ②每十秒的操作 刷新100个脏页到磁盘（可能） InnoDB存储引擎会先判断过去10秒之内磁盘的IO操作是否小于200次，如果是，InnoDB存储引擎认为当前有足够的磁盘IO能力，因此将100个脏页刷新到磁盘。 合并至多5个插入缓冲（总是） 将日志缓冲刷新到磁盘（总是） 删除无用的Undo页（总是） 刷新100个或者10个脏页到磁盘（总是） InnoDB存储引擎会执行full purge操作，即删除无用的Undo页。对表进行update，delete这类的操作时，原先的行被标记为删除，但是因为一致性读的关系，需要保留这些行版本的信息。但是在full purge过程中，InnoDB存储引擎会判断当前事务系统中已被删除的行是否可以删除，比如有时候可能还有查询操作需要读取之前版本的undo信息，如果可以删除，InnoDB存储引擎会立即将其删除。从源代码中可以看出，InnoDB存储引擎在执行full purge 操作时，每次最多尝试回收20个undo页。然后，InnoDB存储引擎会判断缓冲池中脏页的比例（buf_get_modified_ratio_pct）,如果有超过70%的脏页，则刷新100个脏页到磁盘，如果脏页的比例小于70%,则只需刷新10%的脏页到磁盘。 ​ 如果当前没有用户活动（数据库空闲）或者数据库关系，就会切换到backgroud loop这个循环。 backgroud loop会执行以下操作： 删除无用的Undo页（总是） 合并20个插入缓冲（总是） 跳回到主循环（总是） 不断刷新100个页直到符合条件（可能，需要跳转到flush loop中完成） 如果flush loop中也没有什么事情可以做了，InnoDB存储引擎会切换到suspend_loop，将Master Thread挂起，等待事件的发生。若用户启用了InnoDB存储引擎，却没有使用任何InnoDB存储引擎的表，那么Master Thread总是处于挂起的状态。​ 1.0.x版本中，InnoDB存储引擎最多只会刷新100个脏页到磁盘，合并20个插入缓冲。如果是在写入密集的应用程序中，每秒可能会产生大于100个的脏页，如果是产生大于20个插入缓冲的情况，那么可能会来不及刷新所有的脏页以及合并插入缓冲。后来，InnoDB存储引擎提供了参数innodb_io_capacity，用来表示磁盘IO的吞吐量，默认值为200。​ 对于刷新到磁盘的页的数量，会按照innodb_io_capacity的百分比来进行控制。规则如下： 在合并插入缓冲时，合并插入缓冲的数量为innodb_io_capacity值的5%; 在从缓冲区刷新脏页时，刷新脏页的数量为innodb_io_capacity; 如果用户使用的是SSD类的磁盘，可以将innodb_io_capacity的值调高，直到符合磁盘IO的吞吐量为止； 另一个问题是参数innodb_max_dirty_pages_pct的默认值，在1.0.x版本之前，该值的默认值是90，意味着脏页占缓冲池的90%。InnoDB存储引擎在每秒刷新缓冲池和flush loop时会判断这个值，如果该值大于innodb_max_dirty_pages_pct,才会刷新100个脏页，如果有很大的内存，或者数据库服务器的压力很大，这时刷新脏页的速度反而会降低。 后来将innodb_max_dirty_pages_pct的默认值改为了75。这样既可以加快刷新脏页的频率，又能够保证磁盘IO的负载。​ 还有一个新的参数是innodb_adaptive_flushing(自适应地刷新)，该值影响每秒刷新脏页的数量。原来的刷新规则是：脏页在缓冲池所占的比例小于innodb_max_dirty_pages_pct时，不刷新脏页；大于innodb_max_dirty_pages_pct时，刷新100个脏页。随着innodb_adaptive_flushing参数的引入，InnoDB通过一个名为buf_flush_get_desired_flush_rate的函数来判断需要刷新脏页最合适的数量。buf_flush_get_desired_flush_rate函数通过判断产生重做日志的速率来决定最合适的刷新脏页数量。 之前每次进行full purge 操作时，最多回收20个Undo页，从InnoDB 1.0.x版本开始引入了参数innodb_purge_batch_size,该参数可以控制每次full purge回收的Undo页的数量。该参数的默认值为20，并可以动态地对其进行修改。​ 1.2.x版本中再次对Master Thread进行了优化，对于刷新脏页的操作，从Master Thread线程分离到一个单独的Page Cleaner Thread，从而减轻了Master Thread的工作，同时进一步提高了系统的并发性。​ 3.2 IO 线程InnoDB中大量使用AIO (Async IO) 来处理IO请求。IO Thread的作用，是负责这些 IO 请求的回调（call back）。​ 3.3 Purge 线程事务被提交后，其所使用的undo log可能不在需要。因此，需要purge thread来回收已经使用并分配的undo页。以前Master Thread来完成释放undo log，InnoDB1.1独立出来，分担主线程压力。​ 3.4 Page Cleaner 线程​ 负责将脏页刷新到磁盘。以前Master Thread来刷新脏页，InnoDB1.2独立出来，分担主线程压力。​ 除了 InnoDB 架构中的日志文件，MySQL 的 Server 层也有一个日志文件，叫做binlog，它可以被所有的存储引擎使用。 4.binlogbinlog 以事件的形式记录了所有的DDL 和DML 语句（因为它记录的是操作而不是数据值，属于逻辑日志），可以用来做主从复制和数据恢复。跟redo log不一样，它的文件内容是可以追加的，没有固定大小限制。在开启了 binlog 功能的情况下，我们可以把 binlog 导出成 SQL 语句，把所有的操作重放一遍，来实现数据的恢复。binlog 的另一个功能就是用来实现主从复制，它的原理就是从服务器读取主服务器的 binlog，然后执行一遍。​ 有了这两个日志之后，来看一下一条更新语句是怎么执行的：​ 12# id =1 的记录原 name = &#x27;yhd&#x27;update user set name = &#x27;二十&#x27; where id=1; ​ 事务开始，从内存或者磁盘取到这条数据所在的数据页，返回给server的执行器 执行器修改这一行数据的值为二十 记录name =yhd 到undo log 在buffer pool 中修改 name =二十，此时该页变成脏页 记录name = 二十 到redo log buffer，redo log buffer每秒刷盘。 redo log 进入prepare状态，然后告诉执行器，执行完成了，可以随时提交 写入binlog 事务提交，并回写最终状态到redo log里，代表该事务已经提交 ​ 事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便不断写入redo log文件中。一般情况下，每次事务commit时，必须调用 fsync 操作，将redo日志缓冲同步写到磁盘。另外，每次事务提交时同步写到磁盘bin log中。 那么就有了一个谁先谁后的问题：redo log 先，bin log 后。 两阶段提交的内容：**事务提交时，redo log处于 pre状态 -&gt; 写入bin log -&gt; 事务真正提交。 ** 当发生崩溃恢复时，查看的是bin log是否完整，如果bin log完整，则代表事务已经提交。 如果在两阶段提交过程中，bin log写入失败，则事务无法终止提交，崩溃恢复时就不需要重做。如果bin log写完的一瞬间，服务器宕机了，事务都来不及提交，此时bin log并不是完整的，缺少了最终的commit标记。因此也是提交失败。 简单说，redo log和bin log都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。 三，MySQL中支持的字符集和排序规则1.MySQL中的utf8和utf8mb4utf8字符集表示一个字符需要使用1～4个字节，但是我们常用的一些字符使用1～3个字节就可以表示了。而在MySQL中字符集表示一个字符所用最大字节长度在某些方面会影响系统的存储和性能，所以设计MySQL的大叔偷偷的定义了两个概念： utf8mb3：阉割过的utf8字符集，只使用1～3个字节表示字符。 utf8mb4：正宗的utf8字符集，使用1～4个字节表示字符。 在MySQL中utf8是utf8mb3的别名，所以之后在MySQL中提到utf8就意味着使用1~3个字节来表示一个字符，如果有使用4字节编码一个字符的情况，比如存储一些emoji表情啥的，那请使用utf8mb4。 查看字符集：SHOW (CHARACTER SET|CHARSET)。 2.字符集&amp;比较规则的应用2.1 各级别的字符集和比较规则MySQL有4个级别的字符集和比较规则，分别是： 服务器级别 数据库级别 表级别 列级别 接下来仔细看一下怎么设置和查看这几个级别的字符集和比较规则。 服务器级别123456789101112131415mysql&gt; SHOW VARIABLES LIKE &#x27;character_set_server&#x27;;+----------------------+-------+| Variable_name | Value |+----------------------+-------+| character_set_server | utf8 |+----------------------+-------+1 row in set (0.00 sec)mysql&gt; SHOW VARIABLES LIKE &#x27;collation_server&#x27;;+------------------+-----------------+| Variable_name | Value |+------------------+-----------------+| collation_server | utf8_general_ci |+------------------+-----------------+1 row in set (0.00 sec) 可以在启动服务器程序时通过启动选项或者在服务器程序运行过程中使用SET语句修改这两个变量的值。比如我们可以在配置文件中这样写： 123[server]character_set_server=gbkcollation_server=gbk_chinese_ci 当服务器启动的时候读取这个配置文件后这两个系统变量的值便修改了。 数据库级别我们在创建和修改数据库的时候可以指定该数据库的字符集和比较规则，具体语法如下： 1234567CREATE DATABASE 数据库名 [[DEFAULT] CHARACTER SET 字符集名称] [[DEFAULT] COLLATE 比较规则名称];ALTER DATABASE 数据库名 [[DEFAULT] CHARACTER SET 字符集名称] [[DEFAULT] COLLATE 比较规则名称]; 其中的DEFAULT可以省略，并不影响语句的语义。比方说我们新创建一个名叫charset_demo_db的数据库，在创建的时候指定它使用的字符集为gb2312，比较规则为gb2312_chinese_ci： 1234mysql&gt; CREATE DATABASE charset_demo_db -&gt; CHARACTER SET gb2312 -&gt; COLLATE gb2312_chinese_ci;Query OK, 1 row affected (0.01 sec) 查看 1234567891011121314151617181920mysql&gt; USE charset_demo_db;Database changedmysql&gt; SHOW VARIABLES LIKE &#x27;character_set_database&#x27;;+------------------------+--------+| Variable_name | Value |+------------------------+--------+| character_set_database | gb2312 |+------------------------+--------+1 row in set (0.00 sec)mysql&gt; SHOW VARIABLES LIKE &#x27;collation_database&#x27;;+--------------------+-------------------+| Variable_name | Value |+--------------------+-------------------+| collation_database | gb2312_chinese_ci |+--------------------+-------------------+1 row in set (0.00 sec)mysql&gt; 可以看到这个charset_demo_db数据库的字符集和比较规则就是我们在创建语句中指定的。需要注意的一点是： character_set_database 和 _collation_database_ 这两个系统变量是只读的，我们不能通过修改这两个变量的值而改变当前数据库的字符集和比较规则。 表级别我们也可以在创建和修改表的时候指定表的字符集和比较规则，语法如下： 1234567CREATE TABLE 表名 (列的信息) [[DEFAULT] CHARACTER SET 字符集名称] [COLLATE 比较规则名称]]ALTER TABLE 表名 [[DEFAULT] CHARACTER SET 字符集名称] [COLLATE 比较规则名称] 比方说我们在刚刚创建的charset_demo_db数据库中创建一个名为t的表，并指定这个表的字符集和比较规则： 1234mysql&gt; CREATE TABLE t( -&gt; col VARCHAR(10) -&gt; ) CHARACTER SET utf8 COLLATE utf8_general_ci;Query OK, 0 rows affected (0.03 sec) 如果创建和修改表的语句中没有指明字符集和比较规则，将使用该表所在数据库的字符集和比较规则作为该表的字符集和比较规则。 列级别需要注意的是，对于存储字符串的列，同一个表中的不同的列也可以有不同的字符集和比较规则。我们在创建和修改列定义的时候可以指定该列的字符集和比较规则，语法如下： 123456CREATE TABLE 表名( 列名 字符串类型 [CHARACTER SET 字符集名称] [COLLATE 比较规则名称], 其他列...);ALTER TABLE 表名 MODIFY 列名 字符串类型 [CHARACTER SET 字符集名称] [COLLATE 比较规则名称]; 比如我们修改一下表t中列col的字符集和比较规则可以这么写： 12345mysql&gt; ALTER TABLE t MODIFY col VARCHAR(10) CHARACTER SET gbk COLLATE gbk_chinese_ci;Query OK, 0 rows affected (0.04 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; 对于某个列来说，如果在创建和修改的语句中没有指明字符集和比较规则，将使用该列所在表的字符集和比较规则作为该列的字符集和比较规则。 在转换列的字符集时需要注意，如果转换前列中存储的数据不能用转换后的字符集进行表示会发生错误。比方说原先列使用的字符集是utf8，列中存储了一些汉字，现在把列的字符集转换为ascii的话就会出错，因为ascii字符集并不能表示汉字字符。 2.2 客户端和服务器通信中的字符集编码和解码使用的字符集不一致的后果如果对于同一个字符串编码和解码使用的字符集不一样，会产生意想不到的结果，作为人类的我们看上去就像是产生了乱码一样。 从发送请求到接收结果过程中发生的字符集转换 客户端使用操作系统的字符集编码请求字符串，向服务器发送的是经过编码的一个字节串。 服务器将客户端发送来的字节串采用character_set_client代表的字符集进行解码，将解码后的字符串再按照character_set_connection代表的字符集进行编码。 如果character_set_connection代表的字符集和具体操作的列使用的字符集一致，则直接进行相应操作，否则的话需要将请求中的字符串从character_set_connection代表的字符集转换为具体操作的列使用的字符集之后再进行操作。 将从某个列获取到的字节串从该列使用的字符集转换为character_set_results代表的字符集后发送到客户端。 客户端使用操作系统的字符集解析收到的结果集字节串。 在这个过程中各个系统变量的含义如下： 系统变量 描述 character_set_client 服务器解码请求时使用的字符集 character_set_connection 服务器处理请求时会把请求字符串从character_set_client转为character_set_connection character_set_results 服务器向客户端返回数据时使用的字符集 一般情况下要使用保持这三个变量的值和客户端使用的字符集相同。 比较规则的作用通常体现比较字符串大小的表达式以及对某个字符串列进行排序中。​","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"}]},{"title":"ConcurrentHashMap源码解读","slug":"1.基础知识/ConcurrentHashMap","date":"2022-01-05T12:23:06.000Z","updated":"2022-01-05T12:23:06.000Z","comments":true,"path":"2022/01/05/1.基础知识/ConcurrentHashMap/","link":"","permalink":"https://yinhuidong.github.io/2022/01/05/1.%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/ConcurrentHashMap/","excerpt":"","text":"#1.成员变量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147//散列表数组的最大限制private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//散列表默认值private static final int DEFAULT_CAPACITY = 16;static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;//并发级别：jdk7历史遗留问题，仅仅在初始化的时候使用到，并不是真正的代表并发级别private static final int DEFAULT_CONCURRENCY_LEVEL = 16;//负载因子，JDK1.8中 ConcurrentHashMap 是固定值private static final float LOAD_FACTOR = 0.75f;//树化阈值，指定桶位 链表长度达到8的话，有可能发生树化操作。static final int TREEIFY_THRESHOLD = 8;//红黑树转化为链表的阈值static final int UNTREEIFY_THRESHOLD = 6;//联合TREEIFY_THRESHOLD控制桶位是否树化，只有当table数组长度达到64且 某个桶位 中的链表长度达到8，才会真正树化static final int MIN_TREEIFY_CAPACITY = 64;//线程迁移数据最小步长，控制线程迁移任务最小区间一个值private static final int MIN_TRANSFER_STRIDE = 16;//计算扩容时候生成的一个 标识戳private static int RESIZE_STAMP_BITS = 16;//结果是65535 表示并发扩容最多线程数private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;//扩容相关private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;//当node节点hash=-1 表示当前节点已经被迁移了 ，fwd节点static final int MOVED = -1; // hash for forwarding nodes//node hash=-2 表示当前节点已经树化 且 当前节点为treebin对象 ，代理操作红黑树static final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservations//转化成二进制实际上是 31个 1 可以将一个负数通过位移运算得到一个正数static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash//当前系统的cpu数量static final int NCPU = Runtime.getRuntime().availableProcessors();//为了兼容7版本的chp保存的，核心代码并没有使用到private static final ObjectStreamField[] serialPersistentFields = &#123; new ObjectStreamField(&quot;segments&quot;, Segment[].class), new ObjectStreamField(&quot;segmentMask&quot;, Integer.TYPE), new ObjectStreamField(&quot;segmentShift&quot;, Integer.TYPE) &#125;;//散列表，长度一定是2次方数transient volatile Node&lt;K,V&gt;[] table;//扩容过程中，会将扩容中的新table 赋值给nextTable 保持引用，扩容结束之后，这里会被设置为Nullprivate transient volatile Node&lt;K,V&gt;[] nextTable;//LongAdder 中的 baseCount 未发生竞争时 或者 当前LongAdder处于加锁状态时，增量累到到baseCount中private transient volatile long baseCount;/** * sizeCtl &lt; 0 * 1. -1 表示当前table正在初始化（有线程在创建table数组），当前线程需要自旋等待.. * 2.表示当前table数组正在进行扩容 ,高16位表示：扩容的标识戳 低16位表示：（1 + nThread） 当前参与并发扩容的线程数量 * * sizeCtl = 0，表示创建table数组时 使用DEFAULT_CAPACITY为大小 * * sizeCtl &gt; 0 * * 1. 如果table未初始化，表示初始化大小 * 2. 如果table已经初始化，表示下次扩容时的 触发条件（阈值） */private transient volatile int sizeCtl;/** * * 扩容过程中，记录当前进度。所有线程都需要从transferIndex中分配区间任务，去执行自己的任务。 */private transient volatile int transferIndex;/** * LongAdder中的cellsBuzy 0表示当前LongAdder对象无锁状态，1表示当前LongAdder对象加锁状态 */private transient volatile int cellsBusy;/** * LongAdder中的cells数组，当baseCount发生竞争后，会创建cells数组， * 线程会通过计算hash值 取到 自己的cell ，将增量累加到指定cell中 * 总数 = sum(cells) + baseCount */private transient volatile CounterCell[] counterCells;// Unsafe mechanicsprivate static final sun.misc.Unsafe U;/**表示sizeCtl属性在ConcurrentHashMap中内存偏移地址*/private static final long SIZECTL;/**表示transferIndex属性在ConcurrentHashMap中内存偏移地址*/private static final long TRANSFERINDEX;/**表示baseCount属性在ConcurrentHashMap中内存偏移地址*/private static final long BASECOUNT;/**表示cellsBusy属性在ConcurrentHashMap中内存偏移地址*/private static final long CELLSBUSY;/**表示cellValue属性在CounterCell中内存偏移地址*/private static final long CELLVALUE;/**表示数组第一个元素的偏移地址*/private static final long ABASE;private static final int ASHIFT;static &#123; try &#123; U = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = ConcurrentHashMap.class; SIZECTL = U.objectFieldOffset (k.getDeclaredField(&quot;sizeCtl&quot;)); TRANSFERINDEX = U.objectFieldOffset (k.getDeclaredField(&quot;transferIndex&quot;)); BASECOUNT = U.objectFieldOffset (k.getDeclaredField(&quot;baseCount&quot;)); CELLSBUSY = U.objectFieldOffset (k.getDeclaredField(&quot;cellsBusy&quot;)); Class&lt;?&gt; ck = CounterCell.class; CELLVALUE = U.objectFieldOffset (ck.getDeclaredField(&quot;value&quot;)); Class&lt;?&gt; ak = Node[].class; ABASE = U.arrayBaseOffset(ak); //表示数组单元所占用空间大小,scale 表示Node[]数组中每一个单元所占用空间大小 int scale = U.arrayIndexScale(ak); //1 0000 &amp; 0 1111 = 0 if ((scale &amp; (scale - 1)) != 0) throw new Error(&quot;data type scale not a power of two&quot;); //numberOfLeadingZeros() 这个方法是返回当前数值转换为二进制后，从高位到低位开始统计，看有多少个0连续在一块。 //8 =&gt; 1000 numberOfLeadingZeros(8) = 28 //4 =&gt; 100 numberOfLeadingZeros(4) = 29 //ASHIFT = 31 - 29 = 2 ？？ //ABASE + （5 &lt;&lt; ASHIFT） ASHIFT = 31 - Integer.numberOfLeadingZeros(scale); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; #2.基础方法##2.1 spread高位运算 123static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; ##2.2 tabAt该方法获取对象中offset偏移地址对应的对象field的值。实际上这段代码的含义等价于tab[i],但是为什么不直接使用 tab[i]来计算呢？ getObjectVolatile，一旦看到 volatile 关键字，就表示可见性。因为对 volatile 写操作 happen-before 于 volatile 读操作，因此其他线程对 table 的修改均对 get 读取可见； 虽然 table 数组本身是增加了 volatile 属性，但是“volatile 的数组只针对数组的引用具有volatile 的语义，而不是它的元素”。 所以如果有其他线程对这个数组的元素进行写操作，那么当前线程来读的时候不一定能读到最新的值。出于性能考虑，Doug Lea 直接通过 Unsafe 类来对 table 进行操作。 123static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; ##2.3 casTabAtcas设置当前节点为桶位的头节点 1234static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; ##2.4 setTabAt 123static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; ##2.5 resizeStampresizeStamp 用来生成一个和扩容有关的扩容戳，具体有什么作用呢？ 123static final int resizeStamp(int n) &#123; return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));&#125; Integer.numberOfLeadingZeros 这个方法是返回无符号整数 n 最高位非 0 位前面的 0 的个数。 比如 10 的二进制是 0000 0000 0000 0000 0000 0000 0000 1010，那么这个方法返回的值就是 28。 根据 resizeStamp 的运算逻辑，我们来推演一下，假如 n=16，那么 resizeStamp(16)=32796转化为二进制是[0000 0000 0000 0000 1000 0000 0001 1100] 接着再来看,当第一个线程尝试进行扩容的时候，会执行下面这段代码： U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)rs 左移 16 位，相当于原本的二进制低位变成了高位 1000 0000 0001 1100 0000 0000 00000000 然后再+2 =1000 0000 0001 1100 0000 0000 0000 0000+10=1000 0000 0001 1100 0000 00000000 0010 高 16 位代表扩容的标记、低 16 位代表并行扩容的线程数 这样来存储有什么好处呢？ 1，首先在 CHM 中是支持并发扩容的，也就是说如果当前的数组需要进行扩容操作，可以由多个线程来共同负责 2，可以保证每次扩容都生成唯一的生成戳，每次新的扩容，都有一个不同的 n，这个生成戳就是根据 n 来计算出来的一个数字，n 不同，这个数字也不同 第一个线程尝试扩容的时候，为什么是+2 因为 1 表示初始化，2 表示一个线程在执行扩容，而且对 sizeCtl 的操作都是基于位运算的，所以不会关心它本身的数值是多少，只关心它在二进制上的数值，而 sc + 1 会在低 16 位上加 1。##2.6 tableSizeFor经过多次位移返回大于等于c的最小的二次方数 1234567891011121314151617181920 /** * Returns a power of two table size for the given desired capacity. * See Hackers Delight, sec 3.2 * 返回&gt;=c的最小的2的次方数 * c=28 * n=27 =&gt; 0b 11011 * 11011 | 01101 =&gt; 11111 * 11111 | 00111 =&gt; 11111 * .... * =&gt; 11111 + 1 =100000 = 32 */private static final int tableSizeFor(int c) &#123; int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; #3. 构造方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public ConcurrentHashMap() &#123;&#125;public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); //如果指定的容量超过允许的最大值，设置为最大值 int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); /** * sizeCtl &gt; 0 * 当目前table未初始化时，sizeCtl表示初始化容量 */ this.sizeCtl = cap;&#125;public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.sizeCtl = DEFAULT_CAPACITY; putAll(m);&#125;public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, 1);&#125;public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; //参数校验 if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); //如果初始容量小于并发级别，那就设置初始容量为并发级别 if (initialCapacity &lt; concurrencyLevel) initialCapacity = concurrencyLevel; //16/0.75 +1 = 22 long size = (long)(1.0 + (long)initialCapacity / loadFactor); // 22 - &gt; 32 int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); /** * sizeCtl &gt; 0 * 当目前table未初始化时，sizeCtl表示初始化容量 */ this.sizeCtl = cap;&#125; #4.put 1234public V put(K key, V value) &#123; //如果key已经存在，是否覆盖，默认是false return putVal(key, value, false);&#125; #5 putVal 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //控制k 和 v 不能为null if (key == null || value == null) throw new NullPointerException(); //通过spread方法，可以让高位也能参与进寻址运算。 int hash = spread(key.hashCode()); //binCount表示当前k-v 封装成node后插入到指定桶位后，在桶位中的所属链表的下标位置 //0 表示当前桶位为null，node可以直接放着 //2 表示当前桶位已经可能是红黑树 int binCount = 0; //tab 引用map对象的table //自旋 for (Node&lt;K,V&gt;[] tab = table;;) &#123; //f 表示桶位的头结点 //n 表示散列表数组的长度 //i 表示key通过寻址计算后，得到的桶位下标 //fh 表示桶位头结点的hash值 Node&lt;K,V&gt; f; int n, i, fh; //CASE1：成立，表示当前map中的table尚未初始化.. if (tab == null || (n = tab.length) == 0) //最终当前线程都会获取到最新的map.table引用。 tab = initTable(); //CASE2：i 表示key使用路由寻址算法得到 key对应 table数组的下标位置，tabAt 获取指定桶位的头结点 f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //进入到CASE2代码块 前置条件 当前table数组i桶位是Null时。 //使用CAS方式 设置 指定数组i桶位 为 new Node&lt;K,V&gt;(hash, key, value, null),并且期望值是null //cas操作成功 表示ok，直接break for循环即可 //cas操作失败，表示在当前线程之前，有其它线程先你一步向指定i桶位设置值了。 //当前线程只能再次自旋，去走其它逻辑。 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //CASE3：前置条件，桶位的头结点一定不是null。 //条件成立表示当前桶位的头结点 为 FWD结点，表示目前map正处于扩容过程中.. else if ((fh = f.hash) == MOVED) //看到fwd节点后，当前节点有义务帮助当前map对象完成迁移数据的工作 //帮助扩容 tab = helpTransfer(tab, f); //CASE4：当前桶位 可能是 链表 也可能是 红黑树代理结点TreeBin else &#123; //当插入key存在时，会将旧值赋值给oldVal，返回给put方法调用处.. V oldVal = null; //使用sync 加锁“头节点”，理论上是“头结点” synchronized (f) &#123; //为什么又要对比一下，看看当前桶位的头节点 是否为 之前获取的头结点？ //为了避免其它线程将该桶位的头结点修改掉，导致当前线程从sync 加锁 就有问题了。之后所有操作都不用在做了。 if (tabAt(tab, i) == f) &#123;//条件成立，说明咱们 加锁 的对象没有问题，可以进来造了！ //条件成立，说明当前桶位就是普通链表桶位。 if (fh &gt;= 0) &#123; //1.当前插入key与链表当中所有元素的key都不一致时，当前的插入操作是追加到链表的末尾，binCount表示链表长度 //2.当前插入key与链表当中的某个元素的key一致时，当前插入操作可能就是替换了。binCount表示冲突位置（binCount - 1） binCount = 1; //迭代循环当前桶位的链表，e是每次循环处理节点。 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; //当前循环节点 key K ek; //条件一：e.hash == hash 成立 表示循环的当前元素的hash值与插入节点的hash值一致，需要进一步判断 //条件二：((ek = e.key) == key ||(ek != null &amp;&amp; key.equals(ek))) // 成立：说明循环的当前节点与插入节点的key一致，发生冲突了 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; //将当前循环的元素的 值 赋值给oldVal oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; //当前元素 与 插入元素的key不一致 时，会走下面程序。 //1.更新循环处理节点为 当前节点的下一个节点 //2.判断下一个节点是否为null，如果是null，说明当前节点已经是队尾了，插入数据需要追加到队尾节点的后面。 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //前置条件，该桶位一定不是链表 //条件成立，表示当前桶位是 红黑树代理结点TreeBin else if (f instanceof TreeBin) &#123; //p 表示红黑树中如果与你插入节点的key 有冲突节点的话 ，则putTreeVal 方法 会返回冲突节点的引用。 Node&lt;K,V&gt; p; //强制设置binCount为2，因为binCount &lt;= 1 时有其它含义，所以这里设置为了2 binCount = 2; //条件一：成立，说明当前插入节点的key与红黑树中的某个节点的key一致，冲突了 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; //将冲突节点的值 赋值给 oldVal oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; //说明当前桶位不为null，可能是红黑树 也可能是链表 if (binCount != 0) &#123; //如果binCount&gt;=8 表示处理的桶位一定是链表 if (binCount &gt;= TREEIFY_THRESHOLD) //调用转化链表为红黑树的方法 treeifyBin(tab, i); //说明当前线程插入的数据key，与原有k-v发生冲突，需要将原数据v返回给调用者。 if (oldVal != null) return oldVal; break; &#125; &#125; &#125; //1.统计当前table一共有多少数据 //2.判断是否达到扩容阈值标准，触发扩容。 addCount(1L, binCount); return null;&#125; #6 initTable数组初始化方法，这个方法比较简单，就是初始化一个合适大小的数组。 sizeCtl ：这个标志是在 Node 数组初始化或者扩容的时候的一个控制位标识，负数代表正在进行初始化或者扩容操作。 -1 代表正在初始化 -N 代表有 N-1 个线程正在进行扩容操作，这里不是简单的理解成 n 个线程，sizeCtl 就是-N 0 标识 Node 数组还没有被初始化，正数代表初始化或者下一次扩容的大小 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Initializes table, using the size recorded in sizeCtl. * * sizeCtl &lt; 0 * * 1. -1 表示当前table正在初始化（有线程在创建table数组），当前线程需要自旋等待.. * * 2.表示当前table数组正在进行扩容 ,高16位表示：扩容的标识戳 低16位表示：（1 + nThread） 当前参与并发扩容的线程数量 * * * * sizeCtl = 0，表示创建table数组时 使用DEFAULT_CAPACITY为大小 * * * * sizeCtl &gt; 0 * * * * 1. 如果table未初始化，表示初始化大小 * * 2. 如果table已经初始化，表示下次扩容时的 触发条件（阈值） */private final Node&lt;K,V&gt;[] initTable() &#123; //tab 引用map.table //sc sizeCtl的临时值 Node&lt;K,V&gt;[] tab; int sc; //自旋 条件：map.table 尚未初始化 while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) //大概率就是-1，表示其它线程正在进行创建table的过程，当前线程没有竞争到初始化table的锁。 Thread.yield(); // lost initialization race; just spin //1.sizeCtl = 0，表示创建table数组时 使用DEFAULT_CAPACITY为大小 //2.如果table未初始化，表示初始化大小 //3.如果table已经初始化，表示下次扩容时的 触发条件（阈值） else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; //这里为什么又要判断呢？ 防止其它线程已经初始化完毕了，然后当前线程再次初始化..导致丢失数据。 //条件成立，说明其它线程都没有进入过这个if块，当前线程就是具备初始化table权利了。 if ((tab = table) == null || tab.length == 0) &#123; //sc大于0 创建table时 使用 sc为指定大小，否则使用 16 默认值. int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; //最终赋值给 map.table table = tab = nt; //n &gt;&gt;&gt; 2 =&gt; 等于 1/4 n n - (1/4)n = 3/4 n =&gt; 0.75 * n //sc 0.75 n 表示下一次扩容时的触发条件。 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; //1.如果当前线程是第一次创建map.table的线程话，sc表示的是 下一次扩容的阈值 //2.表示当前线程 并不是第一次创建map.table的线程，当前线程进入到else if 块 时，将 //sizeCtl 设置为了-1 ，那么这时需要将其修改为 进入时的值。 sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; #7 addCount 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124private final void addCount(long x, int check) &#123; //as 表示 LongAdder.cells //b 表示LongAdder.base //s 表示当前map.table中元素的数量 CounterCell[] as; long b, s; //条件一：true-&gt;表示cells已经初始化了，当前线程应该去使用hash寻址找到合适的cell 去累加数据 // false-&gt;表示当前线程应该将数据累加到 base //条件二：false-&gt;表示写base成功，数据累加到base中了，当前竞争不激烈，不需要创建cells // true-&gt;表示写base失败，与其他线程在base上发生了竞争，当前线程应该去尝试创建cells。 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; //有几种情况进入到if块中？ //1.true-&gt;表示cells已经初始化了，当前线程应该去使用hash寻址找到合适的cell 去累加数据 //2.true-&gt;表示写base失败，与其他线程在base上发生了竞争，当前线程应该去尝试创建cells。 //a 表示当前线程hash寻址命中的cell CounterCell a; //v 表示当前线程写cell时的期望值 long v; //m 表示当前cells数组的长度 int m; //true -&gt; 未竞争 false-&gt;发生竞争 boolean uncontended = true; //条件一：as == null || (m = as.length - 1) &lt; 0 //true-&gt; 表示当前线程是通过 写base竞争失败 然后进入的if块，就需要调用fullAddCount方法去扩容 或者 重试.. LongAdder.longAccumulate //条件二：a = as[ThreadLocalRandom.getProbe() &amp; m]) == null 前置条件：cells已经初始化了 //true-&gt;表示当前线程命中的cell表格是个空，需要当前线程进入fullAddCount方法去初始化 cell，放入当前位置. //条件三：!(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x) // false-&gt;取反得到false，表示当前线程使用cas方式更新当前命中的cell成功 // true-&gt;取反得到true,表示当前线程使用cas方式更新当前命中的cell失败，需要进入fullAddCount进行重试 或者 扩容 cells。 if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) ) &#123; fullAddCount(x, uncontended); //考虑到fullAddCount里面的事情比较累，就让当前线程 不参与到 扩容相关的逻辑了，直接返回到调用点。 return; &#125; if (check &lt;= 1) return; //获取当前散列表元素个数，这是一个期望值 s = sumCount(); &#125; //表示一定是一个put操作调用的addCount if (check &gt;= 0) &#123; //tab 表示map.table //nt 表示map.nextTable //n 表示map.table数组的长度 //sc 表示sizeCtl的临时值 Node&lt;K,V&gt;[] tab, nt; int n, sc; /** * sizeCtl &lt; 0 * 1. -1 表示当前table正在初始化（有线程在创建table数组），当前线程需要自旋等待.. * 2.表示当前table数组正在进行扩容 ,高16位表示：扩容的标识戳 低16位表示：（1 + nThread） 当前参与并发扩容的线程数量 * * sizeCtl = 0，表示创建table数组时 使用DEFAULT_CAPACITY为大小 * * sizeCtl &gt; 0 * * 1. 如果table未初始化，表示初始化大小 * 2. 如果table已经初始化，表示下次扩容时的 触发条件（阈值） */ //自旋 //条件一：s &gt;= (long)(sc = sizeCtl) // true-&gt; 1.当前sizeCtl为一个负数 表示正在扩容中.. // 2.当前sizeCtl是一个正数，表示扩容阈值 // false-&gt; 表示当前table尚未达到扩容条件 //条件二：(tab = table) != null // 恒成立 true //条件三：(n = tab.length) &lt; MAXIMUM_CAPACITY // true-&gt;当前table长度小于最大值限制，则可以进行扩容。 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; //扩容批次唯一标识戳 //16 -&gt; 32 扩容 标识为：1000 0000 0001 1011 int rs = resizeStamp(n); //条件成立：表示当前table正在扩容 // 当前线程理论上应该协助table完成扩容 if (sc &lt; 0) &#123; //条件一：(sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs // true-&gt;说明当前线程获取到的扩容唯一标识戳 非 本批次扩容 // false-&gt;说明当前线程获取到的扩容唯一标识戳 是 本批次扩容 //条件二： JDK1.8 中有bug jira已经提出来了 其实想表达的是 = sc == (rs &lt;&lt; 16 ) + 1 // true-&gt; 表示扩容完毕，当前线程不需要再参与进来了 // false-&gt;扩容还在进行中，当前线程可以参与 //条件三：JDK1.8 中有bug jira已经提出来了 其实想表达的是 = sc == (rs&lt;&lt;16) + MAX_RESIZERS // true-&gt; 表示当前参与并发扩容的线程达到了最大值 65535 - 1 // false-&gt;表示当前线程可以参与进来 //条件四：(nt = nextTable) == null // true-&gt;表示本次扩容结束 // false-&gt;扩容正在进行中 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //前置条件：当前table正在执行扩容中.. 当前线程有机会参与进扩容。 //条件成立：说明当前线程成功参与到扩容任务中，并且将sc低16位值加1，表示多了一个线程参与工作 //条件失败：1.当前有很多线程都在此处尝试修改sizeCtl，有其它一个线程修改成功了，导致你的sc期望值与内存中的值不一致 修改失败 // 2.transfer 任务内部的线程也修改了sizeCtl。 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) //协助扩容线程，持有nextTable参数 transfer(tab, nt); &#125; //1000 0000 0001 1011 0000 0000 0000 0000 +2 =&gt; 1000 0000 0001 1011 0000 0000 0000 0010 //条件成立，说明当前线程是触发扩容的第一个线程，在transfer方法需要做一些扩容准备工作 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) //触发扩容条件的线程 不持有nextTable transfer(tab, null); s = sumCount(); &#125; &#125;&#125; #8. transferConcurrentHashMap 支持并发扩容，实现方式是，把 Node 数组进行拆分，让每个线程处理自己的区域，假设 table 数组总长度是 64，默认情况下，那么每个线程可以分到 16 个 bucket。然后每个线程处理的范围，按照倒序来做迁移。 通过 for 自循环处理每个槽位中的链表元素，默认 advace 为真，通过 CAS 设置 transferIndex属性值，并初始化 i 和 bound 值，i 指当前处理的槽位序号，bound 指需要处理的槽位边界，先处理槽位 31 的节点； （bound,i） =(16,31) 从 31 的位置往前推动。 每存在一个线程执行完扩容操作，就通过 cas 执行 sc-1。 接着判断(sc-2) !=resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT ; 如果相等，表示当前为整个扩容操作的 最后一个线程，那么意味着整个扩容操作就结束了；如果不相等，说明还得继续。 这么做的目的，一方面是防止不同扩容之间出现相同的 sizeCtl，另外一方面，还可以避免sizeCtl 的 ABA 问题导致的扩容重叠的情况。 扩容图解判断是否需要扩容，也就是当更新后的键值对总数 baseCount &gt;= 阈值 sizeCtl 时，进行rehash，这里面会有两个逻辑。 如果当前正在处于扩容阶段，则当前线程会加入并且协助扩容。 如果当前没有在扩容，则直接触发扩容操作。 扩容操作的核心在于数据的转移，在单线程环境下数据的转移很简单，无非就是把旧数组中的数据迁移到新的数组。但是这在多线程环境下，在扩容的时候其他线程也可能正在添加元素，这时又触发了扩容怎么办？可能大家想到的第一个解决方案是加互斥锁，把转移过程锁住，虽然是可行的解决方案，但是会带来较大的性能开销。因为互斥锁会导致所有访问临界区的线程陷入到阻塞状态，持有锁的线程耗时越长，其他竞争线程就会一直被阻塞，导致吞吐量较低。而且还可能导致死锁。 而 ConcurrentHashMap 并没有直接加锁，而是采用 CAS 实现无锁的并发同步策略，最精华的部分是它可以利用多线程来进行协同扩容。 它把 Node 数组当作多个线程之间共享的任务队列，然后通过维护一个指针来划分每个线程锁负责的区间，每个线程通过区间逆向遍历来实现扩容，一个已经迁移完的bucket会被替换为一个ForwardingNode节点，标记当前bucket已经被其他线程迁移完了。接下来分析一下它的源码实现。 fwd:这个类是个标识类，用于指向新表用的，其他线程遇到这个类会主动跳过这个类，因为这个类要么就是扩容迁移正在进行，要么就是已经完成扩容迁移，也就是这个类要保证线程安全，再进行操作。 advance:这个变量是用于提示代码是否进行推进处理，也就是当前桶处理完，处理下一个桶的标识。 finishing:这个变量用于提示扩容是否结束用的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; //n 表示扩容之前table数组的长度 //stride 表示分配给线程任务的步长 int n = tab.length, stride; // stride 固定为 16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range //条件成立：表示当前线程为触发本次扩容的线程，需要做一些扩容准备工作 //条件不成立：表示当前线程是协助扩容的线程.. if (nextTab == null) &#123; // initiating try &#123; //创建了一个比扩容之前大一倍的table @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; //赋值给对象属性 nextTable ，方便协助扩容线程 拿到新表 nextTable = nextTab; //记录迁移数据整体位置的一个标记。index计数是从1开始计算的。 transferIndex = n; &#125; //表示新数组的长度 int nextn = nextTab.length; //fwd 节点，当某个桶位数据处理完毕后，将此桶位设置为fwd节点，其它写线程 或读线程看到后，会有不同逻辑。 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); //推进标记 boolean advance = true; //完成标记 boolean finishing = false; // to ensure sweep before committing nextTab //i 表示分配给当前线程任务，执行到的桶位 //bound 表示分配给当前线程任务的下界限制 int i = 0, bound = 0; //自旋 for (;;) &#123; //f 桶位的头结点 //fh 头结点的hash Node&lt;K,V&gt; f; int fh; /** * 1.给当前线程分配任务区间 * 2.维护当前线程任务进度（i 表示当前处理的桶位） * 3.维护map对象全局范围内的进度 */ while (advance) &#123; //分配任务的开始下标 //分配任务的结束下标 int nextIndex, nextBound; //CASE1: //条件一：--i &gt;= bound //成立：表示当前线程的任务尚未完成，还有相应的区间的桶位要处理，--i 就让当前线程处理下一个 桶位. //不成立：表示当前线程任务已完成 或 者未分配 if (--i &gt;= bound || finishing) advance = false; //CASE2: //前置条件：当前线程任务已完成 或 者未分配 //条件成立：表示对象全局范围内的桶位都分配完毕了，没有区间可分配了，设置当前线程的i变量为-1 跳出循环后，执行退出迁移任务相关的程序 //条件不成立：表示对象全局范围内的桶位尚未分配完毕，还有区间可分配 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; //CASE3: //前置条件：1、当前线程需要分配任务区间 2.全局范围内还有桶位尚未迁移 //条件成立：说明给当前线程分配任务成功 //条件失败：说明分配给当前线程失败，应该是和其它线程发生了竞争吧 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; //CASE1： //条件一：i &lt; 0 //成立：表示当前线程未分配到任务 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; //保存sizeCtl 的变量 int sc; if (finishing) &#123; nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; //条件成立：说明设置sizeCtl 低16位 -1 成功，当前线程可以正常退出 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; //1000 0000 0001 1011 0000 0000 0000 0000 //条件成立：说明当前线程不是最后一个退出transfer任务的线程 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) //正常退出 return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; //前置条件：【CASE2~CASE4】 当前线程任务尚未处理完，正在进行中 //CASE2: //条件成立：说明当前桶位未存放数据，只需要将此处设置为fwd节点即可。 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); //CASE3: //条件成立：说明当前桶位已经迁移过了，当前线程不用再处理了，直接再次更新当前线程任务索引，再次处理下一个桶位 或者 其它操作 else if ((fh = f.hash) == MOVED) advance = true; // already processed //CASE4: //前置条件：当前桶位有数据，而且node节点 不是 fwd节点，说明这些数据需要迁移。 else &#123; //sync 加锁当前桶位的头结点 synchronized (f) &#123; //防止在你加锁头对象之前，当前桶位的头对象被其它写线程修改过，导致你目前加锁对象错误... if (tabAt(tab, i) == f) &#123; //ln 表示低位链表引用 //hn 表示高位链表引用 Node&lt;K,V&gt; ln, hn; //条件成立：表示当前桶位是链表桶位 if (fh &gt;= 0) &#123; //lastRun //可以获取出 当前链表 末尾连续高位不变的 node int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; //条件成立：说明lastRun引用的链表为 低位链表，那么就让 ln 指向 低位链表 if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; //否则，说明lastRun引用的链表为 高位链表，就让 hn 指向 高位链表 else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; //条件成立：表示当前桶位是 红黑树 代理结点TreeBin else if (f instanceof TreeBin) &#123; //转换头结点为 treeBin引用 t TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; //低位双向链表 lo 指向低位链表的头 loTail 指向低位链表的尾巴 TreeNode&lt;K,V&gt; lo = null, loTail = null; //高位双向链表 lo 指向高位链表的头 loTail 指向高位链表的尾巴 TreeNode&lt;K,V&gt; hi = null, hiTail = null; //lc 表示低位链表元素数量 //hc 表示高位链表元素数量 int lc = 0, hc = 0; //迭代TreeBin中的双向链表，从头结点 至 尾节点 for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; // h 表示循环处理当前元素的 hash int h = e.hash; //使用当前节点 构建出来的 新的 TreeNode TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); //条件成立：表示当前循环节点 属于低位链 节点 if ((h &amp; n) == 0) &#123; //条件成立：说明当前低位链表 还没有数据 if ((p.prev = loTail) == null) lo = p; //说明 低位链表已经有数据了，此时当前元素 追加到 低位链表的末尾就行了 else loTail.next = p; //将低位链表尾指针指向 p 节点 loTail = p; ++lc; &#125; //当前节点 属于 高位链 节点 else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 链表迁移原理 1）高低位原理分析 ConcurrentHashMap 在做链表迁移时，会用高低位来实现，这里有两个问题要分析一下 1，如何实现高低位链表的区分 假如有这样一个队列第 14 个槽位插入新节点之后，链表元素个数已经达到了 8，且数组长度为 16，优先通过扩容来缓解链表过长的问题 假如当前线程正在处理槽位为 14 的节点，它是一个链表结构，在代码中，首先定义两个变量节点 ln 和 hn，实际就是 lowNode 和 HighNode，分别保存 hash 值的第 x 位为 0 和不等于0 的节点 通过 fn&amp;n 可以把这个链表中的元素分为两类，A 类是 hash 值的第 X 位为 0，B 类是 hash 值的第 x 位为不等于 0（至于为什么要这么区分，稍后分析），并且通过 lastRun 记录最后要处理的节点。最终要达到的目的是，A 类的链表保持位置不动，B 类的链表为 14+16(扩容增加的长度)=30 把 14 槽位的链表单独伶出来，用蓝色表示 fn&amp;n=0 的节点，假如链表的分类是这样 1234567for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125;&#125; 通过上面这段代码遍历，会记录 runBit 以及 lastRun，按照上面这个结构，那么 runBit 应该是蓝色节点，lastRun 应该是第 6 个节点接着，再通过这段代码进行遍历，生成 ln 链以及 hn 链 1234567for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);&#125; 接着，通过 CAS 操作，把 hn 链放在 i+n 也就是 14+16 的位置，ln 链保持原来的位置不动。并且设置当前节点为 fwd，表示已经被当前线程迁移完了。 123setTabAt(nextTab, i, ln);setTabAt(nextTab, i + n, hn);setTabAt(tab, i, fwd); 迁移完成以后的数据分布如下 2）为什么要做高低位的划分 要想了解这么设计的目的，我们需要从 ConcurrentHashMap 的根据下标获取对象的算法来看，在 putVal 方法中 1018 行： (f = tabAt(tab, i = (n - 1) &amp; hash)) == null 通过(n-1) &amp; hash 来获得在 table 中的数组下标来获取节点数据，【&amp;运算是二进制运算符，1&amp; 1=1，其他都为 0】。 #9.helpTransfer如果对应的节点存在，判断这个节点的 hash 是不是等于 MOVED(-1)，说明当前节点是ForwardingNode 节点，意味着有其他线程正在进行扩容，那么当前现在直接帮助它进行扩容，因此调用 helpTransfer方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; //nextTab 引用的是 fwd.nextTable == map.nextTable 理论上是这样。 //sc 保存map.sizeCtl Node&lt;K,V&gt;[] nextTab; int sc; //条件一：tab != null 恒成立 true //条件二：(f instanceof ForwardingNode) 恒成立 true //条件三：((ForwardingNode&lt;K,V&gt;)f).nextTable) != null 恒成立 true if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; //拿当前标的长度 获取 扩容标识戳 假设 16 -&gt; 32 扩容：1000 0000 0001 1011 int rs = resizeStamp(tab.length); //条件一：nextTab == nextTable //成立：表示当前扩容正在进行中 //不成立：1.nextTable被设置为Null 了，扩容完毕后，会被设为Null // 2.再次出发扩容了...咱们拿到的nextTab 也已经过期了... //条件二：table == tab //成立：说明 扩容正在进行中，还未完成 //不成立：说明扩容已经结束了，扩容结束之后，最后退出的线程 会设置 nextTable 为 table //条件三：(sc = sizeCtl) &lt; 0 //成立：说明扩容正在进行中 //不成立：说明sizeCtl当前是一个大于0的数，此时代表下次扩容的阈值，当前扩容已经结束。 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; //条件一：(sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs // true-&gt;说明当前线程获取到的扩容唯一标识戳 非 本批次扩容 // false-&gt;说明当前线程获取到的扩容唯一标识戳 是 本批次扩容 //条件二： JDK1.8 中有bug jira已经提出来了 其实想表达的是 = sc == (rs &lt;&lt; 16 ) + 1 // true-&gt; 表示扩容完毕，当前线程不需要再参与进来了 // false-&gt;扩容还在进行中，当前线程可以参与 //条件三：JDK1.8 中有bug jira已经提出来了 其实想表达的是 = sc == (rs&lt;&lt;16) + MAX_RESIZERS // true-&gt; 表示当前参与并发扩容的线程达到了最大值 65535 - 1 // false-&gt;表示当前线程可以参与进来 //条件四：transferIndex &lt;= 0 // true-&gt;说明map对象全局范围内的任务已经分配完了，当前线程进去也没活干.. // false-&gt;还有任务可以分配。 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125; #10.get 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public V get(Object key) &#123; //tab 引用map.table //e 当前元素 //p 目标节点 //n table数组长度 //eh 当前元素hash //ek 当前元素key Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //扰动运算后得到 更散列的hash值 int h = spread(key.hashCode()); //条件一：(tab = table) != null //true-&gt;表示已经put过数据，并且map内部的table也已经初始化完毕 //false-&gt;表示创建完map后，并没有put过数据，map内部的table是延迟初始化的，只有第一次写数据时会触发创建逻辑。 //条件二：(n = tab.length) &gt; 0 true-&gt;表示table已经初始化 //条件三：(e = tabAt(tab, (n - 1) &amp; h)) != null //true-&gt;当前key寻址的桶位 有值 //false-&gt;当前key寻址的桶位中是null，是null直接返回null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //前置条件：当前桶位有数据 //对比头结点hash与查询key的hash是否一致 //条件成立：说明头结点与查询Key的hash值 完全一致 if ((eh = e.hash) == h) &#123; //完全比对 查询key 和 头结点的key //条件成立：说明头结点就是查询数据 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //条件成立： //1.-1 fwd 说明当前table正在扩容，且当前查询的这个桶位的数据 已经被迁移走了 //2.-2 TreeBin节点，需要使用TreeBin 提供的find 方法查询。 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //当前桶位已经形成链表的这种情况 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; #11.remove 123public V remove(Object key) &#123; return replaceNode(key, null, null);&#125; #12.replaceNode 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143final V replaceNode(Object key, V value, Object cv) &#123; //计算key经过扰动运算后的hash int hash = spread(key.hashCode()); //自旋 for (Node&lt;K,V&gt;[] tab = table;;) &#123; //f表示桶位头结点 //n表示当前table数组长度 //i表示hash命中桶位下标 //fh表示桶位头结点 hash Node&lt;K,V&gt; f; int n, i, fh; //CASE1： //条件一：tab == null true-&gt;表示当前map.table尚未初始化.. false-&gt;已经初始化 //条件二：(n = tab.length) == 0 true-&gt;表示当前map.table尚未初始化.. false-&gt;已经初始化 //条件三：(f = tabAt(tab, i = (n - 1) &amp; hash)) == null true -&gt; 表示命中桶位中为null，直接break， 会返回 if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) &amp; hash)) == null) break; //CASE2： //前置条件CASE2 ~ CASE3：当前桶位不是null //条件成立：说明当前table正在扩容中，当前是个写操作，所以当前线程需要协助table完成扩容。 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); //CASE3: //前置条件CASE2 ~ CASE3：当前桶位不是null //当前桶位 可能是 &quot;链表&quot; 也可能 是 &quot;红黑树&quot; TreeBin else &#123; //保留替换之前的数据引用 V oldVal = null; //校验标记 boolean validated = false; //加锁当前桶位 头结点，加锁成功之后会进入 代码块。 synchronized (f) &#123; //判断sync加锁是否为当前桶位 头节点，防止其它线程，在当前线程加锁成功之前，修改过 桶位 的头结点。 //条件成立：当前桶位头结点 仍然为f，其它线程没修改过。 if (tabAt(tab, i) == f) &#123; //条件成立：说明桶位 为 链表 或者 单个 node if (fh &gt;= 0) &#123; validated = true; //e 表示当前循环处理元素 //pred 表示当前循环节点的上一个节点 Node&lt;K,V&gt; e = f, pred = null; for (;;) &#123; //当前节点key K ek; //条件一：e.hash == hash true-&gt;说明当前节点的hash与查找节点hash一致 //条件二：((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) //if 条件成立，说明key 与查询的key完全一致。 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; //当前节点的value V ev = e.val; //条件一：cv == null true-&gt;替换的值为null 那么就是一个删除操作 //条件二：cv == ev || (ev != null &amp;&amp; cv.equals(ev)) 那么是一个替换操作 if (cv == null || cv == ev || (ev != null &amp;&amp; cv.equals(ev))) &#123; //删除 或者 替换 //将当前节点的值 赋值给 oldVal 后续返回会用到 oldVal = ev; //条件成立：说明当前是一个替换操作 if (value != null) //直接替换 e.val = value; //条件成立：说明当前节点非头结点 else if (pred != null) //当前节点的上一个节点，指向当前节点的下一个节点。 pred.next = e.next; else //说明当前节点即为 头结点，只需要将 桶位设置为头结点的下一个节点。 setTabAt(tab, i, e.next); &#125; break; &#125; pred = e; if ((e = e.next) == null) break; &#125; &#125; //条件成立：TreeBin节点。 else if (f instanceof TreeBin) &#123; validated = true; //转换为实际类型 TreeBin t TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; //r 表示 红黑树 根节点 //p 表示 红黑树中查找到对应key 一致的node TreeNode&lt;K,V&gt; r, p; //条件一：(r = t.root) != null 理论上是成立 //条件二：TreeNode.findTreeNode 以当前节点为入口，向下查找key（包括本身节点） // true-&gt;说明查找到相应key 对应的node节点。会赋值给p if ((r = t.root) != null &amp;&amp; (p = r.findTreeNode(hash, key, null)) != null) &#123; //保存p.val 到pv V pv = p.val; //条件一：cv == null 成立：不必对value，就做替换或者删除操作 //条件二：cv == pv ||(pv != null &amp;&amp; cv.equals(pv)) 成立：说明“对比值”与当前p节点的值 一致 if (cv == null || cv == pv || (pv != null &amp;&amp; cv.equals(pv))) &#123; //替换或者删除操作 oldVal = pv; //条件成立：替换操作 if (value != null) p.val = value; //删除操作 else if (t.removeTreeNode(p)) //这里没做判断，直接搞了...很疑惑 setTabAt(tab, i, untreeify(t.first)); &#125; &#125; &#125; &#125; &#125; //当其他线程修改过桶位 头结点时，当前线程 sync 头结点 锁错对象时，validated 为false，会进入下次for 自旋 if (validated) &#123; if (oldVal != null) &#123; //替换的值 为null，说明当前是一次删除操作，oldVal ！=null 成立，说明删除成功，更新当前元素个数计数器。 if (value == null) addCount(-1L, -1); return oldVal; &#125; break; &#125; &#125; &#125; return null;&#125; #13.TreeBin##13.1 属性 1234567891011121314151617//红黑树 根节点 TreeNode&lt;K,V&gt; root;//链表的头节点volatile TreeNode&lt;K,V&gt; first;//等待者线程（当前lockState是读锁状态）volatile Thread waiter;/** * 1.写锁状态 写是独占状态，以散列表来看，真正进入到TreeBin中的写线程 同一时刻 只有一个线程。 1 * 2.读锁状态 读锁是共享，同一时刻可以有多个线程 同时进入到 TreeBin对象中获取数据。 每一个线程 都会给 lockStat + 4 * 3.等待者状态（写线程在等待），当TreeBin中有读线程目前正在读取数据时，写线程无法修改数据，那么就将lockState的最低2位 设置为 0b 10 */volatile int lockState;// values for lockStatestatic final int WRITER = 1; // set while holding write lockstatic final int WAITER = 2; // set when waiting for write lockstatic final int READER = 4; // increment value for setting read lock ##13.2 构造器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586TreeBin(TreeNode&lt;K,V&gt; b) &#123; //设置节点hash为-2 表示此节点是TreeBin节点 super(TREEBIN, null, null, null); //使用first 引用 treeNode链表 this.first = b; //r 红黑树的根节点引用 TreeNode&lt;K,V&gt; r = null; //x表示遍历的当前节点 for (TreeNode&lt;K,V&gt; x = b, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; //强制设置当前插入节点的左右子树为null x.left = x.right = null; //条件成立：说明当前红黑树 是一个空树，那么设置插入元素 为根节点 if (r == null) &#123; //根节点的父节点 一定为 null x.parent = null; //颜色改为黑色 x.red = false; //让r引用x所指向的对象。 r = x; &#125; else &#123; //非第一次循环，都会来带else分支，此时红黑树已经有数据了 //k 表示 插入节点的key K k = x.key; //h 表示 插入节点的hash int h = x.hash; //kc 表示 插入节点key的class类型 Class&lt;?&gt; kc = null; //p 表示 为查找插入节点的父节点的一个临时节点 TreeNode&lt;K,V&gt; p = r; for (;;) &#123; //dir (-1, 1) //-1 表示插入节点的hash值大于 当前p节点的hash //1 表示插入节点的hash值 小于 当前p节点的hash //ph p表示 为查找插入节点的父节点的一个临时节点的hash int dir, ph; //临时节点 key K pk = p.key; //插入节点的hash值 小于 当前节点 if ((ph = p.hash) &gt; h) //插入节点可能需要插入到当前节点的左子节点 或者 继续在左子树上查找 dir = -1; //插入节点的hash值 大于 当前节点 else if (ph &lt; h) //插入节点可能需要插入到当前节点的右子节点 或者 继续在右子树上查找 dir = 1; //如果执行到 CASE3，说明当前插入节点的hash 与 当前节点的hash一致，会在case3 做出最终排序。最终 //拿到的dir 一定不是0，（-1， 1） else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); //xp 想要表示的是 插入节点的 父节点 TreeNode&lt;K,V&gt; xp = p; //条件成立：说明当前p节点 即为插入节点的父节点 //条件不成立：说明p节点 底下还有层次，需要将p指向 p的左子节点 或者 右子节点，表示继续向下搜索。 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; //设置插入节点的父节点 为 当前节点 x.parent = xp; //小于P节点，需要插入到P节点的左子节点 if (dir &lt;= 0) xp.left = x; //大于P节点，需要插入到P节点的右子节点 else xp.right = x; //插入节点后，红黑树性质 可能会被破坏，所以需要调用 平衡方法 r = balanceInsertion(r, x); break; &#125; &#125; &#125; &#125; //将r 赋值给 TreeBin对象的 root引用。 this.root = r; assert checkInvariants(root);&#125; ##13.3 putTreeVal 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970final TreeNode&lt;K,V&gt; putTreeVal(int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if (p == null) &#123; first = root = new TreeNode&lt;K,V&gt;(h, k, v, null, null); break; &#125; else if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.findTreeNode(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.findTreeNode(h, k, kc)) != null)) return q; &#125; dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; //当前循环节点xp 即为 x 节点的爸爸 //x 表示插入节点 //f 老的头结点 TreeNode&lt;K,V&gt; x, f = first; first = x = new TreeNode&lt;K,V&gt;(h, k, v, f, xp); //条件成立：说明链表有数据 if (f != null) //设置老的头结点的前置引用为 当前的头结点。 f.prev = x; if (dir &lt;= 0) xp.left = x; else xp.right = x; if (!xp.red) x.red = true; else &#123; //表示 当前新插入节点后，新插入节点 与 父节点 形成 “红红相连” lockRoot(); try &#123; //平衡红黑树，使其再次符合规范。 root = balanceInsertion(root, x); &#125; finally &#123; unlockRoot(); &#125; &#125; break; &#125; &#125; assert checkInvariants(root); return null;&#125; ##13.4 find 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final Node&lt;K,V&gt; find(int h, Object k) &#123; if (k != null) &#123; //e 表示循环迭代的当前节点 迭代的是first引用的链表 for (Node&lt;K,V&gt; e = first; e != null; ) &#123; //s 保存的是lock临时状态 //ek 链表当前节点 的key int s; K ek; //(WAITER|WRITER) =&gt; 0010 | 0001 =&gt; 0011 //lockState &amp; 0011 != 0 条件成立：说明当前TreeBin 有等待者线程 或者 目前有写操作线程正在加锁 if (((s = lockState) &amp; (WAITER|WRITER)) != 0) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; e = e.next; &#125; //前置条件：当前TreeBin中 等待者线程 或者 写线程 都没有 //条件成立：说明添加读锁成功 else if (U.compareAndSwapInt(this, LOCKSTATE, s, s + READER)) &#123; TreeNode&lt;K,V&gt; r, p; try &#123; //查询操作 p = ((r = root) == null ? null : r.findTreeNode(h, k, null)); &#125; finally &#123; //w 表示等待者线程 Thread w; //U.getAndAddInt(this, LOCKSTATE, -READER) == (READER|WAITER) //1.当前线程查询红黑树结束，释放当前线程的读锁 就是让 lockstate 值 - 4 //(READER|WAITER) = 0110 =&gt; 表示当前只有一个线程在读，且“有一个线程在等待” //当前读线程为 TreeBin中的最后一个读线程。 //2.(w = waiter) != null 说明有一个写线程在等待读操作全部结束。 if (U.getAndAddInt(this, LOCKSTATE, -READER) == (READER|WAITER) &amp;&amp; (w = waiter) != null) //使用unpark 让 写线程 恢复运行状态。 LockSupport.unpark(w); &#125; return p; &#125; &#125; &#125; return null;&#125; #总结在java8中，ConcurrentHashMap使用数组+链表+红黑树的组合方式，利用cas和synchronized保证并发写的安全。 引入红黑树的原因：链表查询的时间复杂度为On，但是红黑树的查询时间复杂度为O(log(n)),所以在节点比较多的情况下，使用红黑树可以大大提升性能。 链式桶是一个由node节点组成的链表。树状桶是一颗由TreeNode节点组成的红黑树。输的根节点为TreeBin类型。 当链表长度大于8整个hash表长度大于64的时候，就会转化为TreeBin。TreeBin作为根节点，其实就是红黑树对象。在ConcurrentHashMap的table数组中，存放的就是TreeBin对象，而不是TreeNoe对象。 数组table是懒加载的，只有第一次添加元素的时候才会初始化，所以initTable()存在线程安全问题。 重要的属性就是sizeCtl，用来控制table的初始化和扩容操作的过程： ● -1代表table正在初始化，其他线程直接join等待。 ● -N代表有N-1个线程正在进行扩容操作，严格来说，当其为负数的时候，只用到了低16位，如果低16位为M，此时有M-1个线程进行扩容。 ● 大于0有两种情况：如果table没有初始化，她就表示table初始化的大小，如果table初始化完了，就表示table的容量，默认是table大小的四分之三。 Transfer()扩容 table数据转移到nextTable。扩容操作的核心在于数据的转移，把旧数组中的数据迁移到新的数组。ConcurrentHashMap精华的部分是它可以利用多线程来进行协同扩容，简单来说，它把table数组当作多个线程之间共享的任务队列，然后通过维护一个指针来划分每个线程所负责的区间，每个线程通过区间逆向遍历来实现扩容，一个已经迁移完的 Bucket会被替换为一个Forwarding节点，标记当前Bucket已经被其他线程迁移完了。 helpTransfer()帮助扩容 ConcurrentHashMap并发添加元素时，如果正在扩容，其他线程会帮助扩容，也就是多线程扩容。 第一次添加元素时，默认初始长度为16，当往table中继续添加元素时，通过Hash值跟数组长度取余来决定放在数组的哪个Bucket位置，如果出现放在同一个位置，就优先以链表的形式存放，在同一个位置的个数达到了8个以上，如果数组的长度还小于64，就会扩容数组。如果数组的长度大于等于64，就会将该节点的链表转换成树。 通过扩容数组的方式来把这些节点分散开。然后将这些元素复制到扩容后的新数组中，同一个Bucket中的元素通过Hash值的数组长度位来重新确定位置，可能还是放在原来的位置，也可能放到新的位置。而且，在扩容完成之后，如果之前某个节点是树，但是现在该节点的“Key-Value对”数又小于等于6个，就会将该树转为链表。 put() JDK1.8在使用CAS自旋完成桶的设置时，使用synchronized内置锁保证桶内并发操作的线程安全。尽管对同一个Map操作的线程争用会非常激烈，但是在同一个桶内的线程争用通常不会很激烈，所以使用CAS自旋、synchronized不会降低ConcurrentHashMap的性能。为什么不用ReentrantLock显式锁呢?如果为每 个桶都创建一个ReentrantLock实 例，就会带来大量的内存消耗，反过来，使用CAS自旋、synchronized，内存消耗的增加更小。 get() get()通过UnSafe的getObjectVolatile()来读取数组中的元素。为什么要这样做?虽然HashEntry数组的引用是volatile类型，但是数组内元素的 用不是volatile类型，因此多线程对 数组元素的修改是不安全的，可能会在数组中读取到尚未构造完成的元素对象。get()方法通过UnSafe的getObjectVolatile方法来保证元素的读取安全，调用getObjectVolatile()去读取数组元素需要先获得元素在数组中的偏移量，在这里，get()方法根据哈希码计算出偏移量为u，然后通过偏移量u来尝试读取数值。","categories":[{"name":"1.基础知识","slug":"1-基础知识","permalink":"https://yinhuidong.github.io/categories/1-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"集合源码分析","slug":"集合源码分析","permalink":"https://yinhuidong.github.io/tags/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]}],"categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/categories/MySQL/"},{"name":"1.基础知识","slug":"1-基础知识","permalink":"https://yinhuidong.github.io/categories/1-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yinhuidong.github.io/tags/MySQL/"},{"name":"集合源码分析","slug":"集合源码分析","permalink":"https://yinhuidong.github.io/tags/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]}