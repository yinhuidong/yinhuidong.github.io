<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Kafka核心原理 | huidong.yin</title><meta name="keywords" content="RabbitMQ"><meta name="author" content="二十"><meta name="copyright" content="二十"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Kafka核心原理">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka核心原理">
<meta property="og:url" content="https://yinhuidong.github.io/2022/01/13/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/kafka[%E4%BA%8C]%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/index.html">
<meta property="og:site_name" content="huidong.yin">
<meta property="og:description" content="Kafka核心原理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yinhuidong.github.io/images/cover/mq.png">
<meta property="article:published_time" content="2022-01-13T14:25:27.238Z">
<meta property="article:modified_time" content="2022-01-13T14:30:39.071Z">
<meta property="article:author" content="二十">
<meta property="article:tag" content="RabbitMQ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yinhuidong.github.io/images/cover/mq.png"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="https://yinhuidong.github.io/2022/01/13/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/kafka[%E4%BA%8C]%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":800},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka核心原理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-01-13 22:30:39'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><meta name="referrer" content="no-referrer" /><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">132</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/%E5%85%B3%E4%BA%8E%E6%88%91/"><i class="fa-fw fas fa-user"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/images/cover/mq.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">huidong.yin</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/%E5%85%B3%E4%BA%8E%E6%88%91/"><i class="fa-fw fas fa-user"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Kafka核心原理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-01-13T14:25:27.238Z" title="发表于 2022-01-13 22:25:27">2022-01-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-01-13T14:30:39.071Z" title="更新于 2022-01-13 22:30:39">2022-01-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Kafka核心原理"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="一，java中使用kafka进行通信"><a href="#一，java中使用kafka进行通信" class="headerlink" title="一，java中使用kafka进行通信"></a>一，java中使用kafka进行通信</h2><p>kafka对于消息的发送，可以支持同步和异步，同步会需要阻塞，而异步不需要等待阻塞的过程。</p>
<p>从本质上来说，kafka都是采用异步的方式来发送消息到broker，但是kafka并不是每次发送消息都会直接发送到broker上，而是把消息放到了一个发送队列中，然后通过一个后台线程不断从队列取出消息进行发送，发送成功后会触发callback。kafka客户端会积累一定量的消息统一组装成一个批量消息发送出去，触发条件是前面提到的batch.size和linger.ms</p>
<p>而同步发送的方法，无非就是通过future.get()来等待消息的发送返回结果，但是这种方法会严重影响消息发送的性能。</p>
<h3 id="1-batch-size"><a href="#1-batch-size" class="headerlink" title="1. batch.size"></a>1. batch.size</h3><p>生产者发送多个消息到broker上的同一个分区时，为了减少网络请求带来的性能开销，通过批量的方式来提交消息，可以通过这个参数来控制批量提交的字节数大小，默认大小是16384byte,也就是16kb，意味着当一批消息大小达到指定的batch.size的时候会统一发送</p>
<h3 id="2-linger-ms"><a href="#2-linger-ms" class="headerlink" title="2. linger.ms"></a>2. linger.ms</h3><p>Producer默认会把两次发送时间间隔内收集到的所有Requests进行一次聚合然后再发送，以此提高吞吐量，而linger.ms就是为每次发送到broker的请求增加一些delay，以此来聚合更多的Message请求。这个有点想TCP里面的Nagle算法，在TCP协议的传输中，为了减少大量小数据包的发送，采用了Nagle算法，也就是基于小包的等-停协议。</p>
<p>batch.size和linger.ms这两个参数是kafka性能优化的关键参数，很多同学会发现batch.size和linger.ms这两者的作用是一样的，如果两个都配置了，那么怎么工作的呢？实际上，当二者都配置的时候，只要满足其中一个要求，就会发送请求到broker上。</p>
<h2 id="二，基础配置分析"><a href="#二，基础配置分析" class="headerlink" title="二，基础配置分析"></a>二，基础配置分析</h2><h3 id="1-group-id"><a href="#1-group-id" class="headerlink" title="1.group.id"></a>1.group.id</h3><p>consumer group是kafka提供的可扩展且具有容错性的消费者机制。既然是一个组，那么组内必然可以有多个消费者或消费者实例(consumer instance)，它们共享一个公共的ID，即group ID。组内的所有消费者协调在一起来消费订阅主题(subscribed topics)的所有分区(partition)。当然，每个分区只能由同一个消费组内的一个consumer来消费.如下图所示，分别有三个消费者，属于两个不同的group，那么对于firstTopic这个topic来说，这两个组的消费者都能同时消费这个topic中的消息，对于此事的架构来说，这个firstTopic就类似于ActiveMQ中的topic概念。如图所示，如果3个消费者都属于同一个group，那么此事firstTopic就是一个Queue的概念</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083750423-14df9108-fd9f-4a2e-9405-de65b455f720.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=ua8abd7a0&margin=%5Bobject%20Object%5D&name=1.png&originHeight=529&originWidth=1142&originalType=binary&ratio=1&rotation=0&showTitle=false&size=50319&status=done&style=none&taskId=u002ace7a-c617-44c0-bad4-7af44619bd6&title=" alt="1.png"></p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083753191-dc23462b-a540-4154-b17c-1ef1fe098556.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=u854677fc&margin=%5Bobject%20Object%5D&name=2.png&originHeight=498&originWidth=1141&originalType=binary&ratio=1&rotation=0&showTitle=false&size=46009&status=done&style=none&taskId=uf59a8e19-e914-430d-b6f2-2a27bc7dd24&title=" alt="2.png"></p>
<h3 id="2-enable-auto-commit"><a href="#2-enable-auto-commit" class="headerlink" title="2.enable.auto.commit"></a>2.enable.auto.commit</h3><p>消费者消费消息以后自动提交，只有当消息提交以后，该消息才不会被再次接收到，还可以配合auto.commit.interval.ms控制自动提交的频率。</p>
<p>当然，我们也可以通过consumer.commitSync()的方式实现手动提交</p>
<h3 id="3-auto-offset-reset"><a href="#3-auto-offset-reset" class="headerlink" title="3.auto.offset.reset"></a>3.auto.offset.reset</h3><p>这个参数是针对新的groupid中的消费者而言的，当有新groupid的消费者来消费指定的topic时，对于该参数的配置，会有不同的语义</p>
<p>auto.offset.reset=latest情况下，新的消费者将会从其他消费者最后消费的offset处开始消费Topic下的消息</p>
<p>auto.offset.reset= earliest情况下，新的消费者会从该topic最早的消息开始消费</p>
<p>auto.offset.reset=none情况下，新的消费者加入以后，由于之前不存在offset，则会直接抛出异常。</p>
<h3 id="4-max-poll-records"><a href="#4-max-poll-records" class="headerlink" title="4.max.poll.records"></a>4.max.poll.records</h3><p>此设置限制每次调用poll返回的消息数，这样可以更容易的预测每次poll间隔要处理的最大值。通过调整此值，可以减少poll间隔</p>
<h2 id="三，SpringBoot-Kafka"><a href="#三，SpringBoot-Kafka" class="headerlink" title="三，SpringBoot+Kafka"></a>三，SpringBoot+Kafka</h2><p>springboot的版本和kafka的版本，有一个对照表格，如果没有按照正确的版本来引入，那么会存在版本问题导致ClassNotFound的问题，具体看spring官网。</p>
<p><a target="_blank" rel="noopener" href="https://spring.io/projects/spring-kafka">https://spring.io/projects/spring-kafka</a></p>
<h3 id="1-依赖"><a href="#1-依赖" class="headerlink" title="1.依赖"></a>1.依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h3 id="2-生产者"><a href="#2-生产者" class="headerlink" title="2.生产者"></a>2.生产者</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yhd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createtime</span> 2021/1/29 15:50</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate&lt;String,String&gt; kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> test topic</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> msgkey key</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> msgData data</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">()</span></span>&#123;</span><br><span class="line">        kafkaTemplate.send(<span class="string">&quot;test&quot;</span>,<span class="string">&quot;msgkey&quot;</span>,<span class="string">&quot;msgData&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="3-消费者"><a href="#3-消费者" class="headerlink" title="3.消费者"></a>3.消费者</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yhd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createtime</span> 2021/1/29 15:53</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &#123;&quot;test&quot;&#125;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listener</span><span class="params">(ConsumerRecord record)</span></span>&#123;</span><br><span class="line">        Optional&lt;Object&gt; msg = Optional.ofNullable(record.value());</span><br><span class="line">        <span class="keyword">if</span> (msg.isPresent())&#123;</span><br><span class="line">            System.out.println(msg.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="4-配置文件"><a href="#4-配置文件" class="headerlink" title="4.配置文件"></a>4.配置文件</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置集群地址</span></span><br><span class="line"><span class="meta">spring.kafka.bootstrap-servers</span>=<span class="string">121.199.31.160:9092</span></span><br><span class="line"><span class="comment">#生产者序列化</span></span><br><span class="line"><span class="meta">spring.kafka.producer.key-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="meta">spring.kafka.producer.value-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="comment">#消费者分组</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.group-id</span>=<span class="string">test-consumer-group</span></span><br><span class="line"><span class="comment">#消息同步</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.auto-offset-reset</span>=<span class="string">earliest</span></span><br><span class="line"><span class="comment">#自动确认</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.enable-auto-commit</span>=<span class="string">true</span></span><br><span class="line"><span class="comment">#消费者反序列化</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.key-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.value-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br></pre></td></tr></table></figure>


<h2 id="四，关于Topic和Partition"><a href="#四，关于Topic和Partition" class="headerlink" title="四，关于Topic和Partition"></a>四，关于Topic和Partition</h2><h3 id="1-Topic"><a href="#1-Topic" class="headerlink" title="1.Topic"></a>1.Topic</h3><p>在kafka中，topic是一个存储消息的逻辑概念，可以认为是一个消息集合。每条消息发送到kafka集群的消息都有一个类别。物理上来说，不同的topic的消息是分开存储的，</p>
<p>每个topic可以有多个生产者向它发送消息，也可以有多个消费者去消费其中的消息。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083764523-87db0f74-8df2-46cd-bbf3-d9ae0ea07170.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=u4c9e0843&margin=%5Bobject%20Object%5D&name=3.png&originHeight=399&originWidth=1144&originalType=binary&ratio=1&rotation=0&showTitle=false&size=39537&status=done&style=none&taskId=u63ad4cf4-b4cd-4bed-8f58-2d142731d2b&title=" alt="3.png"></p>
<h3 id="2-Partition"><a href="#2-Partition" class="headerlink" title="2.Partition"></a>2.Partition</h3><p>每个topic可以划分多个分区（每个Topic至少有一个分区），同一topic下的不同分区包含的消息是不同的。每个消息在被添加到分区时，都会被分配一个offset（称之为偏移量），它是消息在此分区中的唯一编号，kafka通过offset保证消息在分区内的顺序，offset的顺序不跨分区，即kafka只保证在同一个<br>分区内的消息是有序的。</p>
<p>下图中，对于名字为test的topic，做了3个分区，分别是p0、p1、p2.</p>
<p>Ø 每一条消息发送到broker时，会根据partition的规则选择存储到哪一个partition。如果partition规则设置合理，那么所有的消息会均匀的分布在不同的partition中，这样就有点类似数据库的分库分表的概念，把数据做了分片处理。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083778421-3de4271f-54e2-4324-9855-02f67bdb9436.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=u25d1aafe&margin=%5Bobject%20Object%5D&name=4.png&originHeight=458&originWidth=1150&originalType=binary&ratio=1&rotation=0&showTitle=false&size=60503&status=done&style=none&taskId=udef52f40-356d-413a-958c-da914f72395&title=" alt="4.png"></p>
<h3 id="3-Topic-amp-Partition的存储"><a href="#3-Topic-amp-Partition的存储" class="headerlink" title="3.Topic&amp;Partition的存储"></a>3.Topic&amp;Partition的存储</h3><p>Partition是以文件的形式存储在文件系统中，比如创建一个名为firstTopic的topic，其中有3个partition，那么在kafka的数据目录（/tmp/kafka-log）中就有3个目录，firstTopic-0~3， 命名规则是<topic_name>-<partition_id></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh kafka-topics.sh --create --zookeeper 192.168.11.156:2181 --replication-factor1 --partitions 3 --topic firstTopic</span><br></pre></td></tr></table></figure>


<h2 id="五，关于消息分发"><a href="#五，关于消息分发" class="headerlink" title="五，关于消息分发"></a>五，关于消息分发</h2><h3 id="1-kafka消息分发策略"><a href="#1-kafka消息分发策略" class="headerlink" title="1.kafka消息分发策略"></a>1.kafka消息分发策略</h3><p>消息是kafka中最基本的数据单元，在kafka中，一条消息由key、value两部分构成，在发送一条消息时，我们可以指定这个key，那么producer会根据key和partition机制来判断当前这条消息应该发送并存储到哪个partition中。我们可以根据需要进行扩展producer的partition机制。</p>
<h3 id="2-代码演示"><a href="#2-代码演示" class="headerlink" title="2.代码演示"></a>2.代码演示</h3><h4 id="2-1自定义Partitioner"><a href="#2-1自定义Partitioner" class="headerlink" title="2.1自定义Partitioner"></a>2.1自定义Partitioner</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Random random = <span class="keyword">new</span> Random();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String s, Object o, <span class="keyword">byte</span>[] bytes, Object o1, <span class="keyword">byte</span>[] bytes1, Cluster cluster)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取集群中指定topic的所有分区信息</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitionInfos = cluster.partitionsForTopic(s);</span><br><span class="line">        <span class="keyword">int</span> numOfPartition = partitionInfos.size();</span><br><span class="line">        <span class="keyword">int</span> num=<span class="number">0</span>;</span><br><span class="line">        <span class="comment">//key没有设置</span></span><br><span class="line">        <span class="keyword">if</span> (o==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="comment">//随机指定分区</span></span><br><span class="line">            num=random.nextInt(numOfPartition);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            num=Math.abs((o1.hashCode()))%numOfPartition;</span><br><span class="line">        &#125;</span><br><span class="line">        log.info(<span class="string">&quot;key-&gt;&#123;&#125;,value-&gt;&#123;&#125;-&gt;send topartition:&#123;&#125;&quot;</span>,o,o1,num);</span><br><span class="line">        <span class="keyword">return</span> num;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h4 id="2-2发送端代码添加自定义分区"><a href="#2-2发送端代码添加自定义分区" class="headerlink" title="2.2发送端代码添加自定义分区"></a>2.2发送端代码添加自定义分区</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yhd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createtime</span> 2021/1/29 17:28</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span> 发送端代码添加自定义分区</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@SpringBootConfiguration</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> KafkaTemplate&lt;String, String&gt; <span class="title">kafkaTemplate</span><span class="params">(ProducerFactory producerFactory)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Map&lt;Object, String&gt; configMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        configMap.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;121.199.31.160:9092&quot;</span>);</span><br><span class="line">        configMap.put(ProducerConfig.CLIENT_ID_CONFIG, <span class="string">&quot;kafkaTemplate&quot;</span>);</span><br><span class="line">        configMap.put(ProducerConfig.ACKS_CONFIG, <span class="string">&quot;-1&quot;</span>);</span><br><span class="line">        configMap.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.IntegerSerializer&quot;</span>);</span><br><span class="line">        configMap.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        configMap.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, <span class="string">&quot;com.yhd.kafka.diy.MyPartitioner&quot;</span>);</span><br><span class="line">        KafkaTemplate&lt;String, String&gt; kafkaTemplate = <span class="keyword">new</span> KafkaTemplate(producerFactory, configMap);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> kafkaTemplate;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="3-消息默认的分发机制"><a href="#3-消息默认的分发机制" class="headerlink" title="3.消息默认的分发机制"></a>3.消息默认的分发机制</h3><p>默认情况下，kafka采用的是hash取模的分区算法。如果Key为null，则会随机分配一个分区。这个随机是在这个参数”metadata.max.age.ms”的时间范围内随机选择一个。对于这个时间段内，如果key为null，则只会发送到唯一的分区。这个值默认情况下是10分钟更新一次。</p>
<p>关于Metadata，简单理解就是Topic/Partition和broker的映射关系，每一个topic的每一个partition，需要知道对应的broker列表是什么，leader是谁、follower是谁。这些信息都是存储在Metadata这个类里面。</p>
<h3 id="4-消费端如何消费指定的分区"><a href="#4-消费端如何消费指定的分区" class="headerlink" title="4.消费端如何消费指定的分区"></a>4.消费端如何消费指定的分区</h3><p>通过下面的代码，就可以消费指定该topic下的0号分区。其他分区的数据就无法接收</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &#123;&quot;test&quot;&#125;, topicPartitions = &#123;&#125;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listener</span><span class="params">(ConsumerRecord record)</span> </span>&#123;</span><br><span class="line">        Optional&lt;Object&gt; msg = Optional.ofNullable(record.value());</span><br><span class="line">        <span class="keyword">if</span> (msg.isPresent()) &#123;</span><br><span class="line">            System.out.println(msg.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="六，消息的消费原理"><a href="#六，消息的消费原理" class="headerlink" title="六，消息的消费原理"></a>六，消息的消费原理</h2><h3 id="1-kafka消息消费原理演示"><a href="#1-kafka消息消费原理演示" class="headerlink" title="1.kafka消息消费原理演示"></a>1.kafka消息消费原理演示</h3><p>多个partition以及多个consumer的情况下，消费者是如何消费消息的</p>
<p>kafka存在consumer group的概念，也就是group.id一样的consumer，这些consumer属于一个consumer group，组内的所有消费者协调在一起来消费订阅主题的所有分区。当然每一个分区只能由同一个消费组内的consumer来消费，那么同一个consumergroup里面的consumer是怎么去分配该消费哪个分区里的数据的呢？</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083791583-30a54b1b-84d8-4827-b92d-ec5c539ba3ed.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=ue73d462d&margin=%5Bobject%20Object%5D&name=5.png&originHeight=492&originWidth=1144&originalType=binary&ratio=1&rotation=0&showTitle=false&size=65086&status=done&style=none&taskId=uf2bc609c-1a0d-4e06-ac82-8536ff85d50&title=" alt="5.png"></p>
<p>对于上面这个图来说，这3个消费者会分别消费test这个topic 的3个分区，也就是每个consumer消费一个partition。</p>
<p>如果是2个consumer消费3个partition呢？</p>
<p>consumer1会消费partition0/partition1分区、consumer2会消费partition2分区</p>
<p>3个partition对应4个或以上consumer</p>
<p>仍然只有3个consumer对应3个partition，其他的consumer无法消费消息</p>
<h5 id="1-1consumer和partition的数量建议"><a href="#1-1consumer和partition的数量建议" class="headerlink" title="1.1consumer和partition的数量建议"></a>1.1consumer和partition的数量建议</h5><ol>
<li>如果consumer比partition多，是浪费，因为kafka的设计是在一个partition上是不允许并发的，所以consumer数不要大于partition数</li>
<li>如果consumer比partition少，一个consumer会对应于多个partitions，这里主要合理分配consumer数和partition数，否则会导致partition里面的数据被取的不均匀。最好partiton数目是consumer数目的整数倍，所以partition数目很重要，比如取24，就很容易设定consumer数目</li>
<li>如果consumer从多个partition读到数据，不保证数据间的顺序性，kafka只保证在一个partition上数据是有序的，但多个partition，根据你读的顺序会有不同</li>
<li>增减consumer，broker，partition会导致rebalance，所以rebalance后consumer对应的partition会发生变化</li>
</ol>
<h5 id="1-2什么时候会触发这个策略呢？"><a href="#1-2什么时候会触发这个策略呢？" class="headerlink" title="1.2什么时候会触发这个策略呢？"></a>1.2什么时候会触发这个策略呢？</h5><p>当出现以下几种情况时，kafka会进行一次分区分配操作，也就是kafka consumer的rebalance</p>
<ol>
<li>同一个consumer group内新增了消费者</li>
<li>消费者离开当前所属的consumer group，比如主动停机或者宕机</li>
<li>topic新增了分区（也就是分区数量发生了变化）</li>
</ol>
<p>kafka consuemr的rebalance机制规定了一个consumer group下的所有consumer如何达成一致来分配订阅topic的每个分区。而具体如何执行分区策略，就是前面提到过的两种内置的分区策略。而kafka对于分配策略这块，提供了可插拔的实现方式， 也就是说，除了这两种之外，我们还可以创建自己的分配机制。</p>
<h3 id="2-什么是分区分配策略"><a href="#2-什么是分区分配策略" class="headerlink" title="2.什么是分区分配策略"></a>2.什么是分区分配策略</h3><p>在kafka中，存在三种分区分配策略，一种是Range(默认)、 另一种是RoundRobin（轮询）、StickyAssignor(粘性)。 在消费端中的ConsumerConfig中，通过这个属性来指定分区分配策略</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumer</span> </span>&#123;</span><br><span class="line">    <span class="meta">@KafkaListener(topics = &#123;&quot;test&quot;&#125;,properties = &#123;ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG&#125;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listener</span><span class="params">(ConsumerRecord record)</span> </span>&#123;</span><br><span class="line">        Optional&lt;Object&gt; msg = Optional.ofNullable(record.value());</span><br><span class="line">        <span class="keyword">if</span> (msg.isPresent()) &#123;</span><br><span class="line">            System.out.println(msg.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h4 id="2-1RangeAssignor（范围分区）"><a href="#2-1RangeAssignor（范围分区）" class="headerlink" title="2.1RangeAssignor（范围分区）"></a>2.1RangeAssignor（范围分区）</h4><p>Range策略是对每个主题而言的，首先对同一个主题里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。</p>
<p><strong>假设n = 分区数／消费者数量，m= 分区数％消费者数量，那么前m个消费者每个分配n+l个分区，后面的（消费者数量-m)个消费者每个分配n个分区</strong></p>
<p>假设我们有10个分区，3个消费者，排完序的分区将会是0, 1, 2, 3, 4, 5, 6, 7, 8, 9；消费者线程排完序将会是C1-0, C2-0, C3-0。然后将partitions的个数除于消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。在我们的例子里面，我们有10个分区，3个消费者线程， 10 / 3 = 3，而且除不尽，那么消费者线程 C1-0 将会多消费一个分区</p>
<p><strong>的结果看起来是这样的：</strong></p>
<p>C1-0 将消费 0, 1, 2, 3 分区<br>C2-0 将消费 4, 5, 6 分区<br>C3-0 将消费 7, 8, 9 分区</p>
<p><strong>假如我们有11个分区，那么最后分区分配的结果看起来是这样的：</strong></p>
<p>C1-0 将消费 0, 1, 2, 3 分区<br>C2-0 将消费 4, 5, 6, 7 分区<br>C3-0 将消费 8, 9, 10 分区</p>
<p><strong>假如我们有2个主题(T1和T2)，分别有10个分区，那么最后分区分配的结果看起来是这样的：</strong></p>
<p>C1-0 将消费 T1主题的 0, 1, 2, 3 分区以及 T2主题的 0, 1, 2, 3分区<br>C2-0 将消费 T1主题的 4, 5, 6 分区以及 T2主题的 4, 5, 6分区<br>C3-0 将消费 T1主题的 7, 8, 9 分区以及 T2主题的 7, 8, 9分区</p>
<p><strong>可以看出，C1-0 消费者线程比其他消费者线程多消费了2个分区，这就是Range strategy的一个很明显的弊端</strong></p>
<h4 id="2-2RoundRobinAssignor（轮询分区）"><a href="#2-2RoundRobinAssignor（轮询分区）" class="headerlink" title="2.2RoundRobinAssignor（轮询分区）"></a>2.2RoundRobinAssignor（轮询分区）</h4><p>轮询分区策略是把所有partition和所有consumer线程都列出来，然后按照hashcode进行排序。最后通过轮询算法分配partition给消费线程。如果所有consumer实例的订阅是相同的，那么partition会均匀分布。</p>
<p>在我们的例子里面，假如按照 hashCode 排序完的topic-partitions组依次为T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9，我们的消费者线程排序为C1-0, C1-1, C2-0, C2-1，最后分区分配的结果为：</p>
<p>C1-0 将消费 T1-5, T1-2, T1-6 分区；<br>C1-1 将消费 T1-3, T1-1, T1-9 分区；<br>C2-0 将消费 T1-0, T1-4 分区；<br>C2-1 将消费 T1-8, T1-7 分区；</p>
<p>使用轮询分区策略必须满足两个条件：==每个主题的消费者实例具有相同数量的流且每个消费者订阅的主题必须是相同的</p>
<h4 id="2-3StrickyAssignor-分配策略"><a href="#2-3StrickyAssignor-分配策略" class="headerlink" title="2.3StrickyAssignor 分配策略"></a>2.3StrickyAssignor 分配策略</h4><p><strong>分区的分配尽可能的均匀，分区的分配尽可能和上次分配保持相同</strong></p>
<p>当两者发生冲突时， 第 一 个目标优先于第二个目标。 鉴于这两个目标， StickyAssignor分配策略的具体实现要比RangeAssignor和RoundRobinAssi gn or这两种分配策略要复杂得多，假设我们有这样一个场景</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">假设消费组有3个消费者：C0,C1,C2，它们分别订阅了4个Topic(t0,t1,t2,t3),并且每个主题有两个分</span><br><span class="line">区(p0,p1),也就是说，整个消费组订阅了8个分区：tOpO 、 tOpl 、 tlpO 、 tlpl 、 t2p0 、</span><br><span class="line">t2pl 、t3p0 、 t3pl</span><br><span class="line">那么最终的分配场景结果为</span><br><span class="line">CO: tOpO、tlpl 、 t3p0</span><br><span class="line">Cl: tOpl、t2p0 、 t3pl</span><br><span class="line">C2: tlpO、t2pl</span><br><span class="line">这种分配方式有点类似于轮询策略，但实际上并不是，因为假设这个时候，C1这个消费者挂了，就势必会造成</span><br><span class="line">重新分区（reblance），如果是轮询，那么结果应该是</span><br><span class="line">CO: tOpO、tlpO、t2p0、t3p0</span><br><span class="line">C2: tOpl、tlpl、t2pl、t3pl</span><br><span class="line">然后，strickyAssignor它是一种粘滞策略，所以它会满足`分区的分配尽可能和上次分配保持相同`，所以</span><br><span class="line">分配结果应该是</span><br><span class="line">消费者CO: tOpO、tlpl 、 t3p0、t2p0</span><br><span class="line">消费者C2: tlpO、t2pl、tOpl、t3pl</span><br><span class="line">也就是说，C0和C2保留了上一次是的分配结果，并且把原来C1的分区分配给了C0和C2。 这种策略的好处是</span><br><span class="line">使得分区发生变化时，由于分区的“粘性，减少了不必要的分区移动</span><br></pre></td></tr></table></figure>


<h3 id="3-谁来执行Rebalance以及管理consumer的group呢？"><a href="#3-谁来执行Rebalance以及管理consumer的group呢？" class="headerlink" title="3.谁来执行Rebalance以及管理consumer的group呢？"></a>3.谁来执行Rebalance以及管理consumer的group呢？</h3><p>Kafka提供了一个角色：coordinator来执行对于consumer group的管理，当consumer group的第一个consumer启动的时候，它会去和kafka server确定谁是它们组的coordinator。之后该group内的所有成员都会和该coordinator进行协调通信</p>
<h4 id="3-1如何确定coordinator"><a href="#3-1如何确定coordinator" class="headerlink" title="3.1如何确定coordinator"></a>3.1如何确定coordinator</h4><p>消费者向kafka集群中的任意一个broker发送一个GroupCoordinatorRequest请求，服务端会返回一个负载最小的broker节点的id，并将该broker设置为coordinator</p>
<h4 id="3-2JoinGroup的过程"><a href="#3-2JoinGroup的过程" class="headerlink" title="3.2JoinGroup的过程"></a>3.2JoinGroup的过程</h4><p>在rebalance之前，需要保证coordinator是已经确定好了的，整个rebalance的过程分为两个步骤，Join和Sync</p>
<p>join: 表示加入到consumer group中，在这一步中，所有的成员都会向coordinator发送joinGroup的请求。一旦所有成员都发送了joinGroup请求，那么coordinator会选择一个consumer担任leader角色，并把组成员信息和订阅信息发送消费者</p>
<p>leader选举算法比较简单，如果消费组内没有leader，那么第一个加入消费组的消费者就是消费者leader，如果这个时候leader消费者退出了消费组，那么重新选举一个leader，这个选举很随意，类似于随机算法</p>
<p>每个消费者都可以设置自己的分区分配策略，对于消费组而言，会从各个消费者上报过来的分区分配策略中选举一个彼此都赞同的策略来实现整体的分区分配，这个”赞同”的规则是，消费组内的各个消费者会通过投票来决定</p>
<p>在joingroup阶段，每个consumer都会把自己支持的分区分配策略发送到coordinator</p>
<p>coordinator收集到所有消费者的分配策略，组成一个候选集</p>
<p>每个消费者需要从候选集里找出一个自己支持的策略，并且为这个策略投票</p>
<p>最终计算候选集中各个策略的选票数，票数最多的就是当前消费组的分配策略</p>
<h4 id="3-3Synchronizing-Group-State阶段"><a href="#3-3Synchronizing-Group-State阶段" class="headerlink" title="3.3Synchronizing Group State阶段"></a>3.3Synchronizing Group State阶段</h4><p>完成分区分配之后，就进入了Synchronizing Group State阶段，主要逻辑是向GroupCoordinator发送SyncGroupRequest请求，并且处理SyncGroupResponse响应，简单来说，就是leader将消费者对应的partition分配方案同步给consumer group 中的所有consumer</p>
<p>每个消费者都会向coordinator发送syncgroup请求，不过只有leader节点会发送分配方案，其他消费者只是打打酱油而已。当leader把方案发给coordinator以后，coordinator会把结果设置到SyncGroupResponse中。这样所有成员都知道自己应该消费哪个分区。</p>
<h3 id="4-如何保存消费端的消费位置"><a href="#4-如何保存消费端的消费位置" class="headerlink" title="4.如何保存消费端的消费位置"></a>4.如何保存消费端的消费位置</h3><h4 id="4-1什么是offset"><a href="#4-1什么是offset" class="headerlink" title="4.1什么是offset"></a>4.1什么是offset</h4><p>每个消息在被添加到分区时，都会被分配一个offset（称之为偏移量），它是消息在此分区中的唯一编号，kafka通过offset保证消息在分区内的顺序，offset的顺序不跨分区，即kafka只保证在同一个分区内的消息是有序的； 对于应用层的消费来说，每次消费一个消息并且提交以后，会保存当前消费到的最近的一个offset。</p>
<p>那么offset保存在哪里？</p>
<h4 id="4-2offset在哪里维护"><a href="#4-2offset在哪里维护" class="headerlink" title="4.2offset在哪里维护"></a>4.2offset在哪里维护</h4><p><strong>在kafka中，提供了一个consumer_offsets_</strong> 的一个topic，把offset信息写入到这个topic中。**</p>
<h2 id="七，分区副本机制"><a href="#七，分区副本机制" class="headerlink" title="七，分区副本机制"></a>七，分区副本机制</h2><h3 id="1-副本机制概述"><a href="#1-副本机制概述" class="headerlink" title="1.副本机制概述"></a>1.副本机制概述</h3><p>Kafka的每个topic都可以分为多个Partition，并且多个partition会均匀分布在集群的各个节点下。虽然这种方式能够有效的对数据进行分片，但是对于每个partition来说，都是单点的，当其中一个partition不可用的时候，那么这部分消息就没办法消费。所以kafka为了提高partition的可靠性而提供了副本的概念（Replica）,通过副本机制来实现冗余备份。</p>
<p>每个分区可以有多个副本，并且在副本集合中会存在一个leader的副本，所有的读写请求都是由leader副本来进行处理。剩余的其他副本都做为follower副本，follower副本会从leader副本同步消息日志。这个有点类似zookeeper中leader和follower的概念，但是具体的实现方式还是有比较大的差异。所以我们可以认为，副本集会存在一主多从的关系。</p>
<p>一般情况下，同一个分区的多个副本会被均匀分配到集群中的不同broker上，当leader副本所在的broker出现故障后，可以重新选举新的leader副本继续对外提供服务。通过这样的副本机制来提高kafka集群的可用性。</p>
<h3 id="2-创建一个带副本机制的topic"><a href="#2-创建一个带副本机制的topic" class="headerlink" title="2.创建一个带副本机制的topic"></a>2.创建一个带副本机制的topic</h3><p>通过下面的命令去创建带2个副本的topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh kafka-topics.sh --create --zookeeper 121.199.31.160:2181 --replication-factor 3 --partitions 3 --topic secondTopic</span><br></pre></td></tr></table></figure>


<p>在/tmp/kafka-log路径下看到对应topic的副本信息</p>
<p>需要注意的是，kafka集群中的一个broker中最多只能有一个副本，leader副本所在的broker节点的分区叫leader节点，follower副本所在的broker节点的分区叫follower节点</p>
<h2 id="八，消息的存储"><a href="#八，消息的存储" class="headerlink" title="八，消息的存储"></a>八，消息的存储</h2><p>消息发送端发送消息到broker上以后，消息是如何持久化的呢？</p>
<p>kafka是使用日志文件的方式来保存生产者和发送者的消息，每条消息都有一个offset值来表示它在分区中的偏移量。Kafka中存储的一般都是海量的消息数据，为了避免日志文件过大，Log并不是直接对应在一个磁盘上的日志文件，而是对应磁盘上的一个目录，这个目录的命名规则是<topic_name>_<partition_id></p>
<h3 id="1-消息的文件存储机制"><a href="#1-消息的文件存储机制" class="headerlink" title="1.消息的文件存储机制"></a>1.消息的文件存储机制</h3><p>一个topic的多个partition在物理磁盘上的保存路径，路径保存在 /tmp/kafka-logs/topic_partition，包含日志文件、索引文件和时间索引文件</p>
<p>kafka是通过分段的方式将Log分为多个LogSegment，LogSegment是一个逻辑上的概念，一个LogSegment对应磁盘上的一个日志文件和一个索引文件，其中日志文件是用来记录消息的。索引文件是用来保存消息的索引。那么这个LogSegment是什么呢？</p>
<h3 id="2-LogSegment"><a href="#2-LogSegment" class="headerlink" title="2.LogSegment"></a>2.LogSegment</h3><p>假设kafka以partition为最小存储单位，那么我们可以想象当kafka producer不断发送消息，必然会引起partition文件的无线扩张，这样对于消息文件的维护以及被消费的消息的清理带来非常大的挑战，所以kafka 以segment为单位又把partition进行细分。每个partition相当于一个巨型文件被平均分配到多个大小相等的segment数据文件中（每个segment文件中的消息不一定相等），这种特性方便已经被消费的消息的清理，提高磁盘的利用率。</p>
<h3 id="3-查看segment文件命名规则"><a href="#3-查看segment文件命名规则" class="headerlink" title="3.查看segment文件命名规则"></a>3.查看segment文件命名规则</h3><p>通过下面这条命令可以看到kafka消息日志的内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test-0/00000000000000000000.log --print-data-log</span><br></pre></td></tr></table></figure>


<p>假如第一个log文件的最后一个offset为:5376,所以下一个segment的文件命名为:00000000000000005376.log。对应的index为00000000000000005376.index</p>
<h3 id="4-segment中index和log的对应关系"><a href="#4-segment中index和log的对应关系" class="headerlink" title="4.segment中index和log的对应关系"></a>4.segment中index和log的对应关系</h3><p>从所有分段中，找一个分段进行分析</p>
<p>为了提高查找消息的性能，为每一个日志文件添加2个索引索引文件：OffsetIndex 和 TimeIndex，分别对应.index以及.timeindex, TimeIndex索引文件格式：它是映射时间戳和相对offset</p>
<p>查看索引内容：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test-<span class="number">0</span>/<span class="number">00000000000000000000.</span>index --print-data-log</span><br></pre></td></tr></table></figure>


<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083825036-1ab186c3-f74b-48ca-80a8-cfdd76211431.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=ud85b0518&margin=%5Bobject%20Object%5D&name=6.png&originHeight=590&originWidth=900&originalType=binary&ratio=1&rotation=0&showTitle=false&size=75155&status=done&style=none&taskId=ub0aa8b36-c99c-4da9-9ac4-69351762d3f&title=" alt="6.png"></p>
<p>如图所示，index中存储了索引以及物理偏移量。 log存储了消息的内容。索引文件的元数据执行对应数据文件中message的物理偏移地址。举个简单的案例来说，以[4053,80899]为例，在log文件中，对应的是第4053条记录，物理偏移量（position）为80899. position是ByteBuffer的指针位置</p>
<h3 id="5-在partition中如何通过offset查找message"><a href="#5-在partition中如何通过offset查找message" class="headerlink" title="5.在partition中如何通过offset查找message"></a>5.在partition中如何通过offset查找message</h3><p>查找的算法是</p>
<ol>
<li>根据offset的值，查找segment段中的index索引文件。由于索引文件命名是以上一个文件的最后一个offset进行命名的，所以，使用二分查找算法能够根据offset快速定位到指定的索引文件。</li>
<li>找到索引文件后，根据offset进行定位，找到索引文件中的符合范围的索引。（kafka采用稀疏索引的方式来提高查找性能）</li>
<li>得到position以后，再到对应的log文件中，从position出开始查找offset对应的消息，将每条消息的offset与目标offset进行比较，直到找到消息</li>
</ol>
<p>比如说，我们要查找offset=2490这条消息，那么先找到00000000000000000000.index, 然后找到[2487,49111]这个索引，再到log文件中，根据2487这个position开始查找，比较每条消息的offset是否大于等于2490。最后查找到对应的消息以后返回</p>
<h3 id="6-Log文件的消息内容分析"><a href="#6-Log文件的消息内容分析" class="headerlink" title="6.Log文件的消息内容分析"></a>6.Log文件的消息内容分析</h3><p>通过kafka提供的命令，可以查看二进制的日志文件信息，一条消息，会包含很多的字段。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">offset: 5371 position: 102124 CreateTime: 1531477349286 isvalid: true keysize: -1 valuesize: 12 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: false headerKeys: [] payload: message_5371</span><br></pre></td></tr></table></figure>


<p>createTime表示创建时间、keysize和valuesize表示key和value的大小、 compresscodec表示压缩编码、payload:表示消息的具体内容</p>
<h3 id="7-日志的清除策略以及压缩策略"><a href="#7-日志的清除策略以及压缩策略" class="headerlink" title="7.日志的清除策略以及压缩策略"></a>7.日志的清除策略以及压缩策略</h3><h4 id="7-1日志清除策略"><a href="#7-1日志清除策略" class="headerlink" title="7.1日志清除策略"></a>7.1日志清除策略</h4><p>前面提到过，日志的分段存储，一方面能够减少单个文件内容的大小，另一方面，方便kafka进行日志清理。日志的清理策略有两个</p>
<ol>
<li>根据消息的保留时间，当消息在kafka中保存的时间超过了指定的时间，就会触发清理过程</li>
<li>根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阀值，则可以开始删除最旧的消息。kafka会启动一个后台线程，定期检查是否存在可以删除的消息</li>
</ol>
<p>通过log.retention.bytes和log.retention.hours这两个参数来设置，当其中任意一个达到要求，都会执行删除。</p>
<p>默认的保留时间是：7天</p>
<p>Kafka还提供了“日志压缩（Log Compaction）”功能，通过这个功能可以有效的减少日志文件的大小，缓解磁盘紧张的情况，在很多实际场景中，消息的key和value的值之间的对应关系是不断变化的，就像数据库中的数据会不断被修改一样，消费者只关心key对应的最新的value。因此，我们可以开启kafka的日志压缩功能，服务端会在后台启动启动Cleaner线程池，定期将相同的key进行合并，只保留最新的value值。日志的压缩原理是</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083833046-627c7ea8-fa6e-49d7-a4ef-f1b2982291ca.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=uae554518&margin=%5Bobject%20Object%5D&name=7.png&originHeight=398&originWidth=865&originalType=binary&ratio=1&rotation=0&showTitle=false&size=38280&status=done&style=none&taskId=u68d0e1a9-7d71-4d6d-a96d-ad7477627d2&title=" alt="7.png"></p>
<h2 id="九，磁盘存储的性能问题"><a href="#九，磁盘存储的性能问题" class="headerlink" title="九，磁盘存储的性能问题"></a>九，磁盘存储的性能问题</h2><h3 id="1-磁盘存储的性能优化"><a href="#1-磁盘存储的性能优化" class="headerlink" title="1.磁盘存储的性能优化"></a>1.磁盘存储的性能优化</h3><p>如果把消息以随机的方式写入到磁盘，那么磁盘首先要做的就是寻址，也就是定位到数据所在的物理地址，在磁盘上就要找到对应的柱面、磁头以及对应的扇区；这个过程相对内存来说会消耗大量时间，为了规避随机读写带来的时间消耗，kafka采用顺序写的方式存储数据。即使是这样，但是频繁的I/O操作仍然会造成磁盘的性能瓶颈</p>
<h3 id="2-零拷贝"><a href="#2-零拷贝" class="headerlink" title="2.零拷贝"></a>2.零拷贝</h3><p>消息从发送到落地保存，broker维护的消息日志本身就是文件目录，每个文件都是二进制保存，生产者和消费者使用相同的格式来处理。在消费者获取消息时，服务器先从硬盘读取数据到内存，然后把内存中的数据原封不动的通过socket发送给消费者。虽然这个操作描述起来很简单，但实际上经历了很多步骤。</p>
<p>操作系统将数据从磁盘读入到内核空间的页缓存</p>
<p>应用程序将数据从内核空间读入到用户空间缓存中</p>
<p>应用程序将数据写回到内核空间到socket缓存中</p>
<p>操作系统将数据从socket缓冲区复制到网卡缓冲区，以便将数据经网络发出</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083842139-0271a8af-24b5-4d25-b719-b18cf09adab8.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=u430d49ee&margin=%5Bobject%20Object%5D&name=8.png&originHeight=547&originWidth=682&originalType=binary&ratio=1&rotation=0&showTitle=false&size=34244&status=done&style=none&taskId=u083c226f-e74b-4bcf-8523-4bbcd9c2dd3&title=" alt="8.png"></p>
<p>通过“零拷贝”技术，可以去掉这些没必要的数据复制操作，同时也会减少上下文切换次数。现代的unix操作系统提供一个优化的代码路径，用于将数据从页缓存传输到socket；在Linux中，是通过sendfile系统调用来完成的。Java提供了访问这个系统调用的方法：FileChannel.transferTo API</p>
<p>使用sendfile，只需要一次拷贝就行，允许操作系统将数据直接从页缓存发送到网络上。所以在这个优化的路径中，只有最后一步将数据拷贝到网卡缓存中是需要的</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/12610368/1642083850444-61d1defa-105a-4f74-95da-84b8288c010d.png#clientId=u373b6193-d212-4&crop=0&crop=0&crop=1&crop=1&from=ui&id=ua5e37ea9&margin=%5Bobject%20Object%5D&name=9.png&originHeight=532&originWidth=695&originalType=binary&ratio=1&rotation=0&showTitle=false&size=33323&status=done&style=none&taskId=ub540ab8c-a9e2-449f-b5d6-0ea7a746a89&title=" alt="9.png"></p>
<h3 id="3-页缓存"><a href="#3-页缓存" class="headerlink" title="3.页缓存"></a>3.页缓存</h3><p>页缓存是操作系统实现的一种主要的磁盘缓存，但凡设计到缓存的，基本都是为了提升i/o性能，所以页缓存是用来减少磁盘I/O操作的。</p>
<p>磁盘高速缓存有两个重要因素</p>
<p>第一，访问磁盘的速度要远低于访问内存的速度，若从处理器L1和L2高速缓存访问则速度更快。</p>
<p>第二，数据一旦被访问，就很有可能短时间内再次访问。正是由于基于访问内存比磁盘快的多，所以磁盘的内存缓存将给系统存储性能带来质的飞越。</p>
<p>当 一 个进程准备读取磁盘上的文件内容时， 操作系统会先查看待读取的数据所在的页(page)是否在页缓存(pagecache)中，如果存在（命中）则直接返回数据， 从而避免了对物理磁盘的I/0操作；如果没有命中， 则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存， 之后再将数据返回给进程。同样，如果 一 个进程需要将数据写入磁盘， 那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在， 则会先在页缓存中添加相应的页， 最后将数据写入对应的页。 被修改过后的页也就变成了脏页， 操作系统会在合适的时间把脏页中的数据写入磁盘， 以保持数据的 一 致性</p>
<p>Kafka中大量使用了页缓存， 这是Kafka实现高吞吐的重要因素之 一 。 虽然消息都是先被写入页缓存，然后由操作系统负责具体的刷盘任务的， 但在Kafka中同样提供了同步刷盘及间断性强制刷盘(fsync),可以通过  log.flush.interval.messages 和  log.flush.interval.ms 参数来控制。</p>
<p>同步刷盘能够保证消息的可靠性，避免因为宕机导致页缓存数据还未完成同步时造成的数据丢失。但是实际使用上，我们没必要去考虑这样的因素以及这种问题带来的损失，消息可靠性可以由多副本来解决，同步刷盘会带来性能的影响。 刷盘的操作由操作系统去完成即可</p>
<h2 id="十，Kafka消息的可靠性"><a href="#十，Kafka消息的可靠性" class="headerlink" title="十，Kafka消息的可靠性"></a>十，Kafka消息的可靠性</h2><p>kafka如何实现最大可能的可靠性呢？</p>
<p>分区副本， 你可以创建更多的分区来提升可靠性，但是分区数过多也会带来性能上的开销，一般来说，3个副本就能满足对大部分场景的可靠性要求</p>
<p>acks，生产者发送消息的可靠性，也就是我要保证我这个消息一定是到了broker并且完成了多副,本的持久化，但这种要求也同样会带来性能上的开销。它有几个可选项</p>
<p>1 ，生产者把消息发送到leader副本，leader副本在成功写入到本地日志之后就告诉生产者消息提交成功，但是如果isr集合中的follower副本还没来得及同步leader副本的消息，leader挂了，就会造成消息丢失</p>
<p>-1 ，消息不仅仅写入到leader副本，并且被ISR集合中所有副本同步完成之后才告诉生产者已经提交成功，这个时候即使leader副本挂了也不会造成数据丢失。</p>
<p>0：表示producer不需要等待broker的消息确认。这个选项时延最小但同时风险最大（因为当server宕机时，数据将会丢失）。</p>
<p>保障消息到了broker之后，消费者也需要有一定的保证，因为消费者也可能出现某些问题导致消息没有消费到</p>
<p>会造成数据丢失。</p>
<p>0：表示producer不需要等待broker的消息确认。这个选项时延最小但同时风险最大（因为当server宕机时，数据将会丢失）。</p>
<p>保障消息到了broker之后，消费者也需要有一定的保证，因为消费者也可能出现某些问题导致消息没有消费到</p>
<p>enable.auto.commit默认为true，也就是自动提交offset，自动提交是批量执行的，有一个时间窗口，这种方式会带来重复提交或者消息丢失的问题，所以对于高可靠性要求的程序，要使用手动提交。 对于高可靠要求的应用来说，宁愿重复消费也不应该因为消费异常而导致消息丢失.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">二十</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://yinhuidong.github.io/2022/01/13/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/kafka[%E4%BA%8C]%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/">https://yinhuidong.github.io/2022/01/13/消息队列/Kafka/kafka[二]核心原理/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://yinhuidong.github.io" target="_blank">二十</a> 许可协议。转载请注明来自 <a href="https://yinhuidong.github.io" target="_blank">huidong.yin</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/RabbitMQ/">RabbitMQ</a></div><div class="post_share"><div class="social-share" data-image="/images/cover/mq.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat_pay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat_pay.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/01/14/MySQL/MySQL%5B%E5%8D%81%E5%9B%9B%5Dredo%E6%97%A5%E5%BF%97/"><img class="prev-cover" src="/images/cover/mysql.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">MySQL[十四]redo日志</div></div></a></div><div class="next-post pull-right"><a href="/2022/01/13/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/kafka%5B%E4%B8%80%5D%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"><img class="next-cover" src="/images/cover/mq.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Kafka基本使用</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/01/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/" title="RabbitMQ"><img class="cover" src="/images/cover/mq.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-11</div><div class="title">RabbitMQ</div></div></a></div><div><a href="/2022/01/13/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/kafka%5B%E4%B8%80%5D%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/" title="Kafka基本使用"><img class="cover" src="/images/cover/mq.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-13</div><div class="title">Kafka基本使用</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">二十</div><div class="author-info__description">欢迎来到huidong.yin的博客....</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">132</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yinhuidong"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/yinhuidong" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1972039773@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">欢迎来到huidong.yin的个人博客，联系作者：VX：yinhuidong666</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%EF%BC%8Cjava%E4%B8%AD%E4%BD%BF%E7%94%A8kafka%E8%BF%9B%E8%A1%8C%E9%80%9A%E4%BF%A1"><span class="toc-text">一，java中使用kafka进行通信</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-batch-size"><span class="toc-text">1. batch.size</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-linger-ms"><span class="toc-text">2. linger.ms</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%EF%BC%8C%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%E5%88%86%E6%9E%90"><span class="toc-text">二，基础配置分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-group-id"><span class="toc-text">1.group.id</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-enable-auto-commit"><span class="toc-text">2.enable.auto.commit</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-auto-offset-reset"><span class="toc-text">3.auto.offset.reset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-max-poll-records"><span class="toc-text">4.max.poll.records</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%EF%BC%8CSpringBoot-Kafka"><span class="toc-text">三，SpringBoot+Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BE%9D%E8%B5%96"><span class="toc-text">1.依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-text">2.生产者</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-text">3.消费者</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">4.配置文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%EF%BC%8C%E5%85%B3%E4%BA%8ETopic%E5%92%8CPartition"><span class="toc-text">四，关于Topic和Partition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Topic"><span class="toc-text">1.Topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Partition"><span class="toc-text">2.Partition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Topic-amp-Partition%E7%9A%84%E5%AD%98%E5%82%A8"><span class="toc-text">3.Topic&amp;Partition的存储</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%EF%BC%8C%E5%85%B3%E4%BA%8E%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91"><span class="toc-text">五，关于消息分发</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-kafka%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91%E7%AD%96%E7%95%A5"><span class="toc-text">1.kafka消息分发策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA"><span class="toc-text">2.代码演示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1%E8%87%AA%E5%AE%9A%E4%B9%89Partitioner"><span class="toc-text">2.1自定义Partitioner</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2%E5%8F%91%E9%80%81%E7%AB%AF%E4%BB%A3%E7%A0%81%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA"><span class="toc-text">2.2发送端代码添加自定义分区</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%B6%88%E6%81%AF%E9%BB%98%E8%AE%A4%E7%9A%84%E5%88%86%E5%8F%91%E6%9C%BA%E5%88%B6"><span class="toc-text">3.消息默认的分发机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%B6%88%E8%B4%B9%E7%AB%AF%E5%A6%82%E4%BD%95%E6%B6%88%E8%B4%B9%E6%8C%87%E5%AE%9A%E7%9A%84%E5%88%86%E5%8C%BA"><span class="toc-text">4.消费端如何消费指定的分区</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%EF%BC%8C%E6%B6%88%E6%81%AF%E7%9A%84%E6%B6%88%E8%B4%B9%E5%8E%9F%E7%90%86"><span class="toc-text">六，消息的消费原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-kafka%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E5%8E%9F%E7%90%86%E6%BC%94%E7%A4%BA"><span class="toc-text">1.kafka消息消费原理演示</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1consumer%E5%92%8Cpartition%E7%9A%84%E6%95%B0%E9%87%8F%E5%BB%BA%E8%AE%AE"><span class="toc-text">1.1consumer和partition的数量建议</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E8%A7%A6%E5%8F%91%E8%BF%99%E4%B8%AA%E7%AD%96%E7%95%A5%E5%91%A2%EF%BC%9F"><span class="toc-text">1.2什么时候会触发这个策略呢？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-text">2.什么是分区分配策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1RangeAssignor%EF%BC%88%E8%8C%83%E5%9B%B4%E5%88%86%E5%8C%BA%EF%BC%89"><span class="toc-text">2.1RangeAssignor（范围分区）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2RoundRobinAssignor%EF%BC%88%E8%BD%AE%E8%AF%A2%E5%88%86%E5%8C%BA%EF%BC%89"><span class="toc-text">2.2RoundRobinAssignor（轮询分区）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3StrickyAssignor-%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-text">2.3StrickyAssignor 分配策略</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%B0%81%E6%9D%A5%E6%89%A7%E8%A1%8CRebalance%E4%BB%A5%E5%8F%8A%E7%AE%A1%E7%90%86consumer%E7%9A%84group%E5%91%A2%EF%BC%9F"><span class="toc-text">3.谁来执行Rebalance以及管理consumer的group呢？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9Acoordinator"><span class="toc-text">3.1如何确定coordinator</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2JoinGroup%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="toc-text">3.2JoinGroup的过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3Synchronizing-Group-State%E9%98%B6%E6%AE%B5"><span class="toc-text">3.3Synchronizing Group State阶段</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E6%B6%88%E8%B4%B9%E7%AB%AF%E7%9A%84%E6%B6%88%E8%B4%B9%E4%BD%8D%E7%BD%AE"><span class="toc-text">4.如何保存消费端的消费位置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1%E4%BB%80%E4%B9%88%E6%98%AFoffset"><span class="toc-text">4.1什么是offset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2offset%E5%9C%A8%E5%93%AA%E9%87%8C%E7%BB%B4%E6%8A%A4"><span class="toc-text">4.2offset在哪里维护</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%EF%BC%8C%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="toc-text">七，分区副本机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E6%A6%82%E8%BF%B0"><span class="toc-text">1.副本机制概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E7%9A%84topic"><span class="toc-text">2.创建一个带副本机制的topic</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%EF%BC%8C%E6%B6%88%E6%81%AF%E7%9A%84%E5%AD%98%E5%82%A8"><span class="toc-text">八，消息的存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%B6%88%E6%81%AF%E7%9A%84%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="toc-text">1.消息的文件存储机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-LogSegment"><span class="toc-text">2.LogSegment</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%9F%A5%E7%9C%8Bsegment%E6%96%87%E4%BB%B6%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99"><span class="toc-text">3.查看segment文件命名规则</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-segment%E4%B8%ADindex%E5%92%8Clog%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="toc-text">4.segment中index和log的对应关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%9C%A8partition%E4%B8%AD%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87offset%E6%9F%A5%E6%89%BEmessage"><span class="toc-text">5.在partition中如何通过offset查找message</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Log%E6%96%87%E4%BB%B6%E7%9A%84%E6%B6%88%E6%81%AF%E5%86%85%E5%AE%B9%E5%88%86%E6%9E%90"><span class="toc-text">6.Log文件的消息内容分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E6%97%A5%E5%BF%97%E7%9A%84%E6%B8%85%E9%99%A4%E7%AD%96%E7%95%A5%E4%BB%A5%E5%8F%8A%E5%8E%8B%E7%BC%A9%E7%AD%96%E7%95%A5"><span class="toc-text">7.日志的清除策略以及压缩策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1%E6%97%A5%E5%BF%97%E6%B8%85%E9%99%A4%E7%AD%96%E7%95%A5"><span class="toc-text">7.1日志清除策略</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%EF%BC%8C%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98"><span class="toc-text">九，磁盘存储的性能问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="toc-text">1.磁盘存储的性能优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%9B%B6%E6%8B%B7%E8%B4%9D"><span class="toc-text">2.零拷贝</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%A1%B5%E7%BC%93%E5%AD%98"><span class="toc-text">3.页缓存</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%81%EF%BC%8CKafka%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="toc-text">十，Kafka消息的可靠性</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/01/24/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%E5%9B%9B%5D%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/" title="MySQL[二十四]两阶段提交"><img src="/images/cover/mysql.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL[二十四]两阶段提交"/></a><div class="content"><a class="title" href="/2022/01/24/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%E5%9B%9B%5D%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/" title="MySQL[二十四]两阶段提交">MySQL[二十四]两阶段提交</a><time datetime="2022-01-23T16:00:00.000Z" title="发表于 2022-01-24 00:00:00">2022-01-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/23/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%E4%B8%89%5D%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%97%A5%E5%BF%97/" title="MySQL[二十三]二进制日志"><img src="/images/cover/mysql.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL[二十三]二进制日志"/></a><div class="content"><a class="title" href="/2022/01/23/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%E4%B8%89%5D%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%97%A5%E5%BF%97/" title="MySQL[二十三]二进制日志">MySQL[二十三]二进制日志</a><time datetime="2022-01-22T16:00:00.000Z" title="发表于 2022-01-23 00:00:00">2022-01-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/22/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%E4%BA%8C%5DCOUNT/" title="MySQL[二十二]COUNT"><img src="/images/cover/mysql.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL[二十二]COUNT"/></a><div class="content"><a class="title" href="/2022/01/22/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%E4%BA%8C%5DCOUNT/" title="MySQL[二十二]COUNT">MySQL[二十二]COUNT</a><time datetime="2022-01-21T16:00:00.000Z" title="发表于 2022-01-22 00:00:00">2022-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/21/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%E4%B8%80%5DLIMIT/" title="MySQL[二十一]LIMIT"><img src="/images/cover/mysql.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL[二十一]LIMIT"/></a><div class="content"><a class="title" href="/2022/01/21/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%E4%B8%80%5DLIMIT/" title="MySQL[二十一]LIMIT">MySQL[二十一]LIMIT</a><time datetime="2022-01-20T16:00:00.000Z" title="发表于 2022-01-21 00:00:00">2022-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/20/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%5D%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93/" title="MySQL[二十]海量数据处理"><img src="/images/cover/mysql.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL[二十]海量数据处理"/></a><div class="content"><a class="title" href="/2022/01/20/MySQL/MySQL%5B%E4%BA%8C%E5%8D%81%5D%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93/" title="MySQL[二十]海量数据处理">MySQL[二十]海量数据处理</a><time datetime="2022-01-19T16:00:00.000Z" title="发表于 2022-01-20 00:00:00">2022-01-20</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/images/cover/mq.png')"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By 二十</div><div class="footer_custom_text">树是生活，埋的是我。看花就好，别看我落魄。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/chocolate.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="二十,二十二十,二十二十二十,二十二十二十二十,二十二十二十二十二十" data-fontsize="15px" data-random="true" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>